# Redes Generativas Antag√≥nicas

En la secci√≥n anterior, aprendimos sobre **modelos generativos**: modelos que pueden generar nuevas im√°genes similares a las del conjunto de datos de entrenamiento. VAE fue un buen ejemplo de un modelo generativo.

## [Cuestionario previo a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Sin embargo, si intentamos generar algo realmente significativo, como una pintura en una resoluci√≥n razonable, con VAE, veremos que el entrenamiento no converge bien. Para este caso de uso, debemos aprender sobre otra arquitectura espec√≠ficamente dise√±ada para modelos generativos: **Redes Generativas Antag√≥nicas**, o GANs.

La idea principal de una GAN es tener dos redes neuronales que se entrenan entre s√≠:

<img src="images/gan_architecture.png" width="70%"/>

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Un poco de vocabulario:
> * **Generador** es una red que toma un vector aleatorio y produce la imagen como resultado.
> * **Discriminador** es una red que toma una imagen y debe decir si es una imagen real (del conjunto de datos de entrenamiento) o fue generada por un generador. Es esencialmente un clasificador de im√°genes.

### Discriminador

La arquitectura del discriminador no difiere de una red de clasificaci√≥n de im√°genes ordinaria. En el caso m√°s simple, puede ser un clasificador totalmente conectado, pero lo m√°s probable es que sea una [red convolucional](../07-ConvNets/README.md).

> ‚úÖ Una GAN basada en redes convolucionales se llama [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Un discriminador CNN consta de las siguientes capas: varias convoluciones + agrupamientos (con tama√±o espacial decreciente) y, una o m√°s capas totalmente conectadas para obtener el "vector de caracter√≠sticas", el clasificador binario final.

> ‚úÖ Un 'agrupamiento' en este contexto es una t√©cnica que reduce el tama√±o de la imagen. "Las capas de agrupamiento reducen las dimensiones de los datos combinando las salidas de grupos de neuronas en una capa en una sola neurona en la siguiente capa." - [fuente](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generador

Un generador es un poco m√°s complicado. Se puede considerar como un discriminador invertido. Comenzando desde un vector latente (en lugar de un vector de caracter√≠sticas), tiene una capa totalmente conectada para convertirlo en el tama√±o/forma requeridos, seguida de deconvoluciones + aumento de escala. Esto es similar a la parte de *decodificador* de un [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Dado que la capa de convoluci√≥n se implementa como un filtro lineal que recorre la imagen, la deconvoluci√≥n es esencialmente similar a la convoluci√≥n y puede implementarse utilizando la misma l√≥gica de capa.

<img src="images/gan_arch_detail.png" width="70%"/>

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

### Entrenando la GAN

Las GAN se llaman **antag√≥nicas** porque hay una competencia constante entre el generador y el discriminador. Durante esta competencia, tanto el generador como el discriminador mejoran, por lo que la red aprende a producir im√°genes cada vez mejores.

El entrenamiento ocurre en dos etapas:

* **Entrenando al discriminador**. Esta tarea es bastante directa: generamos un lote de im√°genes con el generador, etiquet√°ndolas como 0, que representa una imagen falsa, y tomamos un lote de im√°genes del conjunto de datos de entrada (con etiqueta 1, imagen real). Obtenemos una *p√©rdida del discriminador* y realizamos retropropagaci√≥n.
* **Entrenando al generador**. Esto es un poco m√°s complicado, porque no conocemos la salida esperada para el generador directamente. Tomamos toda la red GAN compuesta por un generador seguido de un discriminador, le proporcionamos algunos vectores aleatorios y esperamos que el resultado sea 1 (correspondiente a im√°genes reales). Luego congelamos los par√°metros del discriminador (no queremos que se entrene en este paso) y realizamos la retropropagaci√≥n.

Durante este proceso, las p√©rdidas tanto del generador como del discriminador no disminuyen significativamente. En la situaci√≥n ideal, deber√≠an oscilar, lo que corresponde a que ambas redes mejoran su rendimiento.

## ‚úçÔ∏è Ejercicios: GANs

* [Cuaderno GAN en TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Cuaderno GAN en PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Problemas con el entrenamiento de GAN

Se sabe que las GAN son especialmente dif√≠ciles de entrenar. Aqu√≠ hay algunos problemas:

* **Colapso de modo**. Por este t√©rmino nos referimos a que el generador aprende a producir una imagen exitosa que enga√±a al discriminador, y no una variedad de im√°genes diferentes.
* **Sensibilidad a los hiperpar√°metros**. A menudo se puede ver que una GAN no converge en absoluto, y luego, de repente, disminuye en la tasa de aprendizaje, lo que lleva a la convergencia.
* Mantener un **equilibrio** entre el generador y el discriminador. En muchos casos, la p√©rdida del discriminador puede caer a cero relativamente r√°pido, lo que resulta en que el generador no puede entrenar m√°s. Para superar esto, podemos intentar establecer diferentes tasas de aprendizaje para el generador y el discriminador, o saltar el entrenamiento del discriminador si la p√©rdida ya es demasiado baja.
* Entrenamiento para **alta resoluci√≥n**. Reflejando el mismo problema que con los autoencoders, este problema se activa porque reconstruir demasiadas capas de una red convolucional conduce a artefactos. Este problema se resuelve t√≠picamente con el llamado **crecimiento progresivo**, cuando primero se entrenan algunas capas en im√°genes de baja resoluci√≥n y luego se "desbloquean" o a√±aden capas. Otra soluci√≥n ser√≠a agregar conexiones adicionales entre capas y entrenar varias resoluciones a la vez; consulte este [art√≠culo sobre GANs de Gradiente Multi-escala](https://arxiv.org/abs/1903.06048) para m√°s detalles.

## Transferencia de Estilo

Las GAN son una excelente manera de generar im√°genes art√≠sticas. Otra t√©cnica interesante es la llamada **transferencia de estilo**, que toma una **imagen de contenido** y la vuelve a dibujar en un estilo diferente, aplicando filtros de la **imagen de estilo**.

La forma en que funciona es la siguiente:
* Comenzamos con una imagen de ruido aleatorio (o con una imagen de contenido, pero para fines de comprensi√≥n es m√°s f√°cil comenzar desde ruido aleatorio).
* Nuestro objetivo ser√≠a crear una imagen que est√© cerca tanto de la imagen de contenido como de la imagen de estilo. Esto se determinar√≠a mediante dos funciones de p√©rdida:
   - **P√©rdida de contenido** se calcula en funci√≥n de las caracter√≠sticas extra√≠das por la CNN en algunas capas de la imagen actual y la imagen de contenido.
   - **P√©rdida de estilo** se calcula entre la imagen actual y la imagen de estilo de una manera inteligente utilizando matrices de Gram (m√°s detalles en el [cuaderno de ejemplo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Para hacer la imagen m√°s suave y eliminar el ruido, tambi√©n introducimos **p√©rdida de variaci√≥n**, que calcula la distancia promedio entre p√≠xeles vecinos.
* El bucle de optimizaci√≥n principal ajusta la imagen actual utilizando descenso de gradiente (o alg√∫n otro algoritmo de optimizaci√≥n) para minimizar la p√©rdida total, que es una suma ponderada de las tres p√©rdidas.

## ‚úçÔ∏è Ejemplo: [Transferencia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Cuestionario posterior a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Conclusi√≥n

En esta lecci√≥n, aprendiste sobre las GAN y c√≥mo entrenarlas. Tambi√©n aprendiste sobre los desaf√≠os especiales que este tipo de red neuronal puede enfrentar y algunas estrategias sobre c√≥mo superarlos.

## üöÄ Desaf√≠o

Ejecuta el [cuaderno de Transferencia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) utilizando tus propias im√°genes.

## Revisi√≥n y Autoestudio

Para referencia, lee m√°s sobre las GAN en estos recursos:

* Marco Pasini, [10 Lecciones que Aprend√≠ Entrenando GANs durante un A√±o](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), una arquitectura GAN *de facto* a considerar
* [Creando Arte Generativo usando GANs en Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Tarea

Revisita uno de los dos cuadernos asociados a esta lecci√≥n y vuelve a entrenar la GAN con tus propias im√°genes. ¬øQu√© puedes crear?

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en inteligencia artificial. Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que surjan del uso de esta traducci√≥n.