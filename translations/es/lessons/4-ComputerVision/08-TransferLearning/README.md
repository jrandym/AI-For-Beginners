# Redes Neuronales Pre-entrenadas y Aprendizaje por Transferencia

Entrenar CNNs puede llevar mucho tiempo, y se requiere una gran cantidad de datos para esa tarea. Sin embargo, gran parte del tiempo se dedica a aprender los mejores filtros de bajo nivel que una red puede utilizar para extraer patrones de las im√°genes. Surge una pregunta natural: ¬øpodemos usar una red neuronal entrenada en un conjunto de datos y adaptarla para clasificar diferentes im√°genes sin necesidad de un proceso de entrenamiento completo?

## [Cuestionario previo a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Este enfoque se llama **aprendizaje por transferencia**, porque transferimos parte del conocimiento de un modelo de red neuronal a otro. En el aprendizaje por transferencia, normalmente comenzamos con un modelo pre-entrenado, que ha sido entrenado en un gran conjunto de datos de im√°genes, como **ImageNet**. Esos modelos ya pueden hacer un buen trabajo extrayendo diferentes caracter√≠sticas de im√°genes gen√©ricas, y en muchos casos, simplemente construir un clasificador sobre esas caracter√≠sticas extra√≠das puede dar un buen resultado.

> ‚úÖ El Aprendizaje por Transferencia es un t√©rmino que se encuentra en otros campos acad√©micos, como la Educaci√≥n. Se refiere al proceso de tomar conocimiento de un dominio y aplicarlo a otro.

## Modelos Pre-entrenados como Extractores de Caracter√≠sticas

Las redes convolucionales de las que hemos hablado en la secci√≥n anterior conten√≠an una serie de capas, cada una de las cuales se supone que extrae algunas caracter√≠sticas de la imagen, comenzando desde combinaciones de p√≠xeles de bajo nivel (como l√≠neas horizontales/verticales o trazos), hasta combinaciones de caracter√≠sticas de nivel superior, que corresponden a cosas como el ojo de una llama. Si entrenamos una CNN en un conjunto de datos suficientemente grande de im√°genes gen√©ricas y diversas, la red deber√≠a aprender a extraer esas caracter√≠sticas comunes.

Tanto Keras como PyTorch contienen funciones para cargar f√°cilmente los pesos de redes neuronales pre-entrenadas para algunas arquitecturas comunes, la mayor√≠a de las cuales fueron entrenadas en im√°genes de ImageNet. Las m√°s utilizadas se describen en la p√°gina de [Arquitecturas CNN](../07-ConvNets/CNN_Architectures.md) de la lecci√≥n anterior. En particular, es posible que desees considerar el uso de uno de los siguientes:

* **VGG-16/VGG-19**, que son modelos relativamente simples que a√∫n ofrecen buena precisi√≥n. A menudo, usar VGG como primer intento es una buena elecci√≥n para ver c√≥mo funciona el aprendizaje por transferencia.
* **ResNet** es una familia de modelos propuestos por Microsoft Research en 2015. Tienen m√°s capas y, por lo tanto, requieren m√°s recursos.
* **MobileNet** es una familia de modelos de tama√±o reducido, adecuados para dispositivos m√≥viles. √ösalos si tienes recursos limitados y puedes sacrificar un poco de precisi√≥n.

Aqu√≠ hay ejemplos de caracter√≠sticas extra√≠das de una imagen de un gato por la red VGG-16:

![Caracter√≠sticas extra√≠das por VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.es.png)

## Conjunto de Datos de Gatos vs. Perros

En este ejemplo, utilizaremos un conjunto de datos de [Gatos y Perros](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), que se asemeja mucho a un escenario real de clasificaci√≥n de im√°genes.

## ‚úçÔ∏è Ejercicio: Aprendizaje por Transferencia

Veamos el aprendizaje por transferencia en acci√≥n en los siguientes cuadernos:

* [Aprendizaje por Transferencia - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Aprendizaje por Transferencia - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Visualizando el Gato Adversarial

Una red neuronal pre-entrenada contiene diferentes patrones dentro de su *cerebro*, incluyendo nociones de **gato ideal** (as√≠ como perro ideal, cebra ideal, etc.). Ser√≠a interesante de alguna manera **visualizar esta imagen**. Sin embargo, no es sencillo, porque los patrones est√°n distribuidos por todos los pesos de la red y tambi√©n organizados en una estructura jer√°rquica.

Un enfoque que podemos tomar es comenzar con una imagen aleatoria y luego intentar usar la t√©cnica de **optimizaci√≥n por descenso de gradiente** para ajustar esa imagen de tal manera que la red comience a pensar que es un gato.

![Bucle de Optimizaci√≥n de Imagen](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.es.png)

Sin embargo, si hacemos esto, obtendremos algo muy similar a un ruido aleatorio. Esto se debe a que *hay muchas formas de hacer que la red piense que la imagen de entrada es un gato*, incluyendo algunas que no tienen sentido visualmente. Aunque esas im√°genes contienen muchos patrones t√≠picos de un gato, no hay nada que las restrinja a ser visualmente distintivas.

Para mejorar el resultado, podemos agregar otro t√©rmino a la funci√≥n de p√©rdida, que se llama **p√©rdida de variaci√≥n**. Es una m√©trica que muestra cu√°n similares son los p√≠xeles vecinos de la imagen. Minimizar la p√©rdida de variaci√≥n hace que la imagen sea m√°s suave y elimina el ruido, revelando as√≠ patrones m√°s visualmente atractivos. Aqu√≠ hay un ejemplo de tales im√°genes "ideales", que son clasificadas como gato y como cebra con alta probabilidad:

![Gato Ideal](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.es.png) | ![Cebra Ideal](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.es.png)
-----|-----
 *Gato Ideal* | *Cebra Ideal*

Un enfoque similar puede utilizarse para realizar lo que se llama **ataques adversariales** en una red neuronal. Supongamos que queremos enga√±ar a una red neuronal y hacer que un perro se vea como un gato. Si tomamos la imagen de un perro, que es reconocida por una red como un perro, podemos ajustarla un poco usando optimizaci√≥n por descenso de gradiente, hasta que la red comience a clasificarla como un gato:

![Imagen de un Perro](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.es.png) | ![Imagen de un perro clasificado como gato](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.es.png)
-----|-----
*Imagen original de un perro* | *Imagen de un perro clasificado como gato*

Consulta el c√≥digo para reproducir los resultados anteriores en el siguiente cuaderno:

* [Gato Ideal y Adversarial - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)
## Conclusi√≥n

Usando el aprendizaje por transferencia, puedes r√°pidamente armar un clasificador para una tarea de clasificaci√≥n de objetos personalizada y lograr alta precisi√≥n. Puedes ver que las tareas m√°s complejas que estamos resolviendo ahora requieren mayor poder computacional y no pueden resolverse f√°cilmente en la CPU. En la pr√≥xima unidad, intentaremos usar una implementaci√≥n m√°s liviana para entrenar el mismo modelo utilizando recursos computacionales m√°s bajos, lo que resulta en una precisi√≥n ligeramente inferior.

## üöÄ Desaf√≠o

En los cuadernos adjuntos, hay notas al final sobre c√≥mo el transferir conocimiento funciona mejor con datos de entrenamiento algo similares (quiz√°s un nuevo tipo de animal). Realiza algunos experimentos con tipos de im√°genes completamente nuevos para ver qu√© tan bien o mal funcionan tus modelos de transferencia de conocimiento.

## [Cuestionario posterior a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Revisi√≥n y Autoestudio

Lee [TrainingTricks.md](TrainingTricks.md) para profundizar tu conocimiento sobre algunas otras formas de entrenar tus modelos.

## [Tarea](lab/README.md)

En este laboratorio, utilizaremos un conjunto de datos de mascotas de la vida real [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) con 35 razas de gatos y perros, y construiremos un clasificador de aprendizaje por transferencia.

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en inteligencia artificial. Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de ning√∫n malentendido o mala interpretaci√≥n que surja del uso de esta traducci√≥n.