# न्यूरल नेटवर्क फ्रेमवर्क

जैसा कि हमने पहले सीखा है, न्यूरल नेटवर्क को प्रभावी ढंग से प्रशिक्षित करने के लिए हमें दो चीजें करनी होती हैं:

* टेन्सरों पर कार्य करना, जैसे गुणा करना, जोड़ना, और कुछ कार्यों की गणना करना जैसे सिग्मॉइड या सॉफ़्टमैक्स
* सभी अभिव्यक्तियों के ग्रेडिएंट की गणना करना, ताकि ग्रेडिएंट डिसेंट ऑप्टिमाइजेशन किया जा सके

## [प्री-लेचर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/105)

जबकि `numpy` लाइब्रेरी पहले भाग को कर सकती है, हमें ग्रेडिएंट की गणना करने के लिए कुछ तंत्र की आवश्यकता है। [हमारे फ्रेमवर्क](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb) में, जिसे हमने पिछले अनुभाग में विकसित किया था, हमें `backward` विधि के अंदर सभी व्युत्पत्ति कार्यों को मैन्युअल रूप से प्रोग्राम करना पड़ा, जो बैकप्रोपेगेशन करता है। आदर्श रूप से, एक फ्रेमवर्क हमें *किसी भी अभिव्यक्ति* के ग्रेडिएंट की गणना करने का अवसर देना चाहिए जिसे हम परिभाषित कर सकते हैं।

एक और महत्वपूर्ण बात यह है कि GPU या किसी अन्य विशेष कंप्यूट इकाइयों पर गणनाएँ करना संभव हो, जैसे कि [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)। गहरी न्यूरल नेटवर्क प्रशिक्षण के लिए *कई* गणनाओं की आवश्यकता होती है, और GPU पर इन गणनाओं को समानांतरित करना बहुत महत्वपूर्ण है।

> ✅ 'समानांतरित' शब्द का अर्थ है गणनाओं को कई उपकरणों पर वितरित करना।

वर्तमान में, दो सबसे लोकप्रिय न्यूरल फ्रेमवर्क हैं: [TensorFlow](http://TensorFlow.org) और [PyTorch](https://pytorch.org/)। दोनों CPU और GPU पर टेन्सरों के साथ कार्य करने के लिए एक निम्न-स्तरीय API प्रदान करते हैं। निम्न-स्तरीय API के ऊपर, एक उच्च-स्तरीय API भी है, जिसे क्रमशः [Keras](https://keras.io/) और [PyTorch Lightning](https://pytorchlightning.ai/) कहा जाता है।

निम्न-स्तरीय API | [TensorFlow](http://TensorFlow.org) | [PyTorch](https://pytorch.org/)
--------------|-------------------------------------|--------------------------------
उच्च-स्तरीय API| [Keras](https://keras.io/) | [PyTorch Lightning](https://pytorchlightning.ai/)

**निम्न-स्तरीय APIs** दोनों फ्रेमवर्क में आपको **गणनात्मक ग्राफ** बनाने की अनुमति देते हैं। यह ग्राफ यह परिभाषित करता है कि दिए गए इनपुट पैरामीटर के साथ आउटपुट (आमतौर पर हानि कार्य) की गणना कैसे की जाए, और यदि GPU उपलब्ध है तो इसे GPU पर गणना के लिए धकेला जा सकता है। इस गणनात्मक ग्राफ को विभाजित करने और ग्रेडिएंट की गणना करने के लिए कार्य होते हैं, जिन्हें फिर मॉडल पैरामीटर के अनुकूलन के लिए उपयोग किया जा सकता है।

**उच्च-स्तरीय APIs** वास्तव में न्यूरल नेटवर्क को **परतों के अनुक्रम** के रूप में मानते हैं, और अधिकांश न्यूरल नेटवर्क को बनाना बहुत आसान बनाते हैं। मॉडल को प्रशिक्षित करने के लिए आमतौर पर डेटा तैयार करने की आवश्यकता होती है और फिर `fit` फ़ंक्शन को कार्य करने के लिए कॉल करना होता है।

उच्च-स्तरीय API आपको बहुत जल्दी सामान्य न्यूरल नेटवर्क बनाने की अनुमति देती है बिना कई विवरणों की चिंता किए। साथ ही, निम्न-स्तरीय API प्रशिक्षण प्रक्रिया पर अधिक नियंत्रण प्रदान करती हैं, और इस प्रकार उनका उपयोग अनुसंधान में बहुत अधिक किया जाता है, जब आप नए न्यूरल नेटवर्क आर्किटेक्चर के साथ काम कर रहे होते हैं।

यह भी महत्वपूर्ण है कि आप समझें कि आप दोनों APIs का एक साथ उपयोग कर सकते हैं, जैसे कि आप निम्न-स्तरीय API का उपयोग करके अपना खुद का नेटवर्क लेयर आर्किटेक्चर विकसित कर सकते हैं, और फिर इसे उच्च-स्तरीय API के साथ निर्मित और प्रशिक्षित बड़े नेटवर्क के अंदर उपयोग कर सकते हैं। या आप उच्च-स्तरीय API का उपयोग करके परतों के अनुक्रम के रूप में एक नेटवर्क परिभाषित कर सकते हैं, और फिर अपने स्वयं के निम्न-स्तरीय प्रशिक्षण लूप का उपयोग करके अनुकूलन कर सकते हैं। दोनों APIs समान मूलभूत अवधारणाओं का उपयोग करती हैं, और इन्हें एक साथ काम करने के लिए डिज़ाइन किया गया है।

## सीखना

इस पाठ्यक्रम में, हम PyTorch और TensorFlow दोनों के लिए अधिकांश सामग्री प्रदान करते हैं। आप अपनी पसंद का फ्रेमवर्क चुन सकते हैं और केवल संबंधित नोटबुक के माध्यम से जा सकते हैं। यदि आप सुनिश्चित नहीं हैं कि कौन सा फ्रेमवर्क चुनें, तो **PyTorch बनाम TensorFlow** के बारे में इंटरनेट पर कुछ चर्चाएँ पढ़ें। आप बेहतर समझ के लिए दोनों फ्रेमवर्क पर भी नज़र डाल सकते हैं।

जहाँ संभव हो, हम सरलता के लिए उच्च-स्तरीय APIs का उपयोग करेंगे। हालाँकि, हमें विश्वास है कि न्यूरल नेटवर्क के काम करने के तरीके को आधार से समझना महत्वपूर्ण है, इसलिए शुरुआत में हम निम्न-स्तरीय API और टेन्सरों के साथ काम करना शुरू करते हैं। हालाँकि, यदि आप जल्दी शुरू करना चाहते हैं और इन विवरणों को सीखने में बहुत अधिक समय नहीं बिताना चाहते हैं, तो आप उन्हें छोड़ सकते हैं और सीधे उच्च-स्तरीय API नोटबुक में जा सकते हैं।

## ✍️ व्यायाम: फ्रेमवर्क

निम्नलिखित नोटबुक में अपने अध्ययन को जारी रखें:

निम्न-स्तरीय API | [TensorFlow+Keras नोटबुक](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb) | [PyTorch](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb)
--------------|-------------------------------------|--------------------------------
उच्च-स्तरीय API| [Keras](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb) | *PyTorch Lightning*

फ्रेमवर्क में महारत हासिल करने के बाद, आइए ओवरफिटिंग की धारणा का पुनरावलोकन करें।

# ओवरफिटिंग

ओवरफिटिंग मशीन लर्निंग में एक अत्यंत महत्वपूर्ण अवधारणा है, और इसे सही तरीके से समझना बहुत महत्वपूर्ण है!

5 बिंदुओं (जो कि नीचे दिए गए ग्राफ़ पर `x` द्वारा दर्शाए गए हैं) का अनुमान लगाने की समस्या पर विचार करें:

![linear](../../../../../translated_images/overfit1.f24b71c6f652e59e6bed7245ffbeaecc3ba320e16e2221f6832b432052c4da43.hi.jpg) | ![overfit](../../../../../translated_images/overfit2.131f5800ae10ca5e41d12a411f5f705d9ee38b1b10916f284b787028dd55cc1c.hi.jpg)
-------------------------|--------------------------
**रेखीय मॉडल, 2 पैरामीटर** | **गैर-रेखीय मॉडल, 7 पैरामीटर**
प्रशिक्षण त्रुटि = 5.3 | प्रशिक्षण त्रुटि = 0
मान्यता त्रुटि = 5.1 | मान्यता त्रुटि = 20

* बाईं ओर, हम एक अच्छी सीधी रेखा का अनुमान देखते हैं। चूंकि पैरामीटर की संख्या उपयुक्त है, मॉडल बिंदुओं के वितरण के पीछे के विचार को सही तरीके से समझता है।
* दाईं ओर, मॉडल बहुत शक्तिशाली है। चूंकि हमारे पास केवल 5 बिंदु हैं और मॉडल के पास 7 पैरामीटर हैं, यह इस तरह से समायोजित हो सकता है कि सभी बिंदुओं के माध्यम से गुजरता है, जिससे प्रशिक्षण त्रुटि 0 हो जाती है। हालाँकि, यह मॉडल को डेटा के पीछे के सही पैटर्न को समझने से रोकता है, इसलिए मान्यता त्रुटि बहुत उच्च होती है।

मॉडल की समृद्धि (पैरामीटर की संख्या) और प्रशिक्षण नमूनों की संख्या के बीच सही संतुलन बनाना बहुत महत्वपूर्ण है।

## ओवरफिटिंग क्यों होती है

  * पर्याप्त प्रशिक्षण डेटा नहीं
  * बहुत शक्तिशाली मॉडल
  * इनपुट डेटा में बहुत अधिक शोर

## ओवरफिटिंग का पता कैसे लगाएं

जैसा कि आप ऊपर दिए गए ग्राफ से देख सकते हैं, ओवरफिटिंग को बहुत कम प्रशिक्षण त्रुटि और उच्च मान्यता त्रुटि द्वारा पहचाना जा सकता है। सामान्यतः प्रशिक्षण के दौरान हम देखेंगे कि प्रशिक्षण और मान्यता त्रुटियाँ दोनों कम होना शुरू होती हैं, और फिर किसी बिंदु पर मान्यता त्रुटि कम होना बंद कर सकती है और बढ़ने लग सकती है। यह ओवरफिटिंग का संकेत होगा, और यह संकेत है कि हमें शायद इस बिंदु पर प्रशिक्षण रोकना चाहिए (या कम से कम मॉडल का एक स्नैपशॉट लेना चाहिए)।

![overfitting](../../../../../translated_images/Overfitting.408ad91cd90b4371d0a81f4287e1409c359751adeb1ae450332af50e84f08c3e.hi.png)

## ओवरफिटिंग से कैसे बचें

यदि आप देख सकते हैं कि ओवरफिटिंग हो रही है, तो आप निम्नलिखित में से एक कर सकते हैं:

 * प्रशिक्षण डेटा की मात्रा बढ़ाएँ
 * मॉडल की जटिलता को कम करें
 * कुछ [नियमितीकरण तकनीक](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md) का उपयोग करें, जैसे [ड्रॉपआउट](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout), जिसे हम बाद में विचार करेंगे।

## ओवरफिटिंग और पूर्वाग्रह-भिन्नता व्यापार संतुलन

ओवरफिटिंग वास्तव में सांख्यिकी में एक अधिक सामान्य समस्या का मामला है जिसे [पूर्वाग्रह-भिन्नता व्यापार संतुलन](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) कहा जाता है। यदि हम अपने मॉडल में त्रुटियों के संभावित स्रोतों पर विचार करें, तो हम दो प्रकार की त्रुटियों को देख सकते हैं:

* **पूर्वाग्रह त्रुटियाँ** हमारे एल्गोरिदम द्वारा प्रशिक्षण डेटा के बीच संबंध को सही तरीके से कैप्चर न करने के कारण होती हैं। यह इस तथ्य के कारण हो सकता है कि हमारा मॉडल पर्याप्त शक्तिशाली नहीं है (**अंडरफिटिंग**)।
* **भिन्नता त्रुटियाँ**, जो मॉडल द्वारा इनपुट डेटा में शोर का अनुमान लगाने के कारण होती हैं, बजाय इसके कि अर्थपूर्ण संबंध (**ओवरफिटिंग**)।

प्रशिक्षण के दौरान, पूर्वाग्रह त्रुटि कम होती है (जैसे ही हमारा मॉडल डेटा का अनुमान लगाना सीखता है), और भिन्नता त्रुटि बढ़ती है। ओवरफिटिंग से बचने के लिए प्रशिक्षण को रोकना महत्वपूर्ण है - या तो मैन्युअल रूप से (जब हम ओवरफिटिंग का पता लगाते हैं) या स्वचालित रूप से (नियमितीकरण द्वारा)।

## निष्कर्ष

इस पाठ में, आपने TensorFlow और PyTorch के लिए विभिन्न APIs के बीच के अंतर के बारे में सीखा। इसके अलावा, आपने एक बहुत महत्वपूर्ण विषय, ओवरफिटिंग के बारे में सीखा।

## 🚀 चुनौती

संबंधित नोटबुक में, आपको नीचे 'कार्य' मिलेंगे; नोटबुक के माध्यम से काम करें और कार्यों को पूरा करें।

## [पोस्ट-लेचर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/205)

## समीक्षा और आत्म-अध्ययन

निम्नलिखित विषयों पर कुछ शोध करें:

- TensorFlow
- PyTorch
- ओवरफिटिंग

अपने आप से निम्नलिखित प्रश्न पूछें:

- TensorFlow और PyTorch के बीच क्या अंतर है?
- ओवरफिटिंग और अंडरफिटिंग के बीच क्या अंतर है?

## [असाइनमेंट](lab/README.md)

इस प्रयोगशाला में, आपसे PyTorch या TensorFlow का उपयोग करके एकल- और बहु-परत पूर्ण रूप से जुड़े नेटवर्क का उपयोग करके दो वर्गीकरण समस्याओं को हल करने के लिए कहा गया है।

* [निर्देश](lab/README.md)
* [नोटबुक](../../../../../lessons/3-NeuralNetworks/05-Frameworks/lab/LabFrameworks.ipynb)

**अस्वीकृति**:  
यह दस्तावेज़ मशीन आधारित एआई अनुवाद सेवाओं का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या असमानताएँ हो सकती हैं। मूल दस्तावेज़ को उसकी मूल भाषा में प्राधिकृत स्रोत के रूप में माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। हम इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए जिम्मेदार नहीं हैं।