# जनरेटिव एडेवर्सेरियल नेटवर्क्स

पिछले अनुभाग में, हमने **जनरेटिव मॉडल** के बारे में सीखा: ऐसे मॉडल जो प्रशिक्षण डेटा सेट में मौजूद छवियों के समान नई छवियां उत्पन्न कर सकते हैं। VAE एक अच्छे जनरेटिव मॉडल का उदाहरण था।

## [प्री-व्याख्यान क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

हालांकि, यदि हम वास्तव में अर्थपूर्ण कुछ उत्पन्न करने की कोशिश करते हैं, जैसे कि उचित संकल्प में एक पेंटिंग, VAE के साथ, हम देखेंगे कि प्रशिक्षण अच्छी तरह से संगठित नहीं होता है। इस उपयोग के मामले के लिए, हमें जनरेटिव मॉडल के लिए विशेष रूप से लक्षित एक और आर्किटेक्चर के बारे में सीखना चाहिए - **जनरेटिव एडेवर्सेरियल नेटवर्क्स**, या GANs।

GAN का मुख्य विचार दो न्यूरल नेटवर्क्स को एक-दूसरे के खिलाफ प्रशिक्षित करना है:

<img src="images/gan_architecture.png" width="70%"/>

> छवि द्वारा [Dmitry Soshnikov](http://soshnikov.com)

> ✅ थोड़ा शब्दावली:
> * **जनरेटर** एक नेटवर्क है जो कुछ यादृच्छिक वेक्टर लेता है, और परिणामस्वरूप छवि उत्पन्न करता है
> * **डिस्क्रिमिनेटर** एक नेटवर्क है जो एक छवि लेता है, और इसे बताना चाहिए कि यह एक वास्तविक छवि है (प्रशिक्षण डेटा सेट से), या इसे एक जनरेटर द्वारा उत्पन्न किया गया था। यह मूलतः एक छवि वर्गीकर्ता है।

### डिस्क्रिमिनेटर

डिस्क्रिमिनेटर की आर्किटेक्चर एक साधारण छवि वर्गीकरण नेटवर्क से भिन्न नहीं होती है। सबसे सरल मामले में, यह एक पूर्ण-सम्पर्कित वर्गीकर्ता हो सकता है, लेकिन संभावना है कि यह एक [संविधान नेटवर्क](../07-ConvNets/README.md) होगा।

> ✅ संविधान नेटवर्क पर आधारित GAN को [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) कहा जाता है

एक CNN डिस्क्रिमिनेटर निम्नलिखित परतों से बना होता है: कई संकुचन+पूलिंग (जो स्थानिक आकार में घटते हैं) और, एक या अधिक पूर्ण-संयोगित परतें "विशेषता वेक्टर" प्राप्त करने के लिए, अंतिम बाइनरी वर्गीकर्ता।

> ✅ इस संदर्भ में 'पूलिंग' एक तकनीक है जो छवि के आकार को कम करती है। "पूलिंग परतें डेटा के आयामों को एक परत में न्यूरॉन क्लस्टरों के आउटपुट को अगले परत में एकल न्यूरॉन में मिलाकर कम करती हैं।" - [स्रोत](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### जनरेटर

जनरेटर थोड़ा अधिक जटिल है। आप इसे एक विपरीत डिस्क्रिमिनेटर मान सकते हैं। एक लैटेंट वेक्टर (विशेषता वेक्टर के स्थान पर) से शुरू करते हुए, इसमें आवश्यक आकार/आकृति में परिवर्तित करने के लिए एक पूर्ण-संयोगित परत होती है, उसके बाद डीकंवोल्यूशन्स+अपस्केलिंग होती है। यह [ऑटोएन्कोडर](../09-Autoencoders/README.md) के *डिकोडर* भाग के समान है।

> ✅ चूंकि संविधान परत को छवि के पार करते हुए एक रैखिक फ़िल्टर के रूप में लागू किया गया है, डीकंवोल्यूशन मूलतः संविधान के समान है, और इसे उसी परत लॉजिक का उपयोग करके लागू किया जा सकता है।

<img src="images/gan_arch_detail.png" width="70%"/>

> छवि द्वारा [Dmitry Soshnikov](http://soshnikov.com)

### GAN को प्रशिक्षित करना

GAN को **एडेवर्सेरियल** कहा जाता है क्योंकि जनरेटर और डिस्क्रिमिनेटर के बीच एक निरंतर प्रतिस्पर्धा होती है। इस प्रतिस्पर्धा के दौरान, दोनों जनरेटर और डिस्क्रिमिनेटर में सुधार होता है, इस प्रकार नेटवर्क बेहतर और बेहतर चित्र उत्पन्न करना सीखता है।

प्रशिक्षण दो चरणों में होता है:

* **डिस्क्रिमिनेटर को प्रशिक्षित करना**। यह कार्य काफी सीधा है: हम जनरेटर द्वारा एक बैच छवियों का निर्माण करते हैं, उन्हें 0 लेबल करते हैं, जो नकली छवि का प्रतीक है, और इनपुट डेटा सेट से एक बैच छवियों का उपयोग करते हैं (जिसमें 1 लेबल, वास्तविक छवि)। हम कुछ *डिस्क्रिमिनेटर हानि* प्राप्त करते हैं, और बैकप्रॉप करते हैं।
* **जनरेटर को प्रशिक्षित करना**। यह थोड़ा अधिक जटिल है, क्योंकि हमें सीधे जनरेटर के लिए अपेक्षित आउटपुट नहीं पता है। हम एक जनरेटर के बाद डिस्क्रिमिनेटर से मिलकर बने पूरे GAN नेटवर्क को लेते हैं, इसे कुछ यादृच्छिक वेक्टरों से खिलाते हैं, और परिणाम की अपेक्षा करते हैं कि यह 1 हो (वास्तविक छवियों के लिए)। फिर हम डिस्क्रिमिनेटर के पैरामीटर को फ्रीज करते हैं (हम नहीं चाहते कि इसे इस चरण में प्रशिक्षित किया जाए), और बैकप्रॉप करते हैं।

इस प्रक्रिया के दौरान, जनरेटर और डिस्क्रिमिनेटर दोनों की हानियाँ महत्वपूर्ण रूप से नहीं घटती हैं। आदर्श स्थिति में, उन्हें दोनो नेटवर्क के प्रदर्शन में सुधार के अनुरूप झूलना चाहिए।

## ✍️ अभ्यास: GANs

* [TensorFlow/Keras में GAN नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorch में GAN नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN प्रशिक्षण के साथ समस्याएँ

GANs को प्रशिक्षित करना विशेष रूप से कठिन माना जाता है। यहाँ कुछ समस्याएँ हैं:

* **मोड पतन**। इस शब्द से हमारा तात्पर्य है कि जनरेटर एक सफल छवि उत्पन्न करना सीखता है जो डिस्क्रिमिनेटर को धोखा देती है, और न कि विभिन्न प्रकार की छवियों का उत्पादन करती है।
* **हाइपरपैरामीटर के प्रति संवेदनशीलता**। अक्सर आप देख सकते हैं कि एक GAN बिल्कुल संगठित नहीं होती है, और फिर अचानक सीखने की दर में कमी आ जाती है जो संगठित होने का परिणाम होती है।
* जनरेटर और डिस्क्रिमिनेटर के बीच **संतुलन** बनाए रखना। कई मामलों में, डिस्क्रिमिनेटर हानि अपेक्षाकृत जल्दी शून्य तक गिर सकती है, जिससे जनरेटर आगे प्रशिक्षित नहीं हो पाता। इसे पार करने के लिए, हम जनरेटर और डिस्क्रिमिनेटर के लिए अलग-अलग सीखने की दरें सेट करने का प्रयास कर सकते हैं, या यदि हानि पहले से ही बहुत कम है तो डिस्क्रिमिनेटर प्रशिक्षण छोड़ सकते हैं।
* **उच्च संकल्प** के लिए प्रशिक्षण। ऑटोएन्कोडर के साथ समान समस्या को दर्शाते हुए, यह समस्या इसलिए उत्पन्न होती है क्योंकि बहुत सारी परतों का पुनर्निर्माण करने से कलाकृतियाँ उत्पन्न होती हैं। इस समस्या का समाधान सामान्यतः **प्रगतिशील वृद्धि** के साथ किया जाता है, जब पहले कुछ परतें कम-रेस छवियों पर प्रशिक्षित होती हैं, और फिर परतें "अनलॉक" या जोड़ी जाती हैं। एक अन्य समाधान यह होगा कि परतों के बीच अतिरिक्त कनेक्शन जोड़े जाएं और एक साथ कई संकल्पों को प्रशिक्षित किया जाए - इसके विवरण के लिए इस [मल्टी-स्केल ग्रेडिएंट GANs पेपर](https://arxiv.org/abs/1903.06048) को देखें।

## शैली परिवर्तन

GANs कलात्मक छवियां उत्पन्न करने का एक शानदार तरीका है। एक और दिलचस्प तकनीक जिसे **शैली परिवर्तन** कहा जाता है, वह एक **सामग्री छवि** लेती है, और इसे एक अलग शैली में फिर से चित्रित करती है, **शैली छवि** से फ़िल्टर लागू करती है।

यह इस प्रकार काम करता है:
* हम एक यादृच्छिक शोर छवि (या एक सामग्री छवि के साथ, लेकिन समझने के लिए यह यादृच्छिक शोर से शुरू करना आसान है)
* हमारा लक्ष्य एक ऐसी छवि बनाना होगा, जो सामग्री छवि और शैली छवि के करीब हो। यह दो हानि कार्यों द्वारा निर्धारित किया जाएगा:
   - **सामग्री हानि** वर्तमान छवि और सामग्री छवि से कुछ परतों पर CNN द्वारा निकाले गए विशेषताओं के आधार पर गणना की जाती है
   - **शैली हानि** वर्तमान छवि और शैली छवि के बीच एक चतुर तरीके से गणना की जाती है, जिसमें ग्राम मैट्रिस का उपयोग किया जाता है (अधिक विवरण [उदाहरण नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) में)
* छवि को चिकना बनाने और शोर को हटाने के लिए, हम **वेरिएशन हानि** भी पेश करते हैं, जो पड़ोसी पिक्सेल के बीच औसत दूरी की गणना करती है
* मुख्य अनुकूलन लूप वर्तमान छवि को ग्रेडिएंट डिसेंट (या किसी अन्य अनुकूलन एल्गोरिदम) का उपयोग करके समायोजित करता है ताकि कुल हानि को न्यूनतम किया जा सके, जो तीन हानियों का एक भारित योग है।

## ✍️ उदाहरण: [शैली परिवर्तन](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [पोस्ट-व्याख्यान क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## निष्कर्ष

इस पाठ में, आपने GANs के बारे में सीखा और उन्हें कैसे प्रशिक्षित किया जाए। आपने इस प्रकार के न्यूरल नेटवर्क को जिन विशेष चुनौतियों का सामना करना पड़ सकता है, और उनसे पार पाने के कुछ रणनीतियों के बारे में भी सीखा।

## 🚀 चुनौती

अपने स्वयं के चित्रों का उपयोग करके [शैली परिवर्तन नोटबुक](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) पर जाएं।

## समीक्षा और आत्म-अध्ययन

संदर्भ के लिए, इन संसाधनों में GANs के बारे में अधिक पढ़ें:

* मार्को पासिनी, [10 पाठ जो मैंने एक वर्ष तक GANs को प्रशिक्षित करते समय सीखे](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), एक *de facto* GAN आर्किटेक्चर जिसे विचार करना है
* [Azure ML पर GANs का उपयोग करके जनरेटिव आर्ट बनाना](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## असाइनमेंट

इस पाठ से जुड़े दो नोटबुक में से एक पर पुनर्विचार करें और अपने स्वयं के चित्रों पर GAN को फिर से प्रशिक्षित करें। आप क्या बना सकते हैं?

**अस्वीकृति**:  
यह दस्तावेज़ मशीन आधारित एआई अनुवाद सेवाओं का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या गलतियाँ हो सकती हैं। मूल दस्तावेज़ को उसकी मूल भाषा में अधिकृत स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।