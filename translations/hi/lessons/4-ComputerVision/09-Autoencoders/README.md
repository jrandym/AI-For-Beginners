# ऑटोएन्कोडर्स

जब हम CNNs को प्रशिक्षित करते हैं, तो एक समस्या यह है कि हमें बहुत सारे लेबल वाले डेटा की आवश्यकता होती है। छवि वर्गीकरण के मामले में, हमें छवियों को विभिन्न श्रेणियों में विभाजित करने की आवश्यकता होती है, जो एक मैनुअल प्रयास है।

## [प्री-लेचर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

हालांकि, हम CNN फ़ीचर एक्सट्रैक्टर्स के लिए कच्चे (अनलेबल्ड) डेटा का उपयोग करना चाहते हैं, जिसे **सेल्फ-सुपरवाइज्ड लर्निंग** कहा जाता है। लेबल के बजाय, हम प्रशिक्षण छवियों का उपयोग नेटवर्क इनपुट और आउटपुट दोनों के रूप में करेंगे। **ऑटोएन्कोडर** का मुख्य विचार यह है कि हमारे पास एक **एन्कोडर नेटवर्क** होगा जो इनपुट छवि को कुछ **लेटेंट स्पेस** (सामान्यतः यह किसी छोटे आकार के वेक्टर के रूप में होता है) में परिवर्तित करता है, फिर **डिकोडर नेटवर्क**, जिसका लक्ष्य मूल छवि को पुनर्निर्माण करना होगा।

> ✅ एक [ऑटोएन्कोडर](https://wikipedia.org/wiki/Autoencoder) "एक प्रकार का कृत्रिम न्यूरल नेटवर्क है जिसका उपयोग अनलेबल्ड डेटा के कुशल कोडिंग सीखने के लिए किया जाता है।"

चूंकि हम एक ऑटोएन्कोडर को मूल छवि से अधिक से अधिक जानकारी को पकड़ने के लिए प्रशिक्षित कर रहे हैं ताकि सटीक पुनर्निर्माण हो सके, नेटवर्क इनपुट छवियों के सर्वोत्तम **एंबेडिंग** को पकड़ने का प्रयास करता है।

![AutoEncoder Diagram](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.hi.jpg)

> छवि [Keras ब्लॉग](https://blog.keras.io/building-autoencoders-in-keras.html) से

## ऑटोएन्कोडर्स के उपयोग के परिदृश्य

जबकि मूल छवियों को पुनर्निर्माण करना अपने आप में उपयोगी नहीं लगता, कुछ परिदृश्य हैं जहाँ ऑटोएन्कोडर्स विशेष रूप से उपयोगी हैं:

* **दृश्यता के लिए छवियों के आयाम को कम करना** या **छवि एंबेडिंग का प्रशिक्षण**। आमतौर पर ऑटोएन्कोडर्स PCA की तुलना में बेहतर परिणाम देते हैं, क्योंकि यह छवियों की स्थानिक प्रकृति और पदानुक्रमित विशेषताओं को ध्यान में रखता है।
* **डिनोइज़िंग**, अर्थात् छवि से शोर को हटाना। क्योंकि शोर बहुत सारी बेकार जानकारी ले जाता है, ऑटोएन्कोडर इसे अपेक्षाकृत छोटे लेटेंट स्पेस में समायोजित नहीं कर सकता है, और इस प्रकार यह छवि के केवल महत्वपूर्ण भाग को पकड़ता है। डिनोइज़र को प्रशिक्षित करते समय, हम मूल छवियों के साथ शुरू करते हैं, और ऑटोएन्कोडर के लिए इनपुट के रूप में कृत्रिम रूप से जोड़े गए शोर के साथ छवियों का उपयोग करते हैं।
* **सुपर-रेज़ोल्यूशन**, छवि की संकल्पना बढ़ाना। हम उच्च-रिज़ॉल्यूशन छवियों के साथ शुरू करते हैं, और ऑटोएन्कोडर इनपुट के रूप में कम रिज़ॉल्यूशन वाली छवि का उपयोग करते हैं।
* **जनरेटिव मॉडल**। एक बार जब हम ऑटोएन्कोडर को प्रशिक्षित कर लेते हैं, तो डिकोडर भाग का उपयोग नए ऑब्जेक्ट्स बनाने के लिए किया जा सकता है, जो यादृच्छिक लेटेंट वेक्टर से शुरू होता है।

## वेरिएशनल ऑटोएन्कोडर्स (VAE)

पारंपरिक ऑटोएन्कोडर इनपुट डेटा के आयाम को किसी न किसी तरह से कम करते हैं, इनपुट छवियों की महत्वपूर्ण विशेषताओं का पता लगाते हैं। हालाँकि, लेटेंट वेक्टर अक्सर ज्यादा मायने नहीं रखते। दूसरे शब्दों में, MNIST डेटासेट को उदाहरण के रूप में लेते हुए, यह पता लगाना कि कौन से अंकों का संबंध विभिन्न लेटेंट वेक्टर से है, एक आसान कार्य नहीं है, क्योंकि निकटतम लेटेंट वेक्टर आवश्यक रूप से समान अंकों से मेल नहीं खा सकते हैं।

दूसरी ओर, *जनरेटिव* मॉडल को प्रशिक्षित करने के लिए लेटेंट स्पेस की कुछ समझ होना बेहतर है। यह विचार हमें **वेरिएशनल ऑटो-एन्कोडर** (VAE) की ओर ले जाता है।

VAE वह ऑटोएन्कोडर है जो लेटेंट पैरामीटर के *आंकिक वितरण* की भविष्यवाणी करना सीखता है, जिसे **लेटेंट वितरण** कहा जाता है। उदाहरण के लिए, हम चाहते हैं कि लेटेंट वेक्टर सामान्य रूप से कुछ औसत z<sub>mean</sub> और मानक विचलन z<sub>sigma</sub> के साथ वितरित हों (दोनों औसत और मानक विचलन कुछ आयाम d के वेक्टर होते हैं)। VAE में एन्कोडर उन पैरामीटर की भविष्यवाणी करना सीखता है, और फिर डिकोडर इस वितरण से एक यादृच्छिक वेक्टर लेता है ताकि वस्तु को पुनर्निर्माण किया जा सके।

सारांश में:

 * इनपुट वेक्टर से, हम `z_mean` और `z_log_sigma` की भविष्यवाणी करते हैं (मानक विचलन की भविष्यवाणी करने के बजाय, हम इसके लॉगरिदम की भविष्यवाणी करते हैं)
 * हम वितरण N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>)) से एक वेक्टर `sample` का नमूना लेते हैं
 * डिकोडर मूल छवि को `sample` को इनपुट वेक्टर के रूप में उपयोग करके डिकोड करने का प्रयास करता है

 <img src="images/vae.png" width="50%">

> छवि [इस ब्लॉग पोस्ट](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) से है, जिसे इसाक डाइकमैन ने लिखा है

वेरिएशनल ऑटो-एन्कोडर्स एक जटिल हानि फ़ंक्शन का उपयोग करते हैं जो दो भागों में विभाजित होता है:

* **पुनर्निर्माण हानि** वह हानि फ़ंक्शन है जो यह दर्शाता है कि पुनर्निर्मित छवि लक्ष्य के कितनी करीब है (यह औसत वर्ग त्रुटि, या MSE हो सकता है)। यह सामान्य ऑटोएन्कोडर्स में वही हानि फ़ंक्शन है।
* **KL हानि**, जो सुनिश्चित करती है कि लेटेंट वेरिएबल वितरण सामान्य वितरण के करीब रहे। यह [Kullback-Leibler divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) के विचार पर आधारित है - एक मेट्रिक जो यह अनुमान लगाने के लिए है कि दो सांख्यिकीय वितरण कितने समान हैं।

VAEs का एक महत्वपूर्ण लाभ यह है कि वे हमें नए चित्रों को अपेक्षाकृत आसानी से उत्पन्न करने की अनुमति देते हैं, क्योंकि हम जानते हैं कि किस वितरण से लेटेंट वेक्टर का नमूना लेना है। उदाहरण के लिए, यदि हम MNIST पर 2D लेटेंट वेक्टर के साथ VAE को प्रशिक्षित करते हैं, तो हम विभिन्न अंकों को प्राप्त करने के लिए लेटेंट वेक्टर के घटकों को भिन्न कर सकते हैं:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> छवि [Dmitry Soshnikov](http://soshnikov.com) द्वारा

ध्यान दें कि छवियाँ एक-दूसरे में कैसे मिलती हैं, क्योंकि हम लेटेंट पैरामीटर स्पेस के विभिन्न भागों से लेटेंट वेक्टर प्राप्त करना शुरू करते हैं। हम इस स्पेस को 2D में भी दृश्य बना सकते हैं:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> छवि [Dmitry Soshnikov](http://soshnikov.com) द्वारा

## ✍️ व्यायाम: ऑटोएन्कोडर्स

ऑटोएन्कोडर्स के बारे में अधिक जानने के लिए इन संबंधित नोटबुक्स को देखें:

* [TensorFlow में ऑटोएन्कोडर्स](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [PyTorch में ऑटोएन्कोडर्स](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## ऑटोएन्कोडर्स के गुण

* **डेटा विशेष** - वे केवल उन प्रकार की छवियों के साथ अच्छी तरह से काम करते हैं जिन पर उन्हें प्रशिक्षित किया गया है। उदाहरण के लिए, यदि हम फूलों पर सुपर-रेज़ोल्यूशन नेटवर्क को प्रशिक्षित करते हैं, तो यह चित्रों पर अच्छी तरह से काम नहीं करेगा। इसका कारण यह है कि नेटवर्क प्रशिक्षण डेटासेट से सीखी गई विशेषताओं से बारीकियों को लेकर उच्च रिज़ॉल्यूशन छवि उत्पन्न कर सकता है।
* **हानिकारक** - पुनर्निर्मित छवि मूल छवि के समान नहीं होती है। हानि की प्रकृति उस *हानि फ़ंक्शन* द्वारा परिभाषित होती है जिसका उपयोग प्रशिक्षण के दौरान किया जाता है।
* **अनलेबल्ड डेटा** पर कार्य करता है।

## [पोस्ट-लेचर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## निष्कर्ष

इस पाठ में, आपने AI वैज्ञानिक के लिए उपलब्ध विभिन्न प्रकार के ऑटोएन्कोडर्स के बारे में सीखा। आपने उन्हें बनाना और छवियों को पुनर्निर्माण करने के लिए उनका उपयोग करना सीखा। आपने VAE के बारे में भी सीखा और इसे नए चित्र उत्पन्न करने के लिए कैसे उपयोग करना है।

## 🚀 चुनौती

इस पाठ में, आपने छवियों के लिए ऑटोएन्कोडर्स के उपयोग के बारे में सीखा। लेकिन उनका उपयोग संगीत के लिए भी किया जा सकता है! मैजेंटा प्रोजेक्ट के [MusicVAE](https://magenta.tensorflow.org/music-vae) प्रोजेक्ट पर जाएं, जो ऑटोएन्कोडर्स का उपयोग करके संगीत को पुनर्निर्माण करना सीखता है। इस पुस्तकालय के साथ कुछ [प्रयोग](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) करें ताकि आप देख सकें कि आप क्या बना सकते हैं।

## [पोस्ट-लेचर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## समीक्षा और आत्म-अध्ययन

संदर्भ के लिए, इन संसाधनों में ऑटोएन्कोडर्स के बारे में अधिक पढ़ें:

* [Keras में ऑटोएन्कोडर्स का निर्माण](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHive पर ब्लॉग पोस्ट](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [वेरिएशनल ऑटोएन्कोडर्स की व्याख्या की गई](https://kvfrans.com/variational-autoencoders-explained/)
* [कंडीशनल वेरिएशनल ऑटोएन्कोडर्स](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## असाइनमेंट

[इस नोटबुक का अंत TensorFlow का उपयोग करते हुए](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) आपको एक 'कार्य' मिलेगा - इसका उपयोग अपने असाइनमेंट के रूप में करें।

**अस्वीकृति**:  
यह दस्तावेज़ मशीन-आधारित एआई अनुवाद सेवाओं का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान रखें कि स्वचालित अनुवादों में त्रुटियाँ या गलतियाँ हो सकती हैं। मूल दस्तावेज़ को उसकी मातृ भाषा में प्राधिकृत स्रोत के रूप में माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।