# प्री-ट्रेंड नेटवर्क और ट्रांसफर लर्निंग

CNNs को प्रशिक्षित करना बहुत समय ले सकता है, और इसके लिए बहुत सारे डेटा की आवश्यकता होती है। हालांकि, अधिकांश समय सबसे अच्छे लो-लेवल फ़िल्टर सीखने में व्यतीत होता है, जिन्हें एक नेटवर्क छवियों से पैटर्न निकालने के लिए उपयोग कर सकता है। एक स्वाभाविक प्रश्न उठता है - क्या हम एक डेटा सेट पर प्रशिक्षित न्यूरल नेटवर्क का उपयोग कर सकते हैं और इसे विभिन्न छवियों को वर्गीकृत करने के लिए अनुकूलित कर सकते हैं बिना पूर्ण प्रशिक्षण प्रक्रिया की आवश्यकता के?

## [प्री-लेचर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

इस दृष्टिकोण को **ट्रांसफर लर्निंग** कहा जाता है, क्योंकि हम एक न्यूरल नेटवर्क मॉडल से दूसरे में कुछ ज्ञान स्थानांतरित करते हैं। ट्रांसफर लर्निंग में, हम आमतौर पर एक प्री-ट्रेंड मॉडल से शुरू करते हैं, जिसे किसी बड़े इमेज डेटा सेट, जैसे कि **ImageNet** पर प्रशिक्षित किया गया है। ये मॉडल पहले से ही सामान्य छवियों से विभिन्न विशेषताएँ निकालने में अच्छा काम कर सकते हैं, और कई मामलों में इन निकाली गई विशेषताओं के ऊपर एक क्लासिफायर बनाना अच्छा परिणाम दे सकता है।

> ✅ ट्रांसफर लर्निंग एक ऐसा शब्द है जिसे आप अन्य शैक्षणिक क्षेत्रों में पाएंगे, जैसे कि शिक्षा। यह एक डोमेन से ज्ञान लेने और उसे दूसरे पर लागू करने की प्रक्रिया को संदर्भित करता है।

## प्री-ट्रेंड मॉडल को फीचर एक्सट्रैक्टर्स के रूप में

पिछले अनुभाग में हमने जिन संवहन नेटवर्कों के बारे में बात की थी, उनमें कई परतें थीं, जिनमें से प्रत्येक को छवि से कुछ विशेषताएँ निकालने के लिए डिज़ाइन किया गया है, जो लो-लेवल पिक्सेल संयोजनों (जैसे क्षैतिज/ऊर्ध्वाधर रेखा या स्ट्रोक) से लेकर उच्च स्तर के संयोजनों तक होती हैं, जो एक लपट की आंख जैसी चीजों से संबंधित होती हैं। यदि हम CNN को सामान्य और विविध छवियों के पर्याप्त बड़े डेटा सेट पर प्रशिक्षित करते हैं, तो नेटवर्क उन सामान्य विशेषताओं को निकालना सीख जाएगा।

Keras और PyTorch दोनों में कुछ सामान्य आर्किटेक्चर के लिए प्री-ट्रेंड न्यूरल नेटवर्क वेट्स को आसानी से लोड करने के लिए फ़ंक्शन होते हैं, जिनमें से अधिकांश को ImageNet छवियों पर प्रशिक्षित किया गया था। सबसे अधिक उपयोग किए जाने वाले उन पर [CNN आर्किटेक्चर](../07-ConvNets/CNN_Architectures.md) पृष्ठ पर पिछले पाठ से वर्णित हैं। विशेष रूप से, आप निम्नलिखित में से एक का उपयोग करने पर विचार कर सकते हैं:

* **VGG-16/VGG-19**, जो अपेक्षाकृत सरल मॉडल हैं जो फिर भी अच्छी सटीकता देते हैं। अक्सर VGG का पहला प्रयास के रूप में उपयोग करना ट्रांसफर लर्निंग को देखने के लिए एक अच्छा विकल्प है।
* **ResNet** एक मॉडल परिवार है जिसे Microsoft Research द्वारा 2015 में प्रस्तावित किया गया था। इनमें अधिक परतें होती हैं, और इसलिए अधिक संसाधनों की आवश्यकता होती है।
* **MobileNet** एक मॉडल परिवार है जिसमें आकार कम होता है, जो मोबाइल उपकरणों के लिए उपयुक्त है। यदि आपके पास संसाधनों की कमी है और आप थोड़ी सटीकता बलिदान कर सकते हैं, तो इन्हें उपयोग करें।

यहां एक बिल्ली की तस्वीर से VGG-16 नेटवर्क द्वारा निकाली गई विशेषताओं के उदाहरण हैं:

![VGG-16 द्वारा निकाली गई विशेषताएँ](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.hi.png)

## बिल्लियाँ बनाम कुत्ते डेटा सेट

इस उदाहरण में, हम [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) का डेटा सेट उपयोग करेंगे, जो वास्तविक जीवन की छवि वर्गीकरण परिदृश्य के बहुत करीब है।

## ✍️ व्यायाम: ट्रांसफर लर्निंग

आइए ट्रांसफर लर्निंग को संबंधित नोटबुक में क्रियान्वित करते हैं:

* [Transfer Learning - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## प्रतिकूल बिल्ली का दृश्य

प्री-ट्रेंड न्यूरल नेटवर्क के अंदर इसके *मस्तिष्क* में विभिन्न पैटर्न होते हैं, जिसमें **आदर्श बिल्ली** (जैसे आदर्श कुत्ता, आदर्श ज़ेबरा, आदि) की धारणा शामिल होती है। इसे किसी तरह **इस छवि को दृश्य रूप में प्रदर्शित करना** दिलचस्प होगा। हालांकि, यह सरल नहीं है, क्योंकि पैटर्न नेटवर्क वेट्स में फैले हुए हैं, और एक पदानुक्रमिक संरचना में व्यवस्थित हैं।

हम जो दृष्टिकोण ले सकते हैं वह है एक यादृच्छिक छवि से शुरू करना, और फिर **ग्रेडिएंट डिसेंट ऑप्टिमाइजेशन** तकनीक का उपयोग करके उस छवि को इस तरह से समायोजित करना, कि नेटवर्क सोचने लगे कि यह एक बिल्ली है।

![छवि ऑप्टिमाइजेशन लूप](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.hi.png)

हालांकि, यदि हम ऐसा करते हैं, तो हमें कुछ ऐसा प्राप्त होगा जो यादृच्छिक शोर के बहुत करीब है। इसका कारण यह है कि *नेटवर्क को यह सोचने के कई तरीके हैं कि इनपुट छवि एक बिल्ली है*, जिनमें से कुछ दृश्य रूप से समझ में नहीं आते हैं। जबकि उन छवियों में बिल्ली के लिए विशिष्ट कई पैटर्न होते हैं, उन्हें दृश्य रूप से विशिष्ट बनाने के लिए कोई सीमा नहीं होती है।

परिणाम को सुधारने के लिए, हम हानि फ़ंक्शन में एक और पद जोड़ सकते हैं, जिसे **वेरिएशन लॉस** कहा जाता है। यह एक मीट्रिक है जो दिखाती है कि छवि के पड़ोसी पिक्सेल कितने समान हैं। वेरिएशन लॉस को न्यूनतम करने से छवि चिकनी होती है, और शोर को हटा देती है - जिससे अधिक दृश्य रूप से आकर्षक पैटर्न प्रकट होते हैं। यहां ऐसे "आदर्श" छवियों का एक उदाहरण है, जिन्हें बिल्ली और ज़ेबरा के रूप में उच्च संभावना के साथ वर्गीकृत किया गया है:

![आदर्श बिल्ली](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.hi.png) | ![आदर्श ज़ेबरा](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.hi.png)
-----|-----
 *आदर्श बिल्ली* | *आदर्श ज़ेबरा*

इसी तरह के दृष्टिकोण का उपयोग न्यूरल नेटवर्क पर **प्रतिकूल हमलों** को करने के लिए किया जा सकता है। मान लीजिए कि हम एक न्यूरल नेटवर्क को धोखा देना चाहते हैं और एक कुत्ते को बिल्ली की तरह दिखाना चाहते हैं। यदि हम कुत्ते की छवि लेते हैं, जिसे नेटवर्क द्वारा कुत्ते के रूप में पहचाना जाता है, तो हम इसे थोड़ा सा समायोजित कर सकते हैं, ग्रेडिएंट डिसेंट ऑप्टिमाइजेशन का उपयोग करके, जब तक कि नेटवर्क इसे बिल्ली के रूप में वर्गीकृत करना शुरू न कर दे:

![कुत्ते की तस्वीर](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.hi.png) | ![बिल्ली के रूप में वर्गीकृत कुत्ते की तस्वीर](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.hi.png)
-----|-----
*कुत्ते की मूल तस्वीर* | *बिल्ली के रूप में वर्गीकृत कुत्ते की तस्वीर*

ऊपर दिए गए परिणामों को पुन: उत्पन्न करने के लिए कोड देखें निम्नलिखित नोटबुक में:

* [आदर्श और प्रतिकूल बिल्ली - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## निष्कर्ष

ट्रांसफर लर्निंग का उपयोग करके, आप एक कस्टम ऑब्जेक्ट वर्गीकरण कार्य के लिए जल्दी से एक क्लासिफायर तैयार कर सकते हैं और उच्च सटीकता प्राप्त कर सकते हैं। आप देख सकते हैं कि अधिक जटिल कार्य जो हम अब हल कर रहे हैं, उन्हें उच्च गणनात्मक शक्ति की आवश्यकता होती है, और उन्हें CPU पर आसानी से हल नहीं किया जा सकता। अगले यूनिट में, हम एक अधिक हल्के कार्यान्वयन का उपयोग करने की कोशिश करेंगे ताकि समान मॉडल को कम गणना संसाधनों का उपयोग करके प्रशिक्षित किया जा सके, जिससे केवल थोड़ी कम सटीकता प्राप्त होती है।

## 🚀 चुनौती

संबंधित नोटबुक में, इस बारे में नोट्स हैं कि ट्रांसफर ज्ञान किस प्रकार के प्रशिक्षण डेटा के साथ सबसे अच्छा काम करता है (शायद एक नए प्रकार का जानवर)। पूरी तरह से नए प्रकार की छवियों के साथ कुछ प्रयोग करें ताकि देखें कि आपके ट्रांसफर ज्ञान मॉडल कैसे प्रदर्शन करते हैं।

## [पोस्ट-लेचर क्विज़](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## समीक्षा और आत्म-अध्ययन

अपने मॉडलों को प्रशिक्षित करने के कुछ अन्य तरीकों के ज्ञान को गहरा करने के लिए [TrainingTricks.md](TrainingTricks.md) को पढ़ें।

## [असाइनमेंट](lab/README.md)

इस प्रयोगशाला में, हम 35 नस्लों की बिल्लियों और कुत्तों के साथ वास्तविक जीवन के [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) पालतू डेटा सेट का उपयोग करेंगे, और हम एक ट्रांसफर लर्निंग क्लासिफायर बनाएंगे।

**अस्वीकृति**:  
यह दस्तावेज़ मशीन-आधारित एआई अनुवाद सेवाओं का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या असंगतताएँ हो सकती हैं। मूल दस्तावेज़ को उसकी मातृ भाषा में प्राधिकृत स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।