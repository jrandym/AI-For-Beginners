# K√§nnedomsigenk√§nning

Hittills har vi mest fokuserat p√• en NLP-uppgift - klassificering. Det finns dock √§ven andra NLP-uppgifter som kan utf√∂ras med neurala n√§tverk. En av dessa uppgifter √§r **[K√§nnedomsigenk√§nning](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), som handlar om att k√§nna igen specifika enheter inom text, s√•som platser, personnamn, datum- och tidsintervall, kemiska formler och s√• vidare.

## [F√∂rl√§sningsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/119)

## Exempel p√• att anv√§nda NER

Anta att du vill utveckla en naturlig spr√•k-chattbot, liknande Amazon Alexa eller Google Assistant. S√§ttet som intelligenta chattbotar fungerar p√• √§r att *f√∂rst√•* vad anv√§ndaren vill genom att g√∂ra textklassificering p√• den inmatade meningen. Resultatet av denna klassificering kallas **avsikt**, vilket avg√∂r vad en chattbot ska g√∂ra.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Bild av f√∂rfattaren

Men en anv√§ndare kan ange vissa parametrar som en del av frasen. Till exempel, n√§r hon fr√•gar efter v√§dret, kan hon specificera en plats eller ett datum. En bot b√∂r kunna f√∂rst√• dessa enheter och fylla i parameterplatserna i enlighet med detta innan den utf√∂r √•tg√§rden. Det √§r precis h√§r som NER kommer in.

> ‚úÖ Ett annat exempel skulle vara [analys av vetenskapliga medicinska artiklar](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). En av de viktigaste sakerna vi beh√∂ver leta efter √§r specifika medicinska termer, s√•som sjukdomar och medicinska √§mnen. Medan ett litet antal sjukdomar troligen kan extraheras med hj√§lp av delstr√§ngs√∂kning, beh√∂ver mer komplexa enheter, s√•som kemiska f√∂reningar och medicinernamn, en mer komplex metod.

## NER som tokenklassificering

NER-modeller √§r i grunden **tokenklassificeringsmodeller**, eftersom vi f√∂r varje inmatad token m√•ste avg√∂ra om den tillh√∂r en enhet eller inte, och om den g√∂r det - till vilken enhetsklass.

√ñverv√§g f√∂ljande artikelrubrik:

**Trikuspidalventilinsufficiens** och **litiumkarbonat** **toxicitet** hos ett nyf√∂tt barn.

Enheterna h√§r √§r:

* Trikuspidalventilinsufficiens √§r en sjukdom (`DIS`)
* Litiumkarbonat √§r ett kemiskt √§mne (`CHEM`)
* Toxicitet √§r ocks√• en sjukdom (`DIS`)

Observera att en enhet kan str√§cka sig √∂ver flera tokens. Och, som i detta fall, beh√∂ver vi s√§rskilja mellan tv√• p√• varandra f√∂ljande enheter. D√§rf√∂r √§r det vanligt att anv√§nda tv√• klasser f√∂r varje enhet - en som specificerar den f√∂rsta token av enheten (ofta anv√§nds `B-` prefixet, f√∂r **b**√∂rjan), och en annan - forts√§ttningen av en enhet (`I-`, f√∂r **i**nner token). Vi anv√§nder ocks√• `O` som en klass f√∂r att representera alla **o**tra tokens. S√•dan tokenm√§rkning kallas [BIO-m√§rkning](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (eller IOB). N√§r den √§r m√§rkt ser v√•r rubrik ut s√• h√§r:

Token | Tag
------|-----
Trikuspidal | B-DIS
ventil | I-DIS
insufficiens | I-DIS
och | O
litium | B-CHEM
karbonat | I-CHEM
toxicitet | B-DIS
hos | O
ett | O
nyf√∂tt | O
barn | O
. | O

Eftersom vi beh√∂ver bygga en en-till-en-koppling mellan tokens och klasser, kan vi tr√§na en h√∂gra **m√•nga-till-m√•nga** neurala n√§tverksmodell fr√•n denna bild:

![Bild som visar vanliga m√∂nster f√∂r √•terkommande neurala n√§tverk.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.sw.jpg)

> *Bild fr√•n [detta blogginl√§gg](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) av [Andrej Karpathy](http://karpathy.github.io/). NER-tokenklassificeringsmodeller motsvarar den h√∂gra n√§tverksarkitekturen p√• denna bild.*

## Tr√§ning av NER-modeller

Eftersom en NER-modell i grunden √§r en tokenklassificeringsmodell, kan vi anv√§nda RNN:er som vi redan √§r bekanta med f√∂r denna uppgift. I det h√§r fallet kommer varje block av det √•terkommande n√§tverket att returnera token-ID. Det f√∂ljande exempelnotebooket visar hur man tr√§nar LSTM f√∂r tokenklassificering.

## ‚úçÔ∏è Exempelnotebookar: NER

Forts√§tt ditt l√§rande i f√∂ljande notebook:

* [NER med TensorFlow](../../../../../lessons/5-NLP/19-NER/NER-TF.ipynb)

## Slutsats

En NER-modell √§r en **tokenklassificeringsmodell**, vilket inneb√§r att den kan anv√§ndas f√∂r att utf√∂ra tokenklassificering. Detta √§r en mycket vanlig uppgift inom NLP, som hj√§lper till att k√§nna igen specifika enheter inom text inklusive platser, namn, datum och mer.

## üöÄ Utmaning

Slutf√∂r uppgiften som l√§nkas nedan f√∂r att tr√§na en modell f√∂r k√§nnedomsigenk√§nning av medicinska termer, och prova sedan p√• en annan dataset.

## [Efterl√§sningsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/219)

## Granskning & Sj√§lvstudie

L√§s igenom bloggen [Den orimliga effektiviteten av √•terkommande neurala n√§tverk](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) och f√∂lj med i avsnittet F√∂rdjupad l√§sning i den artikeln f√∂r att f√∂rdjupa din kunskap.

## [Uppgift](lab/README.md)

I uppgiften f√∂r denna lektion kommer du att beh√∂va tr√§na en modell f√∂r medicinsk enhetsigenk√§nning. Du kan b√∂rja med att tr√§na en LSTM-modell som beskrivs i denna lektion, och forts√§tta med att anv√§nda BERT-transformermodellen. L√§s [instruktionerna](lab/README.md) f√∂r att f√• alla detaljer.

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av maskinbaserade AI-√∂vers√§ttningstj√§nster. √Ñven om vi str√§var efter noggrannhet, v√§nligen var medveten om att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• sitt modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r p√• grund av anv√§ndningen av denna √∂vers√§ttning.