# F√∂rtr√§nade N√§tverk och √ñverf√∂ringsinl√§rning

Att tr√§na CNN:er kan ta mycket tid, och en stor m√§ngd data kr√§vs f√∂r den uppgiften. Mycket av tiden g√•r √•t till att l√§ra sig de b√§sta l√•gniv√•filtrena som ett n√§tverk kan anv√§nda f√∂r att extrahera m√∂nster fr√•n bilder. En naturlig fr√•ga uppst√•r - kan vi anv√§nda ett neuralt n√§tverk som har tr√§nats p√• en dataset och anpassa det f√∂r att klassificera olika bilder utan att beh√∂va en fullst√§ndig tr√§ningsprocess?

## [F√∂r-f√∂rel√§sningsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Denna metod kallas **√∂verf√∂ringsinl√§rning**, eftersom vi √∂verf√∂r viss kunskap fr√•n en neuralt n√§tverksmodell till en annan. Vid √∂verf√∂ringsinl√§rning b√∂rjar vi vanligtvis med en f√∂rtr√§nad modell, som har tr√§nats p√• en stor bilddataset, s√•som **ImageNet**. Dessa modeller kan redan g√∂ra ett bra jobb med att extrahera olika egenskaper fr√•n generiska bilder, och i m√•nga fall kan det att bara bygga en klassificerare ovanp√• dessa extraherade egenskaper ge ett bra resultat.

> ‚úÖ √ñverf√∂ringsinl√§rning √§r ett begrepp som du hittar inom andra akademiska omr√•den, s√•som utbildning. Det h√§nvisar till processen att ta kunskap fr√•n ett omr√•de och till√§mpa den p√• ett annat.

## F√∂rtr√§nade Modeller som Funktionsextraktorer

De konvolutionella n√§tverken som vi har pratat om i den f√∂reg√•ende sektionen inneh√∂ll ett antal lager, d√§r varje lager √§r avsett att extrahera vissa egenskaper fr√•n bilden, som b√∂rjar med l√•gniv√•pixelkombinationer (s√•som horisontella/vertikala linjer eller streck), upp till h√∂gre niv√•kombinationer av egenskaper, motsvarande saker som ett √∂ga p√• en l√•ga. Om vi tr√§nar CNN p√• en tillr√§ckligt stor dataset av generiska och m√•ngsidiga bilder, b√∂r n√§tverket l√§ra sig att extrahera dessa gemensamma egenskaper.

B√•de Keras och PyTorch inneh√•ller funktioner f√∂r att enkelt ladda f√∂rtr√§nade neurala n√§tverksvikter f√∂r vissa vanliga arkitekturer, de flesta av vilka har tr√§nats p√• bilder fr√•n ImageNet. De mest anv√§nda beskrivs p√• sidan [CNN Arkitekturer](../07-ConvNets/CNN_Architectures.md) fr√•n den tidigare lektionen. Specifikt kan du √∂verv√§ga att anv√§nda en av f√∂ljande:

* **VGG-16/VGG-19** som √§r relativt enkla modeller som fortfarande ger bra noggrannhet. Att ofta anv√§nda VGG som ett f√∂rsta f√∂rs√∂k √§r ett bra val f√∂r att se hur √∂verf√∂ringsinl√§rning fungerar.
* **ResNet** √§r en familj av modeller som f√∂reslagits av Microsoft Research 2015. De har fler lager och tar d√§rf√∂r mer resurser.
* **MobileNet** √§r en familj av modeller med minskad storlek, l√§mpliga f√∂r mobila enheter. Anv√§nd dem om du har ont om resurser och kan offra lite noggrannhet.

H√§r √§r exempel p√• egenskaper som extraherats fr√•n en bild av en katt av VGG-16-n√§tverket:

![Egenskaper extraherade av VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.sw.png)

## Katter vs. Hundar Dataset

I det h√§r exemplet kommer vi att anv√§nda en dataset av [Katter och Hundar](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), som ligger mycket n√§ra ett verkligt bildklassificeringsscenario.

## ‚úçÔ∏è √ñvning: √ñverf√∂ringsinl√§rning

L√•t oss se √∂verf√∂ringsinl√§rning i praktiken i motsvarande anteckningsb√∂cker:

* [√ñverf√∂ringsinl√§rning - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [√ñverf√∂ringsinl√§rning - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Visualisering av Fiendens Katt

Det f√∂rtr√§nade neurala n√§tverket inneh√•ller olika m√∂nster inuti sin *hj√§rna*, inklusive begrepp om **ideal katt** (liksom ideal hund, ideal zebra, etc.). Det skulle vara intressant att p√• n√•got s√§tt **visualisera denna bild**. Det √§r dock inte enkelt, eftersom m√∂nster √§r spridda √∂ver n√§tverksvikterna och ocks√• organiserade i en hierarkisk struktur.

En metod vi kan anv√§nda √§r att b√∂rja med en slumpm√§ssig bild och sedan f√∂rs√∂ka anv√§nda **gradientnedstigningsoptimering** f√∂r att justera den bilden p√• ett s√§tt s√• att n√§tverket b√∂rjar tro att det √§r en katt.

![Bildoptimeringsloop](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.sw.png)

Men om vi g√∂r detta, kommer vi att f√• n√•got som liknar slumpm√§ssigt brus. Detta beror p√• att *det finns m√•nga s√§tt att f√• n√§tverket att tro att inmatningsbilden √§r en katt*, inklusive vissa som inte ger visuell mening. Medan dessa bilder inneh√•ller m√•nga m√∂nster som √§r typiska f√∂r en katt, finns det inget som begr√§nsar dem att vara visuellt distinkta.

F√∂r att f√∂rb√§ttra resultatet kan vi l√§gga till en annan term i f√∂rlustfunktionen, som kallas **variationsf√∂rlust**. Det √§r en metrisk som visar hur lika angr√§nsande pixlar i bilden √§r. Att minimera variationsf√∂rlust g√∂r bilden j√§mnare och blir av med brus - vilket avsl√∂jar mer visuellt tilltalande m√∂nster. H√§r √§r ett exempel p√• s√•dana "ideala" bilder, som klassificeras som katt och zebra med h√∂g sannolikhet:

![Ideal Katt](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.sw.png) | ![Ideal Zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.sw.png)
-----|-----
 *Ideal Katt* | *Ideal Zebra*

En liknande metod kan anv√§ndas f√∂r att utf√∂ra s√• kallade **fiendens attacker** p√• ett neuralt n√§tverk. Anta att vi vill lura ett neuralt n√§tverk och f√• en hund att se ut som en katt. Om vi tar en bild av en hund, som n√§tverket k√§nner igen som en hund, kan vi sedan justera den lite med hj√§lp av gradientnedstigningsoptimering, tills n√§tverket b√∂rjar klassificera den som en katt:

![Bild av en Hund](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.sw.png) | ![Bild av en hund klassificerad som en katt](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.sw.png)
-----|-----
*Originalbild av en hund* | *Bild av en hund klassificerad som en katt*

Se koden f√∂r att √•terskapa resultaten ovan i f√∂ljande anteckningsbok:

* [Ideal och Fiendens Katt - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## Slutsats

Genom att anv√§nda √∂verf√∂ringsinl√§rning kan du snabbt s√§tta ihop en klassificerare f√∂r en anpassad objektklassificeringsuppgift och uppn√• h√∂g noggrannhet. Du kan se att mer komplexa uppgifter som vi l√∂ser nu kr√§ver h√∂gre ber√§kningskraft och inte enkelt kan l√∂sas p√• CPU:n. I n√§sta enhet kommer vi att f√∂rs√∂ka anv√§nda en mer l√§ttviktsimplementation f√∂r att tr√§na samma modell med l√§gre ber√§kningsresurser, vilket resulterar i n√•got l√§gre noggrannhet.

## üöÄ Utmaning

I de medf√∂ljande anteckningsb√∂ckerna finns det anteckningar i botten om hur √∂verf√∂rd kunskap fungerar b√§st med n√•got liknande tr√§ningsdata (kanske en ny typ av djur). G√∂r n√•gra experiment med helt nya typer av bilder f√∂r att se hur bra eller d√•ligt dina √∂verf√∂rda kunskapsmodeller presterar.

## [Efter-f√∂rel√§sningsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Granskning & Sj√§lvstudie

L√§s igenom [TrainingTricks.md](TrainingTricks.md) f√∂r att f√∂rdjupa din kunskap om n√•gra andra s√§tt att tr√§na dina modeller.

## [Uppgift](lab/README.md)

I detta labb kommer vi att anv√§nda verkliga [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) husdjursdataset med 35 raser av katter och hundar, och vi kommer att bygga en √∂verf√∂ringsinl√§rningsklassificerare.

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av maskinbaserade AI-√∂vers√§ttningstj√§nster. √Ñven om vi str√§var efter noggrannhet, v√§nligen var medveten om att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• sitt modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r till f√∂ljd av anv√§ndningen av denna √∂vers√§ttning.