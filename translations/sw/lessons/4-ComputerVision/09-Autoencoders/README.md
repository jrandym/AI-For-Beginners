# Autoencoders

N√§r vi tr√§nar CNN:er √§r ett av problemen att vi beh√∂ver mycket m√§rkt data. N√§r det g√§ller bildklassificering beh√∂ver vi separera bilder i olika klasser, vilket √§r en manuell insats.

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Vi kan dock vilja anv√§nda r√• (om√§rkt) data f√∂r att tr√§na CNN-funktionsextraktorer, vilket kallas **sj√§lv√∂vervakad inl√§rning**. Ist√§llet f√∂r etiketter kommer vi att anv√§nda tr√§ningsbilder som b√•de n√§tverksinmatning och utdata. Huvudid√©n med **autoencoder** √§r att vi kommer att ha ett **encoder-n√§tverk** som konverterar inmatad bild till ett visst **latent rum** (normalt √§r det bara en vektor av mindre storlek), och sedan **decoder-n√§tverket**, vars m√•l √§r att rekonstruera den ursprungliga bilden.

> ‚úÖ En [autoencoder](https://wikipedia.org/wiki/Autoencoder) √§r "en typ av artificiellt neuralt n√§tverk som anv√§nds f√∂r att l√§ra sig effektiva kodningar av om√§rkt data."

Eftersom vi tr√§nar en autoencoder f√∂r att f√•nga s√• mycket information som m√∂jligt fr√•n den ursprungliga bilden f√∂r noggrann rekonstruktion, f√∂rs√∂ker n√§tverket hitta den b√§sta **inb√§ddningen** av inmatade bilder f√∂r att f√•nga betydelsen.

![AutoEncoder Diagram](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.sw.jpg)

> Bild fr√•n [Keras blog](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenarier f√∂r anv√§ndning av Autoencoders

√Ñven om rekonstruktion av ursprungliga bilder inte verkar anv√§ndbart i sig, finns det n√•gra scenarier d√§r autoencoders √§r s√§rskilt anv√§ndbara:

* **Minska dimensionen av bilder f√∂r visualisering** eller **tr√§ning av bildeinb√§ddningar**. Vanligtvis ger autoencoders b√§ttre resultat √§n PCA, eftersom de tar h√§nsyn till den spatiala naturen hos bilder och hierarkiska funktioner.
* **Denoising**, dvs. ta bort brus fr√•n bilden. Eftersom brus b√§r med sig mycket oanv√§ndbar information kan autoencodern inte passa in allt i det relativt lilla latenta rummet, och f√•ngar d√§rf√∂r endast den viktiga delen av bilden. N√§r vi tr√§nar avbrusare b√∂rjar vi med ursprungliga bilder och anv√§nder bilder med artificiellt tillagt brus som indata f√∂r autoencodern.
* **Super-uppl√∂sning**, √∂ka bildens uppl√∂sning. Vi b√∂rjar med h√∂guppl√∂sta bilder och anv√§nder bilder med l√§gre uppl√∂sning som autoencoder-inmatning.
* **Generativa modeller**. N√§r vi har tr√§nat autoencodern kan decoder-delen anv√§ndas f√∂r att skapa nya objekt utifr√•n slumpm√§ssiga latenta vektorer.

## Variational Autoencoders (VAE)

Traditionella autoencoders minskar dimensionen av indata p√• n√•got s√§tt, genom att identifiera de viktiga funktionerna i inmatade bilder. Latenta vektorer ger dock ofta inte mycket mening. Med andra ord, med MNIST-datasetet som exempel, √§r det inte en l√§tt uppgift att ta reda p√• vilka siffror som motsvarar olika latenta vektorer, eftersom n√§ra latenta vektorer inte n√∂dv√§ndigtvis motsvarar samma siffror.

√Ö andra sidan, f√∂r att tr√§na *generativa* modeller √§r det b√§ttre att ha en viss f√∂rst√•else f√∂r det latenta rummet. Denna id√© leder oss till **variational autoencoder** (VAE).

VAE √§r autoencodern som l√§r sig att f√∂ruts√§ga *statistisk f√∂rdelning* av de latenta parametrarna, s√• kallad **latent f√∂rdelning**. Till exempel kan vi vilja att latenta vektorer ska f√∂rdelas normalt med ett visst medelv√§rde z<sub>mean</sub> och standardavvikelse z<sub>sigma</sub> (b√•de medelv√§rde och standardavvikelse √§r vektorer av viss dimension d). Encodern i VAE l√§r sig att f√∂ruts√§ga dessa parametrar, och sedan tar decodern en slumpm√§ssig vektor fr√•n denna f√∂rdelning f√∂r att rekonstruera objektet.

Sammanfattningsvis:

 * Fr√•n inmatad vektor f√∂rutsp√•r vi `z_mean` och `z_log_sigma` (ist√§llet f√∂r att f√∂ruts√§ga standardavvikelsen sj√§lv, f√∂rutsp√•r vi dess logaritm)
 * Vi sampel en vektor `sample` fr√•n f√∂rdelningen N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Decodern f√∂rs√∂ker avkoda den ursprungliga bilden med `sample` som inmatad vektor

 <img src="images/vae.png" width="50%">

> Bild fr√•n [denna blogginl√§gg](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) av Isaak Dykeman

Variational autoencoders anv√§nder en komplex f√∂rlustfunktion som best√•r av tv√• delar:

* **Rekonstruktionsf√∂rlust** √§r f√∂rlustfunktionen som visar hur n√§ra en rekonstruerad bild √§r m√•let (det kan vara Mean Squared Error, eller MSE). Det √§r samma f√∂rlustfunktion som i vanliga autoencoders.
* **KL-f√∂rlust**, som s√§kerst√§ller att de latenta variabelns f√∂rdelningar f√∂rblir n√§ra normalf√∂rdelningen. Den baseras p√• begreppet [Kullback-Leibler divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - en metrik f√∂r att uppskatta hur lika tv√• statistiska f√∂rdelningar √§r.

En viktig f√∂rdel med VAEs √§r att de g√∂r det m√∂jligt f√∂r oss att generera nya bilder relativt enkelt, eftersom vi vet vilken f√∂rdelning vi ska sampela latenta vektorer fr√•n. Om vi till exempel tr√§nar en VAE med 2D latent vektor p√• MNIST kan vi sedan variera komponenterna i den latenta vektorn f√∂r att f√• olika siffror:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Bild av [Dmitry Soshnikov](http://soshnikov.com)

Observera hur bilderna blandar sig med varandra, n√§r vi b√∂rjar f√• latenta vektorer fr√•n olika delar av det latenta parameterrummet. Vi kan ocks√• visualisera detta rum i 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Bild av [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è √ñvningar: Autoencoders

L√§r dig mer om autoencoders i dessa motsvarande anteckningar:

* [Autoencoders i TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Autoencoders i PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Egenskaper hos Autoencoders

* **Dataspecifika** - de fungerar bara bra med den typ av bilder de har tr√§nats p√•. Om vi till exempel tr√§nar ett super-uppl√∂sningsn√§tverk p√• blommor kommer det inte att fungera bra p√• portr√§tt. Detta beror p√• att n√§tverket kan producera h√∂guppl√∂sta bilder genom att ta fina detaljer fr√•n funktioner som l√§rts fr√•n tr√§ningsdatasetet.
* **F√∂rlustiga** - den rekonstruerade bilden √§r inte densamma som den ursprungliga bilden. F√∂rlustens natur definieras av *f√∂rlustfunktionen* som anv√§nds under tr√§ning.
* Fungerar p√• **om√§rkt data**.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Slutsats

I denna lektion l√§rde du dig om de olika typerna av autoencoders som finns tillg√§ngliga f√∂r AI-forskaren. Du l√§rde dig hur man bygger dem och hur man anv√§nder dem f√∂r att rekonstruera bilder. Du l√§rde dig ocks√• om VAE och hur man anv√§nder den f√∂r att generera nya bilder.

## üöÄ Utmaning

I denna lektion l√§rde du dig om att anv√§nda autoencoders f√∂r bilder. Men de kan ocks√• anv√§ndas f√∂r musik! Kolla in Magenta-projektets [MusicVAE](https://magenta.tensorflow.org/music-vae) projekt, som anv√§nder autoencoders f√∂r att l√§ra sig rekonstruera musik. G√∂r n√•gra [experiment](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) med detta bibliotek f√∂r att se vad du kan skapa.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Granskning & Sj√§lvstudie

F√∂r referens, l√§s mer om autoencoders i dessa resurser:

* [Bygga Autoencoders i Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blogginl√§gg om NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [F√∂rklarade Variational Autoencoders](https://kvfrans.com/variational-autoencoders-explained/)
* [Villkorliga Variational Autoencoders](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Uppgift

I slutet av [denna anteckning som anv√§nder TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) hittar du en 'uppgift' - anv√§nd detta som din uppgift.

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av maskinbaserade AI-√∂vers√§ttningstj√§nster. √Ñven om vi str√§var efter noggrannhet, v√§nligen var medveten om att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• sitt modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r fr√•n anv√§ndningen av denna √∂vers√§ttning.