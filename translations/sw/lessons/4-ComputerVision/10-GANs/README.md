# Generativa Motst√•ndsn√§tverk

I den f√∂reg√•ende sektionen l√§rde vi oss om **generativa modeller**: modeller som kan skapa nya bilder som liknar de i tr√§ningsdatasetet. VAE var ett bra exempel p√• en generativ modell.

## [F√∂rl√§sningsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Men om vi f√∂rs√∂ker skapa n√•got verkligt meningsfullt, som en m√•lning med rimlig uppl√∂sning, med VAE, kommer vi att se att tr√§ningen inte konvergerar bra. F√∂r detta anv√§ndningsfall b√∂r vi l√§ra oss om en annan arkitektur som √§r specifikt inriktad p√• generativa modeller - **Generativa Motst√•ndsn√§tverk**, eller GANs.

Huvudid√©n med en GAN √§r att ha tv√• neurala n√§tverk som kommer att tr√§nas mot varandra:

<img src="images/gan_architecture.png" width="70%"/>

> Bild av [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Lite vokabul√§r:
> * **Generator** √§r ett n√§tverk som tar en slumpm√§ssig vektor och producerar en bild som resultat
> * **Diskriminator** √§r ett n√§tverk som tar en bild och ska avg√∂ra om det √§r en verklig bild (fr√•n tr√§ningsdatasetet) eller om den har genererats av en generator. Det √§r i grunden en bildklassificerare.

### Diskriminator

Arkitekturen f√∂r diskriminatorn skiljer sig inte fr√•n ett vanligt bildklassificeringsn√§tverk. I det enklaste fallet kan det vara en fullt ansluten klassificerare, men mest sannolikt kommer det att vara ett [konvolutionellt n√§tverk](../07-ConvNets/README.md).

> ‚úÖ En GAN baserad p√• konvolutionella n√§tverk kallas en [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

En CNN-diskriminator best√•r av f√∂ljande lager: flera konvolutioner+pooling (med minskande spatial storlek) och ett eller flera fullt anslutna lager f√∂r att f√• "funktionsvektor", slutlig bin√§r klassificerare.

> ‚úÖ En 'pooling' i detta sammanhang √§r en teknik som minskar storleken p√• bilden. "Pooling-lager minskar dimensionerna av data genom att kombinera utg√•ngarna fr√•n neuronkluster i ett lager till en enda neuron i n√§sta lager." - [k√§lla](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

En generator √§r n√•got mer komplicerad. Du kan betrakta den som en omv√§nd diskriminator. Med utg√•ngspunkt fr√•n en latent vektor (i st√§llet f√∂r en funktionsvektor), har den ett fullt anslutet lager f√∂r att omvandla det till den erforderliga storleken/formen, f√∂ljt av dekonvolutioner+uppskalning. Detta liknar *avkodar* delen av [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Eftersom konvolutionslagret implementeras som ett linj√§rt filter som r√∂r sig √∂ver bilden, √§r dekonvolution i grunden liknande konvolution och kan implementeras med samma lagerlogik.

<img src="images/gan_arch_detail.png" width="70%"/>

> Bild av [Dmitry Soshnikov](http://soshnikov.com)

### Tr√§ning av GAN

GANs kallas **motst√•ndsn√§tverk** eftersom det finns en konstant t√§vling mellan generatorn och diskriminatorn. Under denna t√§vling f√∂rb√§ttras b√•de generatorn och diskriminatorn, vilket g√∂r att n√§tverket l√§r sig att producera b√§ttre och b√§ttre bilder.

Tr√§ningen sker i tv√• steg:

* **Tr√§ning av diskriminatorn**. Denna uppgift √§r ganska rak p√• sak: vi genererar en batch av bilder med generatorn, m√§rker dem med 0, som st√•r f√∂r falsk bild, och tar en batch av bilder fr√•n inmatningsdatasetet (med etikett 1, verklig bild). Vi f√•r en viss *diskriminatorf√∂rlust* och utf√∂r backprop.
* **Tr√§ning av generatorn**. Detta √§r n√•got mer komplicerat, eftersom vi inte vet det f√∂rv√§ntade resultatet f√∂r generatorn direkt. Vi tar hela GAN-n√§tverket best√•ende av en generator f√∂ljd av en diskriminator, matar in den med n√•gra slumpm√§ssiga vektorer och f√∂rv√§ntar oss att resultatet ska vara 1 (som motsvarar verkliga bilder). Vi fryser sedan parametrarna f√∂r diskriminatorn (vi vill inte att den ska tr√§nas i detta steg) och utf√∂r backprop.

Under denna process minskar varken generatorns eller diskriminatorns f√∂rluster signifikant. I den ideala situationen b√∂r de oscillera, vilket motsvarar att b√•da n√§tverken f√∂rb√§ttrar sin prestanda.

## ‚úçÔ∏è √ñvningar: GANs

* [GAN Notebook i TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [GAN Notebook i PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Problem med GAN-tr√§ning

GANs √§r k√§nda f√∂r att vara s√§rskilt sv√•ra att tr√§na. H√§r √§r n√•gra problem:

* **Mode Collapse**. Med denna term menar vi att generatorn l√§r sig att producera en framg√•ngsrik bild som lurar diskriminatorn, och inte en variation av olika bilder.
* **K√§nslighet f√∂r hyperparametrar**. Ofta kan du se att en GAN inte konvergerar alls, och pl√∂tsligt minskar inl√§rningshastigheten vilket leder till konvergens.
* Att h√•lla en **balans** mellan generatorn och diskriminatorn. I m√•nga fall kan diskriminatorf√∂rlusten snabbt sjunka till noll, vilket resulterar i att generatorn inte kan tr√§nas vidare. F√∂r att √∂vervinna detta kan vi f√∂rs√∂ka s√§tta olika inl√§rningshastigheter f√∂r generatorn och diskriminatorn, eller hoppa √∂ver tr√§ningen av diskriminatorn om f√∂rlusten redan √§r f√∂r l√•g.
* Tr√§ning f√∂r **h√∂g uppl√∂sning**. Detta problem speglar samma problem som med autoencoders, och utl√∂ses eftersom rekonstruktionen av f√∂r m√•nga lager i det konvolutionella n√§tverket leder till artefakter. Detta problem l√∂ses vanligtvis med s√• kallad **progressiv tillv√§xt**, d√§r f√∂rst n√•gra lager tr√§nas p√• l√•guppskattade bilder, och sedan lager "avblockeras" eller l√§ggs till. En annan l√∂sning skulle vara att l√§gga till extra kopplingar mellan lager och tr√§na flera uppl√∂sningar samtidigt - se detta [Multi-Scale Gradient GANs-papper](https://arxiv.org/abs/1903.06048) f√∂r detaljer.

## Stil√∂verf√∂ring

GANs √§r ett utm√§rkt s√§tt att generera konstn√§rliga bilder. En annan intressant teknik √§r s√• kallad **stil√∂verf√∂ring**, som tar en **inneh√•llsbild** och √•tertecknar den i en annan stil, genom att applicera filter fr√•n **stilbilden**.

S√• h√§r fungerar det:
* Vi b√∂rjar med en slumpm√§ssig brusbild (eller med en inneh√•llsbild, men f√∂r att f√∂rst√• det √§r det l√§ttare att b√∂rja med slumpm√§ssigt brus)
* V√•rt m√•l √§r att skapa en bild som ligger n√§ra b√•de inneh√•llsbilden och stilbilden. Detta skulle best√§mmas av tv√• f√∂rlustfunktioner:
   - **Inneh√•llsf√∂rlust** ber√§knas baserat p√• de funktioner som extraherats av CNN vid vissa lager fr√•n den aktuella bilden och inneh√•llsbilden
   - **Stilf√∂rlust** ber√§knas mellan den aktuella bilden och stilbilden p√• ett smart s√§tt med hj√§lp av Gram-matriser (mer detaljer i [exempelnotebooken](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb))
* F√∂r att g√∂ra bilden j√§mnare och ta bort brus introducerar vi ocks√• **Variationsf√∂rlust**, som ber√§knar det genomsnittliga avst√•ndet mellan n√§rliggande pixlar
* Den huvudsakliga optimeringsloopen justerar den aktuella bilden med hj√§lp av gradientnedstigning (eller n√•got annat optimeringsalgoritm) f√∂r att minimera den totala f√∂rlusten, som √§r en viktad summa av alla tre f√∂rluster. 

## ‚úçÔ∏è Exempel: [Stil√∂verf√∂ring](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Efterl√§sningsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Slutsats

I den h√§r lektionen l√§rde du dig om GANs och hur man tr√§nar dem. Du l√§rde dig ocks√• om de speciella utmaningar som denna typ av neuralt n√§tverk kan m√∂ta, och n√•gra strategier f√∂r hur man kan √∂vervinna dem.

## üöÄ Utmaning

G√• igenom [Stil√∂verf√∂ringsnotebooken](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) med dina egna bilder.

## Granskning & Sj√§lvstudier

F√∂r referens, l√§s mer om GANs i dessa resurser:

* Marco Pasini, [10 Lektioner Jag L√§rde Mig N√§r Jag Tr√§nade GANs i Ett √Ör](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), en *de facto* GAN-arkitektur att √∂verv√§ga
* [Skapa Generativ Konst med GANs p√• Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Uppgift

√Öterbes√∂k en av de tv√• notebookar som √§r kopplade till denna lektion och tr√§na GAN p√• dina egna bilder. Vad kan du skapa?

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av maskinbaserade AI-√∂vers√§ttningstj√§nster. √Ñven om vi str√§var efter noggrannhet, b√∂r du vara medveten om att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• sitt modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r till f√∂ljd av anv√§ndningen av denna √∂vers√§ttning.