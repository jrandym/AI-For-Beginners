> 이미지 제공: [Dmitry Soshnikov](http://soshnikov.com)

시간이 지나면서 컴퓨팅 자원이 저렴해지고 더 많은 데이터가 제공됨에 따라, 신경망 접근 방식은 컴퓨터 비전이나 음성 인식과 같은 여러 분야에서 인간과 경쟁하는 뛰어난 성능을 보여주기 시작했습니다. 지난 10년 동안, 인공지능이라는 용어는 주로 신경망의 동의어로 사용되었으며, 우리가 듣는 대부분의 인공지능 성공 사례는 신경망에 기반하고 있습니다.

체스 프로그램을 만드는 접근 방식이 어떻게 변화했는지 관찰할 수 있습니다:

* 초기 체스 프로그램은 탐색 기반으로, 프로그램이 주어진 수의 다음 수에 대해 상대방의 가능한 수를 추정하려고 명시적으로 시도하고, 몇 수 내에 달성할 수 있는 최적의 위치를 바탕으로 최적의 수를 선택했습니다. 이로 인해 [알파-베타 가지치기](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) 탐색 알고리즘이 개발되었습니다.
* 탐색 전략은 게임이 끝날 무렵, 가능한 수가 적은 경우에 잘 작동합니다. 그러나 게임 시작 시 탐색 공간은 방대하며, 알고리즘은 인간 플레이어 간의 기존 경기에서 학습하여 개선할 수 있습니다. 이후 실험에서는 [사례 기반 추론](https://en.wikipedia.org/wiki/Case-based_reasoning)을 사용하여 프로그램이 현재 게임의 위치와 매우 유사한 사례를 지식 기반에서 찾도록 했습니다.
* 현대 프로그램은 신경망과 [강화 학습](https://en.wikipedia.org/wiki/Reinforcement_learning)을 기반으로 하며, 프로그램은 스스로와 오랜 시간 동안 대국을 하며 자신의 실수로부터 학습합니다. 이는 인간이 체스를 배우는 방식과 유사합니다. 그러나 컴퓨터 프로그램은 훨씬 더 많은 게임을 짧은 시간에 플레이할 수 있으므로 훨씬 더 빠르게 학습할 수 있습니다.

✅ AI가 플레이한 다른 게임에 대해 조금 조사해 보세요.

유사하게, "대화 프로그램"을 만드는 접근 방식이 어떻게 변화했는지 볼 수 있습니다(튜링 테스트를 통과할 수 있는 프로그램):

* 초기 프로그램인 [엘리자](https://en.wikipedia.org/wiki/ELIZA)와 같은 프로그램은 매우 간단한 문법 규칙과 입력 문장을 질문으로 재구성하는 방식에 기반했습니다.
* 현대의 어시스턴트인 Cortana, Siri, Google Assistant는 모두 음성을 텍스트로 변환하고 우리의 의도를 인식하기 위해 신경망을 사용하며, 필요한 작업을 수행하기 위해 일부 추론이나 명시적 알고리즘을 사용합니다.
* 앞으로는 완전한 신경망 기반 모델이 스스로 대화를 처리할 것으로 예상됩니다. 최근의 GPT 및 [Turing-NLG](https://turing.microsoft.com/) 신경망 가족은 이 분야에서 큰 성공을 보여주고 있습니다.

> 이미지 제공: Dmitry Soshnikov, [사진](https://unsplash.com/photos/r8LmVbUKgns) 제공: [Marina Abrosimova](https://unsplash.com/@abrosimova_marina_foto), Unsplash

## 최근 AI 연구

신경망 연구의 최근 큰 성장은 2010년경에 시작되었으며, 대규모 공개 데이터 세트가 제공되기 시작했습니다. 약 1400만 개의 주석이 달린 이미지로 구성된 [ImageNet](https://en.wikipedia.org/wiki/ImageNet)이라는 방대한 이미지 컬렉션은 [ImageNet 대규모 시각 인식 챌린지](https://image-net.org/challenges/LSVRC/)의 출발점이 되었습니다.

![ILSVRC 정확도](../../../../lessons/1-Intro/images/ilsvrc.gif)

> 이미지 제공: [Dmitry Soshnikov](http://soshnikov.com)
2012년, [합성곱 신경망](../4-ComputerVision/07-ConvNets/README.md)이 이미지 분류에 처음 사용되었으며, 이로 인해 분류 오류가 크게 감소했습니다(거의 30%에서 16.4%로). 2015년, Microsoft Research의 ResNet 아키텍처가 [인간 수준의 정확도](https://doi.org/10.1109/ICCV.2015.123)를 달성했습니다.

그 이후로, 신경망은 많은 작업에서 매우 성공적인 성과를 보여주었습니다:

---

연도 | 인간 수준의 성과
-----|--------
2015 | [이미지 분류](https://doi.org/10.1109/ICCV.2015.123)
2016 | [대화형 음성 인식](https://arxiv.org/abs/1610.05256)
2018 | [자동 기계 번역](https://arxiv.org/abs/1803.05567) (중국어-영어)
2020 | [이미지 캡셔닝](https://arxiv.org/abs/2009.13682)

지난 몇 년 동안 우리는 BERT와 GPT-3와 같은 대형 언어 모델에서 엄청난 성공을 목격했습니다. 이는 모델이 텍스트의 구조와 의미를 포착할 수 있도록 훈련할 수 있는 많은 일반 텍스트 데이터가 존재하기 때문입니다. 일반 텍스트 컬렉션에서 사전 훈련을 한 후, 이러한 모델을 보다 구체적인 작업에 맞게 특화할 수 있습니다. 이 과정에서 [자연어 처리](../5-NLP/README.md)에 대해 더 배우게 될 것입니다.

## 🚀 도전 과제

인터넷을 탐색하여 AI가 가장 효과적으로 사용되는 곳이 어디인지 여러분의 의견을 결정해 보세요. 지도 앱, 음성 인식 서비스, 아니면 비디오 게임일까요? 시스템이 어떻게 구축되었는지 조사해 보세요.

## [강의 후 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/201)

## 복습 및 자기 학습

[이 수업](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/2-history-of-ML)을 읽어보며 AI와 ML의 역사를 복습해 보세요. 그 수업이나 이 수업의 스케치 노트에서 요소 하나를 선택하여 그 진화에 영향을 미친 문화적 맥락을 이해하기 위해 더 깊이 연구해 보세요.

**과제**: [게임 잼](assignment.md)

**면책 조항**:  
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만, 자동 번역에는 오류나 부정확성이 있을 수 있음을 유의하시기 바랍니다. 원본 문서는 해당 언어로 된 권위 있는 자료로 간주되어야 합니다. 중요한 정보에 대해서는 전문적인 인간 번역을 권장합니다. 이 번역의 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 우리는 책임을 지지 않습니다.