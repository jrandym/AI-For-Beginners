# 윤리적이고 책임 있는 AI

이 과정을 거의 마치셨습니다. 이제 AI가 데이터에서 관계를 찾고 인간 행동의 일부 측면을 복제하는 모델을 훈련할 수 있도록 하는 여러 가지 공식적인 수학적 방법에 기반하고 있다는 것을 분명히 이해하고 계시리라 기대합니다. 현재 시점에서 우리는 AI를 데이터에서 패턴을 추출하고 이러한 패턴을 사용하여 새로운 문제를 해결하는 데 매우 강력한 도구로 간주하고 있습니다.

## [강의 전 퀴즈](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

그러나 공상 과학 소설에서는 AI가 인류에 위험을 초래하는 이야기를 자주 접하게 됩니다. 일반적으로 이러한 이야기는 AI가 인간에 맞서기로 결정하는 일종의 AI 반란을 중심으로 진행됩니다. 이는 AI가 어떤 형태의 감정을 가지고 있거나 개발자가 예측하지 못한 결정을 내릴 수 있다는 것을 암시합니다.

이 과정에서 배운 AI는 대규모 행렬 산술에 불과합니다. 이는 문제를 해결하는 데 도움을 주는 매우 강력한 도구이며, 다른 강력한 도구와 마찬가지로 선한 목적과 악한 목적 모두에 사용될 수 있습니다. 중요한 것은 *오용될 수 있다는 점*입니다.

## 책임 있는 AI의 원칙

AI의 우발적 또는 의도적인 오용을 피하기 위해 Microsoft는 중요한 [책임 있는 AI 원칙](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste)을 제시합니다. 이러한 원칙은 다음과 같은 개념에 기초합니다:

* **공정성**은 *모델 편향*이라는 중요한 문제와 관련이 있습니다. 이는 훈련을 위한 편향된 데이터를 사용할 때 발생할 수 있습니다. 예를 들어, 특정 개인이 소프트웨어 개발자 직업을 얻을 확률을 예측하려 할 때, 모델은 남성에게 더 높은 선호를 줄 가능성이 높습니다. 이는 훈련 데이터셋이 남성 청중에게 편향되어 있었기 때문입니다. 우리는 훈련 데이터를 신중하게 조정하고 모델을 조사하여 편향을 피하고, 모델이 더 관련성 있는 특성을 고려하도록 해야 합니다.
* **신뢰성과 안전성**. AI 모델은 본질적으로 실수를 할 수 있습니다. 신경망은 확률을 반환하며, 결정을 내릴 때 이를 고려해야 합니다. 모든 모델은 일정한 정확도와 재현율을 가지며, 우리는 잘못된 조언이 초래할 수 있는 피해를 방지하기 위해 이를 이해해야 합니다.
* **프라이버시와 보안**은 AI에 특화된 몇 가지 함의를 가지고 있습니다. 예를 들어, 모델 훈련에 일부 데이터를 사용할 때, 이 데이터는 어떤 식으로든 모델에 "통합"됩니다. 한편으로는 보안과 프라이버시를 증가시키지만, 다른 한편으로는 모델이 어떤 데이터로 훈련되었는지를 기억해야 합니다.
* **포용성**은 AI를 사람을 대체하기 위해 구축하는 것이 아니라, 사람을 보완하고 우리의 작업을 더 창의적으로 만들기 위해 구축한다는 것을 의미합니다. 이는 공정성과도 관련이 있습니다. 왜냐하면 대표성이 부족한 커뮤니티를 다룰 때, 우리가 수집하는 대부분의 데이터셋은 편향될 가능성이 높으며, 이러한 커뮤니티가 AI에 의해 포함되고 올바르게 처리되도록 해야 하기 때문입니다.
* **투명성**. 이는 AI가 사용되고 있다는 점을 항상 명확히 해야 함을 포함합니다. 또한 가능할 경우, 우리는 *해석 가능한* AI 시스템을 사용하고자 합니다.
* **책임성**. AI 모델이 어떤 결정을 내릴 때, 이러한 결정에 대한 책임이 누구에게 있는지는 항상 명확하지 않습니다. 우리는 AI 결정의 책임이 어디에 있는지를 이해해야 합니다. 대부분의 경우, 우리는 중요한 결정을 내리는 과정에 인간을 포함시켜 실제 사람들이 책임을 지도록 하고자 합니다.

## 책임 있는 AI를 위한 도구

Microsoft는 [책임 있는 AI 툴박스](https://github.com/microsoft/responsible-ai-toolbox)를 개발했습니다. 이 툴박스에는 다음과 같은 도구가 포함되어 있습니다:

* 해석 가능성 대시보드 (InterpretML)
* 공정성 대시보드 (FairLearn)
* 오류 분석 대시보드
* 책임 있는 AI 대시보드에는 다음이 포함됩니다:

   - EconML - 원인 분석 도구로, "무엇일까" 질문에 중점을 둡니다.
   - DiCE - 반사실적 분석 도구로, 모델의 결정에 영향을 주기 위해 어떤 특성을 변경해야 하는지를 보여줍니다.

AI 윤리에 대한 더 많은 정보를 원하신다면, 과제도 포함된 [이 수업](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste)을 방문해 주십시오.

## 복습 및 자기 학습

책임 있는 AI에 대해 더 배우고 싶다면 이 [학습 경로](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste)를 따라가 보세요.

## [강의 후 퀴즈](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**면책 조항**:  
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있음을 유의하시기 바랍니다. 원본 문서는 해당 언어로 작성된 권위 있는 출처로 간주되어야 합니다. 중요한 정보에 대해서는 전문 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해서는 책임을 지지 않습니다.