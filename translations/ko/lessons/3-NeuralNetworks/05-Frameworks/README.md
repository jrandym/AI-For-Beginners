# 신경망 프레임워크

우리가 이미 배운 바와 같이, 신경망을 효율적으로 학습시키기 위해서는 두 가지를 해야 합니다:

* 텐서에서 연산을 수행해야 합니다. 예를 들어, 곱셈, 덧셈, 그리고 시그모이드나 소프트맥스와 같은 함수 계산을 해야 합니다.
* 경량화 최적화를 수행하기 위해 모든 표현의 기울기를 계산해야 합니다.

## [강의 전 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/105)

`numpy` 라이브러리는 첫 번째 작업을 수행할 수 있지만, 기울기를 계산하기 위한 메커니즘이 필요합니다. 우리가 이전 섹션에서 개발한 [우리의 프레임워크](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb)에서는 `backward` 메서드 내부에 모든 미분 함수를 수동으로 프로그래밍해야 했습니다. 이는 역전파를 수행합니다. 이상적으로는, 프레임워크가 우리가 정의할 수 있는 *모든 표현*의 기울기를 계산할 수 있는 기회를 제공해야 합니다.

또한 중요한 것은 GPU나 [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)와 같은 다른 전문 계산 장치에서 계산을 수행할 수 있어야 한다는 것입니다. 심층 신경망 학습은 *많은* 계산을 요구하며, 이러한 계산을 GPU에서 병렬화할 수 있는 것이 매우 중요합니다.

> ✅ '병렬화'라는 용어는 여러 장치에 계산을 분산하는 것을 의미합니다.

현재 가장 인기 있는 두 가지 신경망 프레임워크는 [TensorFlow](http://TensorFlow.org)와 [PyTorch](https://pytorch.org/)입니다. 두 프레임워크 모두 CPU와 GPU에서 텐서를 다루기 위한 저수준 API를 제공합니다. 저수준 API 위에는 각각 [Keras](https://keras.io/)와 [PyTorch Lightning](https://pytorchlightning.ai/)이라는 고수준 API도 있습니다.

저수준 API | [TensorFlow](http://TensorFlow.org) | [PyTorch](https://pytorch.org/)
--------------|-------------------------------------|--------------------------------
고수준 API | [Keras](https://keras.io/) | [PyTorch Lightning](https://pytorchlightning.ai/)

**두 프레임워크의 저수준 API**는 소위 **계산 그래프**를 구축할 수 있게 해줍니다. 이 그래프는 주어진 입력 매개변수로 출력(보통 손실 함수)을 계산하는 방법을 정의하며, GPU에서 계산할 수 있도록 푸시할 수 있습니다. 이 계산 그래프를 미분하고 기울기를 계산하는 함수가 있으며, 이는 모델 매개변수를 최적화하는 데 사용될 수 있습니다.

**고수준 API**는 신경망을 **레이어의 시퀀스**로 간주하며, 대부분의 신경망을 훨씬 쉽게 구성할 수 있게 해줍니다. 모델 학습은 보통 데이터를 준비한 다음 `fit` 함수를 호출하여 작업을 수행하는 것을 요구합니다.

고수준 API를 사용하면 많은 세부사항에 대해 걱정하지 않고 전형적인 신경망을 매우 빠르게 구축할 수 있습니다. 동시에 저수준 API는 학습 과정에 대한 더 많은 제어를 제공하므로, 새로운 신경망 아키텍처를 다룰 때 연구에서 많이 사용됩니다.

두 API를 함께 사용할 수 있다는 점도 중요합니다. 예를 들어, 저수준 API를 사용하여 자신의 네트워크 레이어 아키텍처를 개발한 다음, 고수준 API로 구성하고 학습한 더 큰 네트워크 내에서 사용할 수 있습니다. 또는 고수준 API를 사용하여 레이어의 시퀀스로 네트워크를 정의한 후, 자신의 저수준 학습 루프를 사용하여 최적화를 수행할 수 있습니다. 두 API는 동일한 기본 개념을 사용하며, 잘 작동하도록 설계되었습니다.

## 학습

이 과정에서는 PyTorch와 TensorFlow 모두에 대한 대부분의 내용을 제공합니다. 선호하는 프레임워크를 선택하고 해당 노트북만 진행할 수 있습니다. 어떤 프레임워크를 선택할지 확실하지 않은 경우, **PyTorch vs. TensorFlow**에 대한 인터넷의 논의를 읽어보세요. 두 프레임워크를 모두 살펴보면 더 나은 이해를 얻을 수 있습니다.

가능한 경우 단순함을 위해 고수준 API를 사용할 것입니다. 그러나 신경망이 어떻게 작동하는지를 기초부터 이해하는 것이 중요하다고 생각하므로, 처음에는 저수준 API와 텐서를 사용하여 작업을 시작합니다. 하지만 빠르게 진행하고 싶고 이러한 세부 사항을 배우는 데 많은 시간을 소비하고 싶지 않다면, 해당 내용을 건너뛰고 고수준 API 노트북으로 바로 들어갈 수 있습니다.

## ✍️ 연습: 프레임워크

다음 노트북에서 학습을 계속하세요:

저수준 API | [TensorFlow+Keras 노트북](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb) | [PyTorch](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb)
--------------|-------------------------------------|--------------------------------
고수준 API | [Keras](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb) | *PyTorch Lightning*

프레임워크를 마스터한 후, 과적합의 개념을 요약해 보겠습니다.

# 과적합

과적합은 머신러닝에서 매우 중요한 개념이며, 이를 올바르게 이해하는 것이 매우 중요합니다!

다음 문제를 고려해 보세요: 5개의 점(아래 그래프의 `x`로 표시)을 근사하는 문제입니다:

![linear](../../../../../translated_images/overfit1.f24b71c6f652e59e6bed7245ffbeaecc3ba320e16e2221f6832b432052c4da43.ko.jpg) | ![overfit](../../../../../translated_images/overfit2.131f5800ae10ca5e41d12a411f5f705d9ee38b1b10916f284b787028dd55cc1c.ko.jpg)
-------------------------|--------------------------
**선형 모델, 2개의 매개변수** | **비선형 모델, 7개의 매개변수**
훈련 오류 = 5.3 | 훈련 오류 = 0
검증 오류 = 5.1 | 검증 오류 = 20

* 왼쪽에서는 좋은 직선 근사를 볼 수 있습니다. 매개변수의 수가 적절하기 때문에, 모델은 점 분포의 아이디어를 올바르게 이해합니다.
* 오른쪽에서는 모델이 너무 강력합니다. 점이 5개뿐인데 모델이 7개의 매개변수를 가지고 있어 모든 점을 통과하도록 조정할 수 있습니다. 이로 인해 훈련 오류는 0이 됩니다. 그러나 이는 모델이 데이터 뒤에 있는 올바른 패턴을 이해하지 못하게 하여 검증 오류가 매우 높아집니다.

모델의 풍부함(매개변수의 수)과 훈련 샘플의 수 사이에서 올바른 균형을 찾는 것이 매우 중요합니다.

## 과적합이 발생하는 이유

* 훈련 데이터가 충분하지 않음
* 모델이 너무 강력함
* 입력 데이터에 노이즈가 너무 많음

## 과적합을 감지하는 방법

위 그래프에서 볼 수 있듯이, 과적합은 매우 낮은 훈련 오류와 높은 검증 오류로 감지할 수 있습니다. 일반적으로 훈련 중에는 훈련 오류와 검증 오류가 모두 감소하기 시작하며, 그 후 어느 시점에서 검증 오류가 더 이상 감소하지 않고 증가하기 시작할 수 있습니다. 이는 과적합의 신호이며, 이 시점에서 훈련을 중단해야 할지도 모른다는 지표입니다(또는 최소한 모델의 스냅샷을 만들어야 합니다).

![overfitting](../../../../../translated_images/Overfitting.408ad91cd90b4371d0a81f4287e1409c359751adeb1ae450332af50e84f08c3e.ko.png)

## 과적합을 방지하는 방법

과적합이 발생하는 것을 볼 수 있다면, 다음 중 하나를 수행할 수 있습니다:

* 훈련 데이터의 양을 늘리기
* 모델의 복잡성 줄이기
* [정규화 기법](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md) 사용하기, 예를 들어 [드롭아웃](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout)과 같은 기법을 나중에 고려할 것입니다.

## 과적합과 편향-분산 균형

과적합은 통계에서 더 일반적인 문제인 [편향-분산 균형](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)의 경우입니다. 모델의 가능한 오류 원인을 고려하면 두 가지 유형의 오류를 볼 수 있습니다:

* **편향 오류**는 알고리즘이 훈련 데이터 간의 관계를 올바르게 포착하지 못해서 발생합니다. 이는 모델이 충분히 강력하지 않기 때문에 발생할 수 있습니다 (**과소적합**).
* **분산 오류**는 모델이 입력 데이터의 노이즈를 근사화하는 대신 의미 있는 관계를 포착하는 데서 발생합니다 (**과적합**).

훈련 중에는 편향 오류가 감소하고(모델이 데이터를 근사화하는 방법을 학습하면서), 분산 오류는 증가합니다. 과적합을 방지하기 위해 훈련을 중단하는 것이 중요합니다 - 수동으로(과적합을 감지할 때) 또는 자동으로(정규화를 도입하여) 중단할 수 있습니다.

## 결론

이번 수업에서는 TensorFlow와 PyTorch라는 두 가지 가장 인기 있는 AI 프레임워크에 대한 다양한 API의 차이점에 대해 배웠습니다. 또한 매우 중요한 주제인 과적합에 대해서도 배웠습니다.

## 🚀 도전

동반 노트북에서 하단에 '작업'을 찾을 수 있습니다; 노트북을 통해 작업을 완료하세요.

## [강의 후 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/205)

## 복습 및 자가 학습

다음 주제에 대해 연구해 보세요:

- TensorFlow
- PyTorch
- 과적합

다음 질문을 스스로에게 해보세요:

- TensorFlow와 PyTorch의 차이점은 무엇인가요?
- 과적합과 과소적합의 차이점은 무엇인가요?

## [과제](lab/README.md)

이번 실습에서는 PyTorch 또는 TensorFlow를 사용하여 단일 및 다층 완전 연결 네트워크를 이용한 두 가지 분류 문제를 해결해야 합니다.

* [지침](lab/README.md)
* [노트북](../../../../../lessons/3-NeuralNetworks/05-Frameworks/lab/LabFrameworks.ipynb)

**면책 조항**:  
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있음을 유의하시기 바랍니다. 원본 문서는 해당 언어로 된 권위 있는 출처로 간주되어야 합니다. 중요한 정보에 대해서는 전문적인 인간 번역을 권장합니다. 이 번역의 사용으로 인해 발생하는 오해나 잘못된 해석에 대해서는 저희가 책임지지 않습니다.