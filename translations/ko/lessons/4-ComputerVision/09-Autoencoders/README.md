# 오토인코더

CNN을 훈련할 때의 문제 중 하나는 많은 레이블이 있는 데이터가 필요하다는 것입니다. 이미지 분류의 경우, 이미지를 서로 다른 클래스로 분리해야 하며, 이는 수동적인 작업입니다.

## [강의 전 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

하지만 CNN 특징 추출기를 훈련하기 위해 원시(레이블이 없는) 데이터를 사용하고 싶을 수도 있습니다. 이를 **자기 지도 학습**이라고 합니다. 레이블 대신, 우리는 훈련 이미지를 네트워크의 입력과 출력으로 사용합니다. **오토인코더**의 주요 아이디어는 입력 이미지를 어떤 **잠재 공간**(보통은 더 작은 크기의 벡터)으로 변환하는 **인코더 네트워크**가 있고, 원래 이미지를 재구성하는 것을 목표로 하는 **디코더 네트워크**가 있다는 것입니다.

> ✅ [오토인코더](https://wikipedia.org/wiki/Autoencoder)는 "레이블이 없는 데이터의 효율적인 코딩을 학습하기 위해 사용되는 인공 신경망의 일종입니다."

우리는 원래 이미지에서 가능한 한 많은 정보를 캡처하기 위해 오토인코더를 훈련하고 있으므로, 네트워크는 의미를 포착하기 위해 입력 이미지의 최상의 **임베딩**을 찾으려고 합니다.

![AutoEncoder Diagram](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ko.jpg)

> 이미지 출처: [Keras 블로그](https://blog.keras.io/building-autoencoders-in-keras.html)

## 오토인코더 사용 시나리오

원래 이미지를 재구성하는 것이 그 자체로는 유용해 보이지 않지만, 오토인코더가 특히 유용한 몇 가지 시나리오가 있습니다:

* **시각화를 위한 이미지 차원 축소** 또는 **이미지 임베딩 훈련**. 일반적으로 오토인코더는 PCA보다 더 나은 결과를 제공합니다. 왜냐하면 이미지의 공간적 특성과 계층적 특징을 고려하기 때문입니다.
* **노이즈 제거**, 즉 이미지에서 노이즈를 제거하는 것입니다. 노이즈는 많은 쓸모없는 정보를 담고 있기 때문에, 오토인코더는 이를 상대적으로 작은 잠재 공간에 모두 맞출 수 없으며, 따라서 이미지의 중요한 부분만 캡처합니다. 노이즈 제거기를 훈련할 때, 우리는 원래 이미지를 시작으로 하고, 인위적으로 추가된 노이즈가 있는 이미지를 오토인코더의 입력으로 사용합니다.
* **슈퍼 해상도**, 이미지 해상도 증가. 우리는 고해상도 이미지를 시작으로 하고, 낮은 해상도의 이미지를 오토인코더 입력으로 사용합니다.
* **생성 모델**. 오토인코더를 훈련한 후, 디코더 부분을 사용하여 임의의 잠재 벡터에서 새로운 객체를 생성할 수 있습니다.

## 변분 오토인코더 (VAE)

전통적인 오토인코더는 입력 데이터의 차원을 줄이면서 입력 이미지의 중요한 특징을 파악합니다. 그러나 잠재 벡터는 종종 그다지 의미가 없습니다. 예를 들어, MNIST 데이터셋을 예로 들면, 서로 다른 잠재 벡터에 해당하는 숫자를 파악하는 것은 쉬운 일이 아닙니다. 왜냐하면 가까운 잠재 벡터가 반드시 같은 숫자에 해당하지는 않기 때문입니다.

반면에 *생성적* 모델을 훈련하기 위해서는 잠재 공간에 대한 어느 정도의 이해가 필요합니다. 이 아이디어는 **변분 오토인코더**(VAE)로 이어집니다.

VAE는 잠재 매개변수의 *통계적 분포*를 예측하는 방법을 배우는 오토인코더로, 이를 **잠재 분포**라고 합니다. 예를 들어, 우리는 잠재 벡터가 평균 z<sub>mean</sub>과 표준 편차 z<sub>sigma</sub>를 가지며 정규 분포를 이루기를 원할 수 있습니다(평균과 표준 편차 모두 어떤 차원 d의 벡터입니다). VAE의 인코더는 이러한 매개변수를 예측하는 방법을 배우고, 그런 다음 디코더는 이 분포에서 임의의 벡터를 가져와 객체를 재구성합니다.

요약하자면:

 * 입력 벡터에서 `z_mean` 및 `z_log_sigma`를 예측합니다(표준 편차 자체를 예측하는 대신, 그 로그를 예측합니다).
 * 분포 N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))에서 벡터 `sample`를 샘플링합니다.
 * 디코더는 `sample`를 입력 벡터로 사용하여 원래 이미지를 디코딩하려고 합니다.

 <img src="images/vae.png" width="50%">

> 이미지 출처: [이 블로그 포스트](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) by Isaak Dykeman

변분 오토인코더는 두 부분으로 구성된 복잡한 손실 함수를 사용합니다:

* **재구성 손실**은 재구성된 이미지가 목표와 얼마나 가까운지를 나타내는 손실 함수입니다(평균 제곱 오차(MSE)일 수 있습니다). 이것은 일반 오토인코더와 동일한 손실 함수입니다.
* **KL 손실**은 잠재 변수 분포가 정규 분포에 가깝도록 보장합니다. 이는 두 통계적 분포가 얼마나 유사한지를 추정하는 메트릭인 [쿨백-라이블러 발산](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)에 기반합니다.

VAE의 중요한 장점 중 하나는 잠재 벡터를 샘플링할 분포를 알기 때문에 상대적으로 쉽게 새로운 이미지를 생성할 수 있다는 것입니다. 예를 들어, MNIST에서 2D 잠재 벡터로 VAE를 훈련시키면, 잠재 벡터의 구성 요소를 변화시켜 다양한 숫자를 얻을 수 있습니다:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> 이미지 출처: [Dmitry Soshnikov](http://soshnikov.com)

이미지가 서로 섞여 들어가는 모습을 관찰하세요. 잠재 매개변수 공간의 서로 다른 부분에서 잠재 벡터를 가져오기 시작할 때입니다. 우리는 또한 이 공간을 2D로 시각화할 수 있습니다:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> 이미지 출처: [Dmitry Soshnikov](http://soshnikov.com)

## ✍️ 연습: 오토인코더

오토인코더에 대해 더 알아보려면 다음의 관련 노트북을 참조하세요:

* [TensorFlow에서의 오토인코더](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [PyTorch에서의 오토인코더](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## 오토인코더의 특성

* **데이터 특정** - 훈련한 이미지 유형에서만 잘 작동합니다. 예를 들어, 꽃에 대한 슈퍼 해상도 네트워크를 훈련하면 초상화에는 잘 작동하지 않습니다. 이는 네트워크가 훈련 데이터셋에서 학습한 특징의 세부 정보를 사용하여 고해상도 이미지를 생성하기 때문입니다.
* **손실** - 재구성된 이미지는 원래 이미지와 동일하지 않습니다. 손실의 성격은 훈련 중에 사용된 *손실 함수*에 의해 정의됩니다.
* **레이블이 없는 데이터**에서 작동합니다.

## [강의 후 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## 결론

이번 강의에서는 AI 과학자가 사용할 수 있는 다양한 유형의 오토인코더에 대해 배웠습니다. 오토인코더를 구축하는 방법과 이미지를 재구성하는 데 사용하는 방법을 배웠습니다. 또한 VAE에 대해 배우고, 이를 사용하여 새로운 이미지를 생성하는 방법도 배웠습니다.

## 🚀 도전 과제

이번 강의에서는 이미지에 대한 오토인코더 사용에 대해 배웠습니다. 그러나 음악에도 사용할 수 있습니다! 오토인코더를 사용하여 음악을 재구성하는 방법을 배우는 Magenta 프로젝트의 [MusicVAE](https://magenta.tensorflow.org/music-vae) 프로젝트를 확인해 보세요. 이 라이브러리로 [실험](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb)을 해보며 어떤 것을 만들 수 있는지 확인해 보세요.

## [강의 후 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## 복습 및 자기 학습

참고로, 다음 자료에서 오토인코더에 대해 더 읽어보세요:

* [Keras에서 오토인코더 구축하기](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHive의 블로그 포스트](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [변분 오토인코더 설명](https://kvfrans.com/variational-autoencoders-explained/)
* [조건부 변분 오토인코더](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## 과제

[이 TensorFlow 노트북](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersTF.ipynb)의 끝에서 '작업'을 찾을 수 있습니다. 이를 과제로 사용하세요.

**면책 조항**:  
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서는 해당 언어로 작성된 것이 권위 있는 출처로 간주되어야 합니다. 중요한 정보에 대해서는 전문 인간 번역을 권장합니다. 이 번역을 사용하여 발생하는 오해나 잘못된 해석에 대해 우리는 책임을 지지 않습니다.