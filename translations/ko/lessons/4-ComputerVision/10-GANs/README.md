# 생성적 적대 신경망

이전 섹션에서는 **생성 모델**에 대해 배웠습니다: 훈련 데이터셋의 이미지와 유사한 새로운 이미지를 생성할 수 있는 모델입니다. VAE는 생성 모델의 좋은 예시였습니다.

## [강의 전 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

하지만 VAE로 합리적인 해상도의 그림과 같이 정말 의미 있는 무언가를 생성하려고 하면, 훈련이 잘 수렴하지 않는 것을 볼 수 있습니다. 이러한 용도에 대해서는 생성 모델에 특별히 초점을 맞춘 또 다른 아키텍처인 **생성적 적대 신경망**(GAN)에 대해 배워야 합니다.

GAN의 주요 아이디어는 서로 경쟁하는 두 개의 신경망을 갖는 것입니다:

<img src="images/gan_architecture.png" width="70%"/>

> 이미지 제공: [Dmitry Soshnikov](http://soshnikov.com)

> ✅ 약간의 용어 정리:
> * **생성기(Generator)**는 임의의 벡터를 입력으로 받아 이미지를 생성하는 네트워크입니다.
> * **구분기(Discriminator)**는 이미지를 입력으로 받아 그것이 실제 이미지(훈련 데이터셋에서 온 것)인지, 아니면 생성기에 의해 생성된 것인지를 판단해야 하는 네트워크입니다. 본질적으로 이는 이미지 분류기입니다.

### 구분기

구분기의 아키텍처는 일반적인 이미지 분류 네트워크와 다르지 않습니다. 가장 간단한 경우, 완전 연결된 분류기일 수 있지만, 대부분은 [합성곱 신경망](../07-ConvNets/README.md)일 것입니다.

> ✅ 합성곱 신경망 기반의 GAN은 [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)이라고 불립니다.

CNN 구분기는 다음과 같은 층으로 구성됩니다: 여러 개의 합성곱+풀링(공간 크기가 감소하는)과 "특징 벡터"를 얻기 위한 하나 이상의 완전 연결 층, 마지막 이진 분류기입니다.

> ✅ 여기서 '풀링'은 이미지의 크기를 줄이는 기술입니다. "풀링 층은 한 층의 뉴런 클러스터의 출력을 다음 층의 단일 뉴런으로 결합하여 데이터의 차원을 줄입니다." - [출처](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### 생성기

생성기는 약간 더 복잡합니다. 이것은 구분기의 반대라고 생각할 수 있습니다. 잠재 벡터(특징 벡터 대신)에서 시작하여, 필요한 크기/형태로 변환하기 위해 완전 연결 층을 가지고 있으며, 그 뒤에 역합성곱+업스케일링이 이어집니다. 이는 [오토인코더](../09-Autoencoders/README.md)의 *디코더* 부분과 유사합니다.

> ✅ 합성곱 층이 이미지를 가로지르는 선형 필터로 구현되기 때문에, 역합성곱은 본질적으로 합성곱과 유사하며 동일한 층 논리를 사용하여 구현할 수 있습니다.

<img src="images/gan_arch_detail.png" width="70%"/>

> 이미지 제공: [Dmitry Soshnikov](http://soshnikov.com)

### GAN 훈련하기

GAN은 생성기와 구분기 간의 지속적인 경쟁이 있기 때문에 **적대적**이라고 불립니다. 이 경쟁 과정에서 생성기와 구분기 모두 개선되며, 따라서 네트워크는 점점 더 나은 이미지를 생성하는 법을 배웁니다.

훈련은 두 단계로 진행됩니다:

* **구분기 훈련**. 이 작업은 꽤 간단합니다: 생성기로부터 이미지 배치를 생성하고, 이를 0(가짜 이미지)로 레이블을 붙이고, 입력 데이터셋에서 이미지 배치를 가져와(1, 실제 이미지 레이블) 구분기 손실을 얻고 역전파를 수행합니다.
* **생성기 훈련**. 이는 약간 더 복잡합니다. 왜냐하면 생성기에 대한 예상 출력 값을 직접 알 수 없기 때문입니다. 생성기와 구분기로 구성된 전체 GAN 네트워크를 가져와 임의의 벡터로 공급하고, 결과가 1(실제 이미지에 해당)일 것으로 기대합니다. 그런 다음 구분기의 매개변수를 고정시키고(이 단계에서는 훈련되지 않기를 원합니다), 역전파를 수행합니다.

이 과정 동안 생성기와 구분기 손실은 크게 감소하지 않습니다. 이상적인 상황에서는 두 네트워크 모두 성능이 향상되면서 진동해야 합니다.

## ✍️ 연습문제: GANs

* [TensorFlow/Keras의 GAN 노트북](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorch의 GAN 노트북](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN 훈련의 문제점

GAN은 훈련하기 특히 어려운 것으로 알려져 있습니다. 다음은 몇 가지 문제입니다:

* **모드 붕괴**. 이 용어는 생성기가 구분기를 속이는 하나의 성공적인 이미지를 생성하는 법을 배우고, 다양한 이미지를 생성하지 못하는 상황을 의미합니다.
* **하이퍼파라미터에 대한 민감성**. 종종 GAN이 전혀 수렴하지 않는 것을 볼 수 있으며, 그러다가 학습률이 갑자기 감소하여 수렴하게 됩니다.
* 생성기와 구분기 간의 **균형** 유지. 많은 경우 구분기 손실이 상대적으로 빠르게 0으로 떨어질 수 있으며, 이로 인해 생성기가 더 이상 훈련할 수 없게 됩니다. 이를 극복하기 위해 생성기와 구분기에 서로 다른 학습률을 설정하거나 손실이 이미 너무 낮을 경우 구분기 훈련을 건너뛰는 방법을 시도할 수 있습니다.
* **고해상도** 훈련. 오토인코더와 유사한 문제를 반영하며, 너무 많은 합성곱 신경망 층을 재구성하면 아티팩트가 발생하는 문제입니다. 이 문제는 일반적으로 **점진적 성장**이라고 하는 방법으로 해결되며, 처음에는 몇 개의 층이 저해상도 이미지에서 훈련되고, 이후에 층이 "언블록"되거나 추가됩니다. 또 다른 해결책은 층 간에 추가 연결을 추가하고 여러 해상도를 동시에 훈련하는 것입니다 - 자세한 내용은 [Multi-Scale Gradient GANs 논문](https://arxiv.org/abs/1903.06048)을 참조하세요.

## 스타일 전이

GAN은 예술적인 이미지를 생성하는 훌륭한 방법입니다. 또 다른 흥미로운 기술은 **스타일 전이**라고 하며, 이는 하나의 **콘텐츠 이미지**를 가져와 다른 스타일로 다시 그리며 **스타일 이미지**의 필터를 적용합니다.

작동 방식은 다음과 같습니다:
* 우리는 무작위 노이즈 이미지(또는 콘텐츠 이미지)로 시작합니다. 이해를 돕기 위해 무작위 노이즈에서 시작하는 것이 더 쉽습니다.
* 우리의 목표는 콘텐츠 이미지와 스타일 이미지 모두에 가까운 이미지를 생성하는 것입니다. 이는 두 개의 손실 함수에 의해 결정됩니다:
   - **콘텐츠 손실**은 현재 이미지와 콘텐츠 이미지에서 CNN이 추출한 특징을 기반으로 계산됩니다.
   - **스타일 손실**은 현재 이미지와 스타일 이미지 간의 관계를 그람 행렬을 사용하여 정교하게 계산합니다(자세한 내용은 [예제 노트북](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) 참조).
* 이미지를 더 부드럽게 하고 노이즈를 제거하기 위해 **변화 손실**을 도입하여 이웃 픽셀 간의 평균 거리를 계산합니다.
* 주요 최적화 루프는 현재 이미지를 총 손실을 최소화하기 위해 경량 하강법(또는 다른 최적화 알고리즘)을 사용하여 조정합니다. 총 손실은 세 가지 손실의 가중 합입니다.

## ✍️ 예제: [스타일 전이](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [강의 후 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## 결론

이번 수업에서는 GAN과 이를 훈련하는 방법에 대해 배웠습니다. 또한 이 유형의 신경망이 직면할 수 있는 특별한 도전 과제와 이를 극복하는 방법에 대한 몇 가지 전략도 배웠습니다.

## 🚀 도전 과제

자신의 이미지를 사용하여 [스타일 전이 노트북](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)을 실행해 보세요.

## 복습 및 자습

참고로, GAN에 대해 더 알아보려면 다음 자료를 읽어보세요:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), 고려해야 할 *de facto* GAN 아키텍처
* [Azure ML에서 GAN을 사용하여 생성적 예술 만들기](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## 과제

이 수업과 관련된 두 개의 노트북 중 하나를 다시 방문하여 자신의 이미지로 GAN을 재훈련해 보세요. 무엇을 만들 수 있을까요?

**면책 조항**:  
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있음을 유의하시기 바랍니다. 원본 문서는 해당 언어로 작성된 권위 있는 자료로 간주되어야 합니다. 중요한 정보에 대해서는 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해서는 책임을 지지 않습니다.