# 잘 알려진 CNN 아키텍처

### VGG-16

VGG-16은 2014년 ImageNet top-5 분류에서 92.7%의 정확도를 달성한 네트워크입니다. 다음과 같은 레이어 구조를 가지고 있습니다:

![ImageNet Layers](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.ko.jpg)

보시다시피, VGG는 전통적인 피라미드 아키텍처를 따르며, 이는 일련의 합성곱-풀링 레이어로 구성되어 있습니다.

![ImageNet Pyramid](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.ko.jpg)

> 이미지 출처: [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet은 2015년 Microsoft Research에서 제안한 모델 패밀리입니다. ResNet의 주요 아이디어는 **잔차 블록**을 사용하는 것입니다:

<img src="images/resnet-block.png" width="300"/>

> 이미지 출처: [이 논문](https://arxiv.org/pdf/1512.03385.pdf)

아이덴티티 패스스루를 사용하는 이유는 이전 레이어의 결과와 잔차 블록의 출력을 비교하여 **차이**를 예측하도록 레이어를 구성하기 위함입니다 - 그래서 *잔차*라는 이름이 붙었습니다. 이러한 블록은 훈련하기가 훨씬 쉬우며, 수백 개의 블록으로 구성된 네트워크를 구축할 수 있습니다 (가장 일반적인 변형은 ResNet-52, ResNet-101 및 ResNet-152입니다).

이 네트워크는 데이터셋에 따라 복잡성을 조정할 수 있는 것으로 생각할 수도 있습니다. 네트워크 훈련을 시작할 때는 가중치 값이 작고 대부분의 신호가 패스스루 아이덴티티 레이어를 통해 전달됩니다. 훈련이 진행되면서 가중치가 커지면 네트워크 매개변수의 중요성이 커지고, 네트워크는 훈련 이미지를 올바르게 분류하기 위해 필요한 표현력을 조정합니다.

### Google Inception

Google Inception 아키텍처는 이 아이디어를 한 단계 더 발전시켜, 각 네트워크 레이어를 여러 다른 경로의 조합으로 구성합니다:

<img src="images/inception.png" width="400"/>

> 이미지 출처: [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

여기서 1x1 합성곱의 역할을 강조할 필요가 있습니다. 처음에는 그 의미가 잘 이해되지 않을 수 있습니다. 왜 1x1 필터로 이미지를 통과해야 할까요? 그러나 합성곱 필터는 여러 깊이 채널(원래는 RGB 색상, 후속 레이어에서는 서로 다른 필터를 위한 채널)과 함께 작동한다는 것을 기억해야 합니다. 1x1 합성곱은 이러한 입력 채널을 서로 다른 학습 가능한 가중치를 사용하여 혼합하는 데 사용됩니다. 이는 채널 차원에서 다운샘플링(풀링)으로도 볼 수 있습니다.

이 주제에 대한 [좋은 블로그 포스트](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578)와 [원본 논문](https://arxiv.org/pdf/1312.4400.pdf)을 참고하세요.

### MobileNet

MobileNet은 크기가 줄어든 모델 패밀리로, 모바일 장치에 적합합니다. 자원이 부족하고 정확도를 조금 희생할 수 있다면 이 모델들을 사용하세요. 이 모델의 주요 아이디어는 **깊이별 분리 합성곱**으로, 공간 합성곱과 깊이 채널에 대한 1x1 합성곱의 조합으로 합성곱 필터를 표현할 수 있게 해줍니다. 이는 매개변수의 수를 크게 줄여 네트워크의 크기를 작게 만들고, 데이터가 적어도 훈련하기 쉽게 만듭니다.

MobileNet에 대한 [좋은 블로그 포스트](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470)를 참고하세요.

## 결론

이 단원에서는 컴퓨터 비전 신경망의 주요 개념인 합성곱 신경망(CNN)에 대해 배웠습니다. 이미지 분류, 객체 탐지 및 이미지 생성 네트워크를 지원하는 실제 아키텍처는 모두 CNN을 기반으로 하며, 레이어 수가 더 많고 몇 가지 추가 훈련 기법이 포함되어 있습니다.

## 🚀 도전 과제

동반된 노트북에는 더 높은 정확도를 얻는 방법에 대한 메모가 있습니다. 실험을 통해 더 높은 정확도를 달성할 수 있는지 확인해 보세요.

## [강의 후 퀴즈](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/207)

## 리뷰 및 자기 학습

CNN은 일반적으로 컴퓨터 비전 작업에 가장 많이 사용되지만, 고정 크기 패턴을 추출하는 데도 일반적으로 유용합니다. 예를 들어, 소리를 다룰 때도 오디오 신호에서 특정 패턴을 찾기 위해 CNN을 사용할 수 있습니다. 이 경우 필터는 1차원(이 CNN은 1D-CNN이라고 불림)으로 구성됩니다. 또한, 때때로 3D-CNN이 다차원 공간에서 특징을 추출하는 데 사용되며, 비디오에서 발생하는 특정 이벤트를 캡처할 수 있습니다. CNN으로 수행할 수 있는 다른 작업에 대해 리뷰하고 자기 학습을 해보세요.

## [과제](lab/README.md)

이 실습에서는 다양한 고양이와 개 품종을 분류하는 작업을 맡게 됩니다. 이 이미지는 MNIST 데이터셋보다 더 복잡하고 차원이 더 높으며, 10개 이상의 클래스가 있습니다.

**면책 조항**:  
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있음을 유의하시기 바랍니다. 원본 문서는 해당 언어로 작성된 권위 있는 출처로 간주되어야 합니다. 중요한 정보에 대해서는 전문 인간 번역을 권장합니다. 이 번역을 사용하여 발생하는 오해나 잘못된 해석에 대해서는 책임을 지지 않습니다.