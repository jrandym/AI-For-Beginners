# Aufmerksamkeitsmechanismen und Transformer

## [Vorlesungsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/118)

Eines der wichtigsten Probleme im Bereich der NLP ist die **maschinelle √úbersetzung**, eine grundlegende Aufgabe, die Tools wie Google Translate zugrunde liegt. In diesem Abschnitt konzentrieren wir uns auf maschinelle √úbersetzung oder, allgemeiner, auf jede *Sequenz-zu-Sequenz*-Aufgabe (die auch als **Satztransduktion** bezeichnet wird).

Bei RNNs wird Sequenz-zu-Sequenz durch zwei rekursive Netzwerke implementiert, wobei ein Netzwerk, der **Encoder**, eine Eingabesequenz in einen verborgenen Zustand zusammenfasst, w√§hrend ein anderes Netzwerk, der **Decoder**, diesen verborgenen Zustand in ein √ºbersetztes Ergebnis entfaltet. Es gibt einige Probleme mit diesem Ansatz:

* Der endg√ºltige Zustand des Encoder-Netzwerks hat Schwierigkeiten, sich an den Anfang eines Satzes zu erinnern, was zu einer schlechten Modellqualit√§t bei langen S√§tzen f√ºhrt.
* Alle W√∂rter in einer Sequenz haben den gleichen Einfluss auf das Ergebnis. In der Realit√§t haben jedoch bestimmte W√∂rter in der Eingabesequenz oft einen gr√∂√üeren Einfluss auf die sequenziellen Ausgaben als andere.

**Aufmerksamkeitsmechanismen** bieten ein Mittel, um den kontextuellen Einfluss jedes Eingangsvektors auf jede Vorhersageausgabe des RNN zu gewichten. Die Implementierung erfolgt durch die Schaffung von Abk√ºrzungen zwischen den Zwischenzust√§nden des Eingangs-RNN und dem Ausgangs-RNN. Auf diese Weise ber√ºcksichtigen wir beim Generieren des Ausgabesymbols y<sub>t</sub> alle Eingangsversteckzust√§nde h<sub>i</sub> mit unterschiedlichen Gewichtungskoeffizienten Œ±<sub>t,i</sub>.

![Bild, das ein Encoder/Decoder-Modell mit einer additiven Aufmerksamkeitschicht zeigt](../../../../../translated_images/encoder-decoder-attention.7a726296894fb567aa2898c94b17b3289087f6705c11907df8301df9e5eeb3de.de.png)

> Das Encoder-Decoder-Modell mit dem additiven Aufmerksamkeitsmechanismus in [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf), zitiert aus [diesem Blogbeitrag](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

Die Aufmerksamkeitsmatrix {Œ±<sub>i,j</sub>} w√ºrde den Grad darstellen, in dem bestimmte Eingabew√∂rter an der Generierung eines bestimmten Wortes in der Ausgabesequenz beteiligt sind. Im Folgenden finden Sie ein Beispiel f√ºr eine solche Matrix:

![Bild, das eine Beispielausrichtung zeigt, die von RNNsearch-50 gefunden wurde, entnommen von Bahdanau - arviz.org](../../../../../translated_images/bahdanau-fig3.09ba2d37f202a6af11de6c82d2d197830ba5f4528d9ea430eb65fd3a75065973.de.png)

> Abbildung aus [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf) (Fig.3)

Aufmerksamkeitsmechanismen sind f√ºr einen Gro√üteil des aktuellen oder nahezu aktuellen Stands der Technik im NLP verantwortlich. Die Hinzuf√ºgung von Aufmerksamkeit erh√∂ht jedoch erheblich die Anzahl der Modellparameter, was zu Skalierungsproblemen bei RNNs f√ºhrte. Eine wichtige Einschr√§nkung bei der Skalierung von RNNs ist, dass die rekursive Natur der Modelle es schwierig macht, das Training zu batchen und zu parallelisieren. In einem RNN muss jedes Element einer Sequenz in sequentieller Reihenfolge verarbeitet werden, was bedeutet, dass es nicht leicht parallelisiert werden kann.

![Encoder Decoder mit Aufmerksamkeit](../../../../../lessons/5-NLP/18-Transformers/images/EncDecAttention.gif)

> Abbildung aus [Google's Blog](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)

Die Einf√ºhrung von Aufmerksamkeitsmechanismen in Kombination mit dieser Einschr√§nkung f√ºhrte zur Schaffung der heutigen State-of-the-Art-Transformer-Modelle, die wir kennen und verwenden, wie BERT und Open-GPT3.

## Transformermodelle

Eine der Hauptideen hinter Transformern ist es, die sequentielle Natur von RNNs zu vermeiden und ein Modell zu schaffen, das w√§hrend des Trainings parallelisierbar ist. Dies wird erreicht, indem zwei Ideen implementiert werden:

* Positionskodierung
* Verwendung des Selbstaufmerksamkeitsmechanismus zur Erfassung von Mustern anstelle von RNNs (oder CNNs) (deshalb hei√üt das Papier, das Transformer einf√ºhrt, *[Attention is all you need](https://arxiv.org/abs/1706.03762)*)

### Positionskodierung/Einbettung

Die Idee der Positionskodierung ist die folgende. 
1. Bei der Verwendung von RNNs wird die relative Position der Tokens durch die Anzahl der Schritte dargestellt und muss daher nicht explizit dargestellt werden. 
2. Sobald wir jedoch zu Aufmerksamkeit wechseln, m√ºssen wir die relativen Positionen der Tokens innerhalb einer Sequenz kennen. 
3. Um die Positionskodierung zu erhalten, erweitern wir unsere Sequenz von Tokens um eine Sequenz von Tokenpositionen in der Sequenz (d.h. eine Sequenz von Zahlen 0,1, ...).
4. Wir mischen dann die Tokenposition mit einem Token-Einbettungsvektor. Um die Position (ganzzahlig) in einen Vektor zu transformieren, k√∂nnen wir verschiedene Ans√§tze verwenden:

* Trainierbare Einbettung, √§hnlich wie bei der Token-Einbettung. Dies ist der Ansatz, den wir hier betrachten. Wir wenden Einbettungsschichten auf sowohl die Tokens als auch ihre Positionen an, was zu Einbettungsvektoren der gleichen Dimensionen f√ºhrt, die wir dann zusammenaddieren.
* Feste Positionskodierungsfunktion, wie im urspr√ºnglichen Papier vorgeschlagen.

<img src="images/pos-embedding.png" width="50%"/>

> Bild des Autors

Das Ergebnis, das wir mit der Positions-Einbettung erhalten, bettet sowohl das urspr√ºngliche Token als auch seine Position innerhalb einer Sequenz ein.

### Multi-Head Selbstaufmerksamkeit

Als N√§chstes m√ºssen wir einige Muster innerhalb unserer Sequenz erfassen. Dazu verwenden Transformer einen **Selbstaufmerksamkeits**mechanismus, der im Wesentlichen Aufmerksamkeit auf die gleiche Sequenz anwendet, die als Eingabe und Ausgabe dient. Die Anwendung von Selbstaufmerksamkeit erm√∂glicht es uns, den **Kontext** innerhalb des Satzes zu ber√ºcksichtigen und zu sehen, welche W√∂rter miteinander in Beziehung stehen. Zum Beispiel erm√∂glicht es uns zu sehen, welche W√∂rter durch Kofe referenziert werden, wie *es*, und auch den Kontext zu ber√ºcksichtigen:

![](../../../../../translated_images/CoreferenceResolution.861924d6d384a7d68d8d0039d06a71a151f18a796b8b1330239d3590bd4947eb.de.png)

> Bild aus dem [Google Blog](https://research.googleblog.com/2017/08/transformer-novel-neural-network.html)

In Transformern verwenden wir **Multi-Head Attention**, um dem Netzwerk die F√§higkeit zu geben, mehrere verschiedene Arten von Abh√§ngigkeiten zu erfassen, z.B. langfristige vs. kurzfristige Wortbeziehungen, Kofeferenz vs. etwas anderes usw.

[TensorFlow Notebook](../../../../../lessons/5-NLP/18-Transformers/TransformersTF.ipynb) enth√§lt weitere Details zur Implementierung von Transformerschichten.

### Encoder-Decoder-Aufmerksamkeit

In Transformern wird Aufmerksamkeit an zwei Stellen verwendet:

* Um Muster innerhalb des Eingabetextes mit Selbstaufmerksamkeit zu erfassen
* Um die Sequenz√ºbersetzung durchzuf√ºhren - es ist die Aufmerksamkeitschicht zwischen Encoder und Decoder.

Die Encoder-Decoder-Aufmerksamkeit √§hnelt sehr dem Aufmerksamkeitsmechanismus, der in RNNs verwendet wird, wie zu Beginn dieses Abschnitts beschrieben. Dieses animierte Diagramm erkl√§rt die Rolle der Encoder-Decoder-Aufmerksamkeit.

![Animiertes GIF, das zeigt, wie die Bewertungen in Transformermodellen durchgef√ºhrt werden.](../../../../../lessons/5-NLP/18-Transformers/images/transformer-animated-explanation.gif)

Da jede Eingabeposition unabh√§ngig auf jede Ausgabeposition abgebildet wird, k√∂nnen Transformer besser parallelisieren als RNNs, was viel gr√∂√üere und ausdrucksst√§rkere Sprachmodelle erm√∂glicht. Jeder Aufmerksamkeitskopf kann verwendet werden, um verschiedene Beziehungen zwischen W√∂rtern zu lernen, die nachgelagerte Aufgaben der nat√ºrlichen Sprachverarbeitung verbessern.

## BERT

**BERT** (Bidirektionale Encoder-Darstellungen von Transformern) ist ein sehr gro√ües, mehrschichtiges Transformernetzwerk mit 12 Schichten f√ºr *BERT-base* und 24 f√ºr *BERT-large*. Das Modell wird zun√§chst auf einem gro√üen Korpus von Textdaten (Wikipedia + B√ºcher) mit un√ºberwachtem Training (Vorhersage maskierter W√∂rter in einem Satz) vortrainiert. W√§hrend des Vortrainings absorbiert das Modell erhebliche Niveaus des Sprachverst√§ndnisses, die dann mit anderen Datens√§tzen durch Feinabstimmung genutzt werden k√∂nnen. Dieser Prozess wird als **Transferlernen** bezeichnet.

![Bild von http://jalammar.github.io/illustrated-bert/](../../../../../translated_images/jalammarBERT-language-modeling-masked-lm.34f113ea5fec4362e39ee4381aab7cad06b5465a0b5f053a0f2aa05fbe14e746.de.png)

> Bild [Quelle](http://jalammar.github.io/illustrated-bert/)

## ‚úçÔ∏è √úbungen: Transformer

Setzen Sie Ihr Lernen in den folgenden Notebooks fort:

* [Transformers in PyTorch](../../../../../lessons/5-NLP/18-Transformers/TransformersPyTorch.ipynb)
* [Transformers in TensorFlow](../../../../../lessons/5-NLP/18-Transformers/TransformersTF.ipynb)

## Fazit

In dieser Lektion haben Sie √ºber Transformer und Aufmerksamkeitsmechanismen gelernt, alles wesentliche Werkzeuge im NLP-Toolkit. Es gibt viele Variationen von Transformer-Architekturen, darunter BERT, DistilBERT, BigBird, OpenGPT3 und mehr, die feinabgestimmt werden k√∂nnen. Das [HuggingFace-Paket](https://github.com/huggingface/) bietet ein Repository zum Trainieren vieler dieser Architekturen sowohl mit PyTorch als auch mit TensorFlow.

## üöÄ Herausforderung

## [Nachlesequiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/218)

## √úberpr√ºfung & Selbststudium

* [Blogbeitrag](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/), der das klassische [Attention is all you need](https://arxiv.org/abs/1706.03762) Papier √ºber Transformer erkl√§rt.
* [Eine Reihe von Blogbeitr√§gen](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452) √ºber Transformer, die die Architektur im Detail erkl√§ren.

## [Aufgabe](assignment.md)

**Haftungsausschluss**:  
Dieses Dokument wurde mit maschinellen KI-√úbersetzungsdiensten √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, bitten wir zu beachten, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als die ma√ügebliche Quelle betrachtet werden. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Verwendung dieser √úbersetzung entstehen.