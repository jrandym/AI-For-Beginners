# Generative Adversarial Networks

Im vorherigen Abschnitt haben wir √ºber **generative Modelle** gelernt: Modelle, die neue Bilder erzeugen k√∂nnen, die den Bildern im Trainingsdatensatz √§hnlich sind. VAE war ein gutes Beispiel f√ºr ein generatives Modell.

## [Vorlesungsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Wenn wir jedoch versuchen, etwas wirklich Sinnvolles zu generieren, wie ein Gem√§lde in angemessener Aufl√∂sung, mit VAE, werden wir feststellen, dass das Training nicht gut konvergiert. F√ºr diesen Anwendungsfall sollten wir √ºber eine andere Architektur lernen, die speziell auf generative Modelle abzielt - **Generative Adversarial Networks**, oder GANs.

Die Hauptidee eines GANs besteht darin, zwei neuronale Netzwerke zu haben, die gegeneinander trainiert werden:

<img src="images/gan_architecture.png" width="70%"/>

> Bild von [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Ein kleines Vokabular:
> * **Generator** ist ein Netzwerk, das einen zuf√§lligen Vektor nimmt und als Ergebnis das Bild erzeugt
> * **Discriminator** ist ein Netzwerk, das ein Bild nimmt und feststellen sollte, ob es sich um ein echtes Bild (aus dem Trainingsdatensatz) handelt oder ob es von einem Generator erzeugt wurde. Es ist im Wesentlichen ein Bildklassifizierer.

### Discriminator

Die Architektur des Discriminators unterscheidet sich nicht von einem gew√∂hnlichen Bildklassifizierungsnetzwerk. Im einfachsten Fall kann es ein vollst√§ndig verbundener Klassifizierer sein, aber h√∂chstwahrscheinlich wird es ein [konvolutionales Netzwerk](../07-ConvNets/README.md) sein.

> ‚úÖ Ein auf konvolutionalen Netzwerken basierendes GAN wird als [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) bezeichnet.

Ein CNN-Discriminator besteht aus den folgenden Schichten: mehreren Faltungen+Pooling (mit abnehmender r√§umlicher Gr√∂√üe) und einer oder mehreren vollst√§ndig verbundenen Schichten, um den "Merkmalsvektor" zu erhalten, und einem endg√ºltigen bin√§ren Klassifizierer.

> ‚úÖ Ein 'Pooling' in diesem Kontext ist eine Technik, die die Gr√∂√üe des Bildes reduziert. "Pooling-Schichten reduzieren die Dimensionen der Daten, indem sie die Ausgaben von Neuronengruppen in einer Schicht in ein einzelnes Neuron in der n√§chsten Schicht kombinieren." - [Quelle](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

Ein Generator ist etwas kniffliger. Man kann ihn als umgekehrten Discriminator betrachten. Ausgehend von einem latenten Vektor (anstatt eines Merkmalsvektors) hat er eine vollst√§ndig verbundene Schicht, um ihn in die erforderliche Gr√∂√üe/Form zu konvertieren, gefolgt von Dekonvolutionen+Hochskalierung. Dies √§hnelt dem *Decoder*-Teil eines [Autoencoders](../09-Autoencoders/README.md).

> ‚úÖ Da die Faltungsschicht als linearer Filter implementiert ist, der das Bild durchl√§uft, ist die Dekonvolution im Wesentlichen √§hnlich wie die Faltung und kann mit derselben Schichtlogik implementiert werden.

<img src="images/gan_arch_detail.png" width="70%"/>

> Bild von [Dmitry Soshnikov](http://soshnikov.com)

### Training des GAN

GANs werden als **adversarial** bezeichnet, weil es einen st√§ndigen Wettbewerb zwischen dem Generator und dem Discriminator gibt. W√§hrend dieses Wettbewerbs verbessern sich sowohl der Generator als auch der Discriminator, sodass das Netzwerk lernt, immer bessere Bilder zu erzeugen.

Das Training erfolgt in zwei Phasen:

* **Training des Discriminators**. Diese Aufgabe ist ziemlich einfach: Wir erzeugen eine Charge von Bildern mit dem Generator, kennzeichnen sie mit 0, was f√ºr ein gef√§lschtes Bild steht, und nehmen eine Charge von Bildern aus dem Eingabedatensatz (mit dem Label 1, echtes Bild). Wir erhalten einen *Discriminator-Verlust* und f√ºhren die R√ºckpropagation durch.
* **Training des Generators**. Dies ist etwas kniffliger, da wir den erwarteten Ausgang f√ºr den Generator nicht direkt kennen. Wir nehmen das gesamte GAN-Netzwerk, das aus einem Generator gefolgt von einem Discriminator besteht, f√ºttern es mit einigen zuf√§lligen Vektoren und erwarten, dass das Ergebnis 1 ist (entsprechend echten Bildern). Dann frieren wir die Parameter des Discriminators ein (wir m√∂chten nicht, dass er in diesem Schritt trainiert wird) und f√ºhren die R√ºckpropagation durch.

W√§hrend dieses Prozesses sinken die Verluste von sowohl Generator als auch Discriminator nicht signifikant. In der idealen Situation sollten sie oszillieren, was bedeutet, dass beide Netzwerke ihre Leistung verbessern.

## ‚úçÔ∏è √úbungen: GANs

* [GAN-Notebook in TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [GAN-Notebook in PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Probleme beim Training von GANs

Es ist bekannt, dass GANs besonders schwierig zu trainieren sind. Hier sind einige Probleme:

* **Mode Collapse**. Mit diesem Begriff meinen wir, dass der Generator lernt, ein erfolgreiches Bild zu erzeugen, das den Discriminator t√§uscht, und nicht eine Vielzahl unterschiedlicher Bilder.
* **Empfindlichkeit gegen√ºber Hyperparametern**. Oft sieht man, dass ein GAN √ºberhaupt nicht konvergiert, und dann pl√∂tzlich der Lernrate sinkt, was zur Konvergenz f√ºhrt.
* Den **Ausgleich** zwischen Generator und Discriminator halten. In vielen F√§llen kann der Discriminator-Verlust relativ schnell auf null sinken, was dazu f√ºhrt, dass der Generator nicht weiter trainiert werden kann. Um dies zu √ºberwinden, k√∂nnen wir versuchen, unterschiedliche Lernraten f√ºr den Generator und den Discriminator festzulegen oder das Training des Discriminators zu √ºberspringen, wenn der Verlust bereits zu niedrig ist.
* Training f√ºr **hohe Aufl√∂sung**. Dies spiegelt dasselbe Problem wie bei Autoencodern wider; dieses Problem wird ausgel√∂st, weil das Rekonstruieren zu vieler Schichten eines konvolutionalen Netzwerks zu Artefakten f√ºhrt. Dieses Problem wird typischerweise mit dem sogenannten **progressiven Wachsen** gel√∂st, bei dem zun√§chst einige Schichten mit niedrig aufgel√∂sten Bildern trainiert werden und dann Schichten "freigeschaltet" oder hinzugef√ºgt werden. Eine andere L√∂sung w√§re, zus√§tzliche Verbindungen zwischen den Schichten hinzuzuf√ºgen und mehrere Aufl√∂sungen gleichzeitig zu trainieren - siehe dazu das [Multi-Scale Gradient GANs-Papier](https://arxiv.org/abs/1903.06048) f√ºr weitere Details.

## Stiltransfer

GANs sind eine gro√üartige M√∂glichkeit, k√ºnstlerische Bilder zu generieren. Eine weitere interessante Technik ist der sogenannte **Stiltransfer**, bei dem ein **Inhaltsbild** genommen und in einem anderen Stil neu gezeichnet wird, indem Filter aus einem **Stilbild** angewendet werden.

So funktioniert es:
* Wir beginnen mit einem Bild aus zuf√§lligem Rauschen (oder mit einem Inhaltsbild, aber um es besser zu verstehen, ist es einfacher, mit zuf√§lligem Rauschen zu beginnen)
* Unser Ziel w√§re es, ein solches Bild zu erstellen, das sowohl dem Inhaltsbild als auch dem Stilbild nahekommt. Dies w√ºrde durch zwei Verlustfunktionen bestimmt:
   - **Inhaltsverlust** wird basierend auf den Merkmalen berechnet, die von der CNN in einigen Schichten aus dem aktuellen Bild und dem Inhaltsbild extrahiert werden
   - **Stilverlust** wird auf clevere Weise zwischen dem aktuellen Bild und dem Stilbild unter Verwendung von Gram-Matrizen berechnet (weitere Details im [Beispiel-Notebook](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb))
* Um das Bild glatter zu machen und Rauschen zu entfernen, f√ºhren wir auch einen **Variationsverlust** ein, der die durchschnittliche Distanz zwischen benachbarten Pixeln berechnet
* Die Hauptoptimierungsschleife passt das aktuelle Bild unter Verwendung von Gradientenabstieg (oder einem anderen Optimierungsalgorithmus) an, um den Gesamtschaden zu minimieren, der eine gewichtete Summe aller drei Verluste ist.

## ‚úçÔ∏è Beispiel: [Stiltransfer](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Nachlesungsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Fazit

In dieser Lektion haben Sie √ºber GANs gelernt und wie man sie trainiert. Sie haben auch √ºber die speziellen Herausforderungen gelernt, mit denen dieser Typ von neuronalen Netzwerken konfrontiert sein kann, sowie √ºber einige Strategien, um dar√ºber hinwegzukommen.

## üöÄ Herausforderung

Durchlaufen Sie das [Stiltransfer-Notebook](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) mit Ihren eigenen Bildern.

## √úberpr√ºfung & Selbststudium

Zur Referenz lesen Sie mehr √ºber GANs in diesen Ressourcen:

* Marco Pasini, [10 Lektionen, die ich beim Training von GANs f√ºr ein Jahr gelernt habe](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), eine *de facto* GAN-Architektur, die in Betracht gezogen werden sollte
* [Erstellung generativer Kunst mit GANs auf Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Aufgabe

√úberarbeiten Sie eines der beiden Notebooks, die mit dieser Lektion verbunden sind, und trainieren Sie das GAN mit Ihren eigenen Bildern neu. Was k√∂nnen Sie erschaffen?

**Haftungsausschluss**:  
Dieses Dokument wurde mit maschinellen KI-√úbersetzungsdiensten √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner Originalsprache sollte als die ma√ügebliche Quelle angesehen werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Verantwortung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Verwendung dieser √úbersetzung entstehen.