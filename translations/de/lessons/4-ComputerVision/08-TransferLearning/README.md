# Vorgefertigte Netzwerke und Transferlernen

Das Training von CNNs kann viel Zeit in Anspruch nehmen, und es wird eine gro√üe Menge an Daten ben√∂tigt. Ein Gro√üteil der Zeit wird damit verbracht, die besten niedrigstufigen Filter zu lernen, die ein Netzwerk verwenden kann, um Muster aus Bildern zu extrahieren. Eine nat√ºrliche Frage stellt sich - k√∂nnen wir ein neuronales Netzwerk, das auf einem Datensatz trainiert wurde, anpassen, um verschiedene Bilder zu klassifizieren, ohne einen vollst√§ndigen Trainingsprozess durchlaufen zu m√ºssen?

## [Vorlesungsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Dieser Ansatz wird als **Transferlernen** bezeichnet, da wir Wissen von einem neuronalen Netzwerkmodell auf ein anderes √ºbertragen. Beim Transferlernen beginnen wir typischerweise mit einem vortrainierten Modell, das auf einem gro√üen Bilddatensatz wie **ImageNet** trainiert wurde. Diese Modelle k√∂nnen bereits gut darin sein, verschiedene Merkmale aus allgemeinen Bildern zu extrahieren, und in vielen F√§llen kann der Aufbau eines Klassifikators auf Basis dieser extrahierten Merkmale zu guten Ergebnissen f√ºhren.

> ‚úÖ Transferlernen ist ein Begriff, den man auch in anderen akademischen Bereichen wie der P√§dagogik findet. Es bezieht sich auf den Prozess, Wissen aus einem Bereich zu nehmen und es auf einen anderen anzuwenden.

## Vorgefertigte Modelle als Merkmalsextraktoren

Die konvolutionalen Netzwerke, √ºber die wir im vorherigen Abschnitt gesprochen haben, enthalten eine Reihe von Schichten, von denen jede einige Merkmale aus dem Bild extrahieren soll, beginnend mit niedrigstufigen Pixelkombinationen (wie horizontalen/vertikalen Linien oder Strichen) bis hin zu h√∂herstufigen Kombinationen von Merkmalen, die Dingen wie einem Auge einer Flamme entsprechen. Wenn wir ein CNN auf einem ausreichend gro√üen Datensatz allgemeiner und vielf√§ltiger Bilder trainieren, sollte das Netzwerk lernen, diese gemeinsamen Merkmale zu extrahieren.

Sowohl Keras als auch PyTorch enthalten Funktionen, um vortrainierte Gewichte neuronaler Netzwerke f√ºr einige g√§ngige Architekturen einfach zu laden, von denen die meisten auf Bildern von ImageNet trainiert wurden. Die am h√§ufigsten verwendeten sind auf der Seite [CNN-Architekturen](../07-ConvNets/CNN_Architectures.md) aus der vorherigen Lektion beschrieben. Insbesondere m√∂chten Sie m√∂glicherweise eines der folgenden Modelle in Betracht ziehen:

* **VGG-16/VGG-19**, die relativ einfache Modelle sind, die dennoch eine gute Genauigkeit bieten. Oft ist die Verwendung von VGG als ersten Versuch eine gute Wahl, um zu sehen, wie das Transferlernen funktioniert.
* **ResNet** ist eine Familie von Modellen, die 2015 von Microsoft Research vorgeschlagen wurde. Sie haben mehr Schichten und ben√∂tigen daher mehr Ressourcen.
* **MobileNet** ist eine Familie von Modellen mit reduzierter Gr√∂√üe, die f√ºr mobile Ger√§te geeignet sind. Verwenden Sie sie, wenn Sie wenig Ressourcen haben und bereit sind, ein wenig Genauigkeit zu opfern.

Hier sind Beispiele f√ºr Merkmale, die von einem Bild einer Katze durch das VGG-16-Netzwerk extrahiert wurden:

![Merkmale, die von VGG-16 extrahiert wurden](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.de.png)

## Katzen- und Hundedatensatz

In diesem Beispiel verwenden wir einen Datensatz von [Katzen und Hunden](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), der sehr nah an einem realen Bildklassifizierungsszenario ist.

## ‚úçÔ∏è √úbung: Transferlernen

Lassen Sie uns das Transferlernen in den entsprechenden Notebooks in Aktion sehen:

* [Transferlernen - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Transferlernen - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Visualisierung des adversarialen Katers

Das vortrainierte neuronale Netzwerk enth√§lt verschiedene Muster in seinem *Gehirn*, einschlie√ülich Vorstellungen von **idealen Katzen** (sowie idealen Hunden, idealen Zebras usw.). Es w√§re interessant, dieses Bild irgendwie **zu visualisieren**. Allerdings ist das nicht einfach, da die Muster √ºber die Netzwerkgewichte verteilt und auch in einer hierarchischen Struktur organisiert sind.

Ein Ansatz, den wir verfolgen k√∂nnen, besteht darin, mit einem zuf√§lligen Bild zu beginnen und dann die Technik der **Gradientenabstieg-Optimierung** zu verwenden, um dieses Bild so anzupassen, dass das Netzwerk anf√§ngt zu denken, es sei eine Katze.

![Bildoptimierungsschleife](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.de.png)

Wenn wir dies jedoch tun, erhalten wir etwas, das sehr √§hnlich wie Rauschen aussieht. Das liegt daran, dass *es viele M√∂glichkeiten gibt, das Netzwerk glauben zu lassen, dass das Eingabebild eine Katze ist*, einschlie√ülich einiger, die visuell keinen Sinn ergeben. W√§hrend diese Bilder viele Muster enthalten, die typisch f√ºr eine Katze sind, gibt es nichts, was sie visuell unterscheidbar macht.

Um das Ergebnis zu verbessern, k√∂nnen wir einen weiteren Begriff in die Verlustfunktion einf√ºgen, der als **Variationsverlust** bezeichnet wird. Es handelt sich um eine Metrik, die zeigt, wie √§hnlich benachbarte Pixel des Bildes sind. Die Minimierung des Variationsverlusts macht das Bild glatter und beseitigt Rauschen ‚Äì wodurch ansprechendere Muster sichtbar werden. Hier ist ein Beispiel f√ºr solche "idealen" Bilder, die mit hoher Wahrscheinlichkeit als Katze und als Zebra klassifiziert werden:

![Ideale Katze](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.de.png) | ![Ideales Zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.de.png)
-----|-----
 *Ideale Katze* | *Ideales Zebra*

Ein √§hnlicher Ansatz kann verwendet werden, um sogenannte **adversariale Angriffe** auf ein neuronales Netzwerk durchzuf√ºhren. Angenommen, wir m√∂chten ein neuronales Netzwerk t√§uschen und einen Hund wie eine Katze aussehen lassen. Wenn wir ein Bild eines Hundes nehmen, das von einem Netzwerk als Hund erkannt wird, k√∂nnen wir es dann ein wenig anpassen, indem wir die Gradientenabstieg-Optimierung verwenden, bis das Netzwerk beginnt, es als Katze zu klassifizieren:

![Bild eines Hundes](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.de.png) | ![Bild eines Hundes, der als Katze klassifiziert wird](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.de.png)
-----|-----
*Urspr√ºngliches Bild eines Hundes* | *Bild eines Hundes, der als Katze klassifiziert wird*

Siehe den Code, um die oben genannten Ergebnisse im folgenden Notebook zu reproduzieren:

* [Ideale und adversariale Katze - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)
## Fazit

Mit Transferlernen k√∂nnen Sie schnell einen Klassifikator f√ºr eine benutzerdefinierte Objektklassifizierungsaufgabe zusammenstellen und eine hohe Genauigkeit erreichen. Sie k√∂nnen sehen, dass komplexere Aufgaben, die wir jetzt l√∂sen, mehr Rechenleistung erfordern und nicht einfach auf der CPU gel√∂st werden k√∂nnen. In der n√§chsten Einheit werden wir versuchen, eine leichtere Implementierung zu verwenden, um dasselbe Modell mit geringeren Rechenressourcen zu trainieren, was zu einer nur geringf√ºgig niedrigeren Genauigkeit f√ºhrt.

## üöÄ Herausforderung

In den begleitenden Notebooks gibt es Hinweise am Ende, wie der Wissenstransfer am besten mit einigerma√üen √§hnlichen Trainingsdaten funktioniert (vielleicht eine neue Tierart). Experimentieren Sie mit v√∂llig neuen Bildtypen, um zu sehen, wie gut oder schlecht Ihre Modelle f√ºr den Wissenstransfer abschneiden.

## [Nachlesungsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## √úberpr√ºfung & Selbststudium

Lesen Sie [TrainingTricks.md](TrainingTricks.md) durch, um Ihr Wissen √ºber einige andere M√∂glichkeiten zu vertiefen, wie Sie Ihre Modelle trainieren k√∂nnen.

## [Aufgabe](lab/README.md)

In diesem Labor werden wir den realen [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) Haustierdatensatz mit 35 Rassen von Katzen und Hunden verwenden und einen Klassifikator f√ºr das Transferlernen erstellen.

**Haftungsausschluss**:  
Dieses Dokument wurde mit maschinellen KI-√úbersetzungsdiensten √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, bitten wir zu beachten, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Verwendung dieser √úbersetzung entstehen.