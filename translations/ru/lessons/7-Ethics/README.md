# Этический и Ответственный ИИ

Вы почти завершили этот курс, и я надеюсь, что к этому моменту вы четко понимаете, что ИИ основан на ряде формальных математических методов, которые позволяют нам находить взаимосвязи в данных и обучать модели для воспроизведения некоторых аспектов человеческого поведения. На данном этапе истории мы считаем ИИ очень мощным инструментом для извлечения паттернов из данных и применения этих паттернов для решения новых задач.

## [Предварительный тест](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

Однако в научной фантастике мы часто видим истории, где ИИ представляет опасность для человечества. Обычно такие истории сосредоточены вокруг некого восстания ИИ, когда ИИ решает противостоять людям. Это подразумевает, что ИИ обладает неким чувством или может принимать решения, непредусмотренные его разработчиками.

Тот ИИ, о котором мы узнали в этом курсе, не что иное, как большая матричная арифметика. Это очень мощный инструмент, который помогает нам решать наши проблемы, и, как и любой другой мощный инструмент, он может использоваться как для добрых, так и для злых целей. Важно отметить, что его можно *неправильно использовать*.

## Принципы Ответственного ИИ

Чтобы избежать случайного или преднамеренного неправильного использования ИИ, Microsoft заявляет о важных [Принципах Ответственного ИИ](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste). Следующие концепции лежат в основе этих принципов:

* **Справедливость** связана с важной проблемой *предвзятости моделей*, которая может возникать из-за использования предвзятых данных для обучения. Например, когда мы пытаемся предсказать вероятность получения работы разработчика программного обеспечения для человека, модель, скорее всего, отдаст предпочтение мужчинам - просто потому, что обучающий набор данных, вероятно, был предвзят в пользу мужской аудитории. Нам нужно тщательно сбалансировать обучающие данные и исследовать модель, чтобы избежать предвзятости и убедиться, что модель учитывает более актуальные характеристики.
* **Надежность и Безопасность**. По своей природе модели ИИ могут ошибаться. Нейронная сеть возвращает вероятности, и мы должны учитывать это при принятии решений. У каждой модели есть определенная точность и полнота, и мы должны понимать это, чтобы предотвратить вред, который может причинить неправильный совет.
* **Конфиденциальность и Безопасность** имеют некоторые специфические для ИИ последствия. Например, когда мы используем некоторые данные для обучения модели, эти данные становятся как бы "интегрированными" в модель. С одной стороны, это повышает безопасность и конфиденциальность, с другой - нам нужно помнить, на каких данных была обучена модель.
* **Инклюзивность** означает, что мы не создаем ИИ для замены людей, а скорее для дополнения людей и повышения креативности нашей работы. Это также связано со справедливостью, потому что при работе с недопредставленными сообществами большинство собранных нами наборов данных, вероятно, будут предвзяты, и нам нужно убедиться, что эти сообщества включены и правильно обрабатываются ИИ.
* **Прозрачность**. Это включает в себя обеспечение того, чтобы мы всегда четко указывали на использование ИИ. Кроме того, где это возможно, мы хотим использовать ИИ-системы, которые являются *интерпретируемыми*.
* **Ответственность**. Когда модели ИИ принимают некоторые решения, не всегда ясно, кто за эти решения отвечает. Нам нужно убедиться, что мы понимаем, где лежит ответственность за решения ИИ. В большинстве случаев мы хотели бы включить людей в процесс принятия важных решений, чтобы фактические люди несли ответственность.

## Инструменты для Ответственного ИИ

Microsoft разработала [Инструментарий Ответственного ИИ](https://github.com/microsoft/responsible-ai-toolbox), который содержит набор инструментов:

* Панель интерпретируемости (InterpretML)
* Панель справедливости (FairLearn)
* Панель анализа ошибок
* Панель Ответственного ИИ, которая включает в себя

   - EconML - инструмент для причинного анализа, который фокусируется на вопросах "что если"
   - DiCE - инструмент для контрфактического анализа, который позволяет увидеть, какие характеристики необходимо изменить, чтобы повлиять на решение модели

Для получения дополнительной информации о Этическом ИИ, пожалуйста, посетите [этот урок](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) в Учебной программе по Машинному Обучению, которая включает задания.

## Обзор и Самостоятельное Изучение

Пройдите этот [Учебный путь](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste), чтобы узнать больше о ответственном ИИ.

## [Пост-тест](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**Отказ от ответственности**:  
Этот документ был переведен с использованием услуг машинного перевода на основе ИИ. Хотя мы стремимся к точности, пожалуйста, имейте в виду, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на родном языке следует считать авторитетным источником. Для критически важной информации рекомендуется профессиональный человеческий перевод. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникающие в результате использования этого перевода.