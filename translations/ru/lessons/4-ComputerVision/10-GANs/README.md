# Генеративные Состязательные Сети

В предыдущем разделе мы узнали о **генеративных моделях**: моделях, которые могут создавать новые изображения, похожие на те, что находятся в обучающем наборе данных. VAE был хорошим примером генеративной модели.

## [Предварительный тест](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Однако, если мы попытаемся сгенерировать что-то действительно значимое, например, картину разумного разрешения, с помощью VAE, мы увидим, что обучение не сходится хорошо. Для этой задачи нам следует изучить другую архитектуру, специально предназначенную для генеративных моделей - **Генеративные Состязательные Сети**, или GAN.

Основная идея GAN заключается в том, чтобы иметь две нейронные сети, которые будут обучаться друг против друга:

<img src="images/gan_architecture.png" width="70%"/>

> Изображение от [Дмитрия Сошникова](http://soshnikov.com)

> ✅ Немного словарного запаса:
> * **Генератор** - это сеть, которая принимает случайный вектор и производит изображение в результате
> * **Дискриминатор** - это сеть, которая принимает изображение и должна определить, является ли оно реальным изображением (из обучающего набора данных) или было сгенерировано генератором. Это по сути классификатор изображений.

### Дискриминатор

Архитектура дискриминатора не отличается от обычной сети классификации изображений. В самом простом случае это может быть полностью связанный классификатор, но, скорее всего, это будет [сверточная сеть](../07-ConvNets/README.md).

> ✅ GAN на основе сверточных сетей называется [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Дискриминатор CNN состоит из следующих слоев: нескольких сверток + пуллингов (с уменьшающимся пространственным размером) и одного или нескольких полностью связанных слоев для получения "вектор признаков", финального бинарного классификатора.

> ✅ 'Пуллинг' в этом контексте - это техника, которая уменьшает размер изображения. "Слои пуллинга уменьшают размеры данных, комбинируя выходы кластеров нейронов на одном слое в один нейрон на следующем слое." - [источник](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Генератор

Генератор немного более сложен. Вы можете рассматривать его как обратный дискриминатор. Начав с латентного вектора (вместо вектора признаков), он имеет полностью связанный слой, который преобразует его в необходимый размер/форму, за которым следуют деконволюции + увеличение. Это похоже на *декодер* в [автоэнкодере](../09-Autoencoders/README.md).

> ✅ Поскольку сверточный слой реализуется как линейный фильтр, проходящий по изображению, деконволюция по сути аналогична свертке и может быть реализована с использованием той же логики слоев.

<img src="images/gan_arch_detail.png" width="70%"/>

> Изображение от [Дмитрия Сошникова](http://soshnikov.com)

### Обучение GAN

GAN называются **состязательными**, потому что между генератором и дискриминатором существует постоянная конкуренция. В ходе этой конкуренции как генератор, так и дискриминатор улучшаются, таким образом, сеть учится производить все лучшие и лучшие изображения.

Обучение происходит в два этапа:

* **Обучение дискриминатора**. Эта задача довольно проста: мы генерируем партию изображений с помощью генератора, помечая их как 0, что означает фальшивое изображение, и берем партию изображений из входного набора данных (с меткой 1, реальное изображение). Мы получаем некоторую *потерю дискриминатора* и выполняем обратное распространение.
* **Обучение генератора**. Это немного сложнее, потому что мы не знаем ожидаемый выход для генератора напрямую. Мы берем всю сеть GAN, состоящую из генератора, за которым следует дискриминатор, подаем ее с некоторыми случайными векторами и ожидаем, что результат будет 1 (соответствующий реальным изображениям). Затем мы замораживаем параметры дискриминатора (мы не хотим, чтобы он обучался на этом этапе) и выполняем обратное распространение.

В ходе этого процесса потери как генератора, так и дискриминатора не уменьшаются значительно. В идеальной ситуации они должны колебаться, соответствуя улучшению производительности обеих сетей.

## ✍️ Упражнения: GAN

* [Записная книжка GAN в TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Записная книжка GAN в PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Проблемы с обучением GAN

Известно, что GAN особенно трудно обучать. Вот несколько проблем:

* **Падение режима**. Под этим термином мы имеем в виду, что генератор учится производить одно успешное изображение, которое обманывает дискриминатор, а не разнообразие различных изображений.
* **Чувствительность к гиперпараметрам**. Часто можно увидеть, что GAN вообще не сходится, а затем внезапно уменьшается скорость обучения, что приводит к сходимости.
* Сохранение **баланса** между генератором и дискриминатором. В многих случаях потеря дискриминатора может быстро упасть до нуля, что приводит к тому, что генератор не может обучаться дальше. Чтобы преодолеть это, мы можем попробовать установить разные скорости обучения для генератора и дискриминатора или пропустить обучение дискриминатора, если потеря уже слишком низка.
* Обучение для **высокого разрешения**. Это проблема, аналогичная той, что возникает с автоэнкодерами, и она возникает, потому что восстановление слишком многих слоев сверточной сети приводит к артефактам. Эта проблема обычно решается с помощью так называемого **прогрессивного роста**, когда сначала несколько слоев обучаются на изображениях низкого разрешения, а затем слои "разблокируются" или добавляются. Другим решением может быть добавление дополнительных соединений между слоями и обучение нескольких разрешений одновременно - смотрите эту [статью о многоуровневых градиентных GAN](https://arxiv.org/abs/1903.06048) для подробностей.

## Перенос стиля

GAN - отличный способ создавать художественные изображения. Еще одна интересная техника называется **перенос стиля**, которая берет одно **контентное изображение** и перерисовывает его в другом стиле, применяя фильтры из **стильного изображения**.

Принцип работы таков:
* Мы начинаем с изображения случайного шума (или с контентного изображения, но для понимания проще начать с случайного шума)
* Наша цель - создать такое изображение, которое было бы близко как к контентному изображению, так и к стильному изображению. Это будет определяться двумя функциями потерь:
   - **Потеря контента** вычисляется на основе признаков, извлеченных CNN на некоторых слоях из текущего изображения и контентного изображения
   - **Потеря стиля** вычисляется между текущим изображением и стильным изображением хитрым образом с использованием матриц Грама (подробности в [примерной записной книжке](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb))
* Чтобы сделать изображение более гладким и убрать шум, мы также вводим **потерю вариации**, которая вычисляет среднее расстояние между соседними пикселями
* Основной цикл оптимизации корректирует текущее изображение с помощью градиентного спуска (или другого алгоритма оптимизации), чтобы минимизировать общую потерю, которая является взвешенной суммой всех трех потерь.

## ✍️ Пример: [Перенос стиля](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Посттест](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Заключение

На этом уроке вы узнали о GAN и о том, как их обучать. Вы также узнали о специальных проблемах, с которыми может столкнуться этот тип нейронной сети, и о некоторых стратегиях, как их преодолеть.

## 🚀 Вызов

Пройдите через [записную книжку переноса стиля](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb), используя свои собственные изображения.

## Обзор и самостоятельное изучение

Для справки прочитайте больше о GAN в этих источниках:

* Марко Пазини, [10 уроков, которые я усвоил, обучая GAN в течение года](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), *де-факто* архитектура GAN, которую стоит рассмотреть
* [Создание генеративного искусства с использованием GAN на Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Задание

Вернитесь к одной из двух записных книжек, связанных с этим уроком, и повторно обучите GAN на своих собственных изображениях. Что вы можете создать?

**Отказ от ответственности**:  
Этот документ был переведен с использованием услуг машинного перевода на основе ИИ. Хотя мы стремимся к точности, пожалуйста, имейте в виду, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на родном языке следует считать авторитетным источником. Для критически важной информации рекомендуется профессиональный человеческий перевод. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникающие в результате использования этого перевода.