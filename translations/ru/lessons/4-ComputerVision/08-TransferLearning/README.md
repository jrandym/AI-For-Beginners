# Предобученные сети и перенос обучения

Обучение CNN может занять много времени, и для этой задачи требуется много данных. Однако большая часть времени уходит на изучение лучших низкоуровневых фильтров, которые сеть может использовать для извлечения паттернов из изображений. Возникает естественный вопрос: можем ли мы использовать нейронную сеть, обученную на одном наборе данных, и адаптировать ее для классификации различных изображений без необходимости полного процесса обучения?

## [Предварительная викторина](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Этот подход называется **переносом обучения**, потому что мы переносим некоторые знания из одной модели нейронной сети в другую. В переносе обучения мы обычно начинаем с предобученной модели, которая была обучена на большом наборе изображений, таком как **ImageNet**. Эти модели уже хорошо справляются с извлечением различных признаков из общих изображений, и во многих случаях просто создание классификатора на основе этих извлеченных признаков может дать хороший результат.

> ✅ Перенос обучения — это термин, который вы можете встретить в других академических областях, таких как образование. Он относится к процессу переноса знаний из одной области и их применению в другой.

## Предобученные модели в качестве извлекателей признаков

Сверточные сети, о которых мы говорили в предыдущем разделе, содержат ряд слоев, каждый из которых предназначен для извлечения некоторых признаков из изображения, начиная с низкоуровневых комбинаций пикселей (таких как горизонтальная/вертикальная линия или штрих) и заканчивая более высокоуровневыми комбинациями признаков, соответствующими таким вещам, как глаз пламени. Если мы обучим CNN на достаточно большом наборе общих и разнообразных изображений, сеть должна научиться извлекать эти общие признаки.

Как Keras, так и PyTorch содержат функции для простого загрузки предобученных весов нейронной сети для некоторых распространенных архитектур, большинство из которых были обучены на изображениях ImageNet. Наиболее часто используемые из них описаны на странице [Архитектуры CNN](../07-ConvNets/CNN_Architectures.md) из предыдущего урока. В частности, вы можете рассмотреть возможность использования одной из следующих:

* **VGG-16/VGG-19**, которые являются относительно простыми моделями, но все же обеспечивают хорошую точность. Часто использование VGG в качестве первой попытки — это хороший выбор, чтобы увидеть, как работает перенос обучения.
* **ResNet** — это семейство моделей, предложенное Microsoft Research в 2015 году. У них больше слоев, и, следовательно, они требуют больше ресурсов.
* **MobileNet** — это семейство моделей с уменьшенным размером, подходящих для мобильных устройств. Используйте их, если у вас недостаточно ресурсов и вы можете немного пожертвовать точностью.

Вот примеры признаков, извлеченных из изображения кошки с помощью сети VGG-16:

![Признаки, извлеченные VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.ru.png)

## Набор данных «Кошки против собак»

В этом примере мы будем использовать набор данных [Кошки и собаки](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), который очень близок к реальному сценарию классификации изображений.

## ✍️ Упражнение: Перенос обучения

Давайте посмотрим, как работает перенос обучения, в соответствующих ноутбуках:

* [Перенос обучения - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Перенос обучения - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Визуализация противоречивой кошки

Предобученная нейронная сеть содержит различные паттерны внутри своего *мозга*, включая понятия **идеальной кошки** (а также идеальной собаки, идеальной зебры и т.д.). Было бы интересно каким-то образом **визуализировать это изображение**. Однако это не просто, потому что паттерны распределены по всем весам сети и также организованы в иерархическую структуру.

Один из подходов, который мы можем использовать, — это начать с случайного изображения, а затем попытаться использовать технику **оптимизации градиентного спуска**, чтобы настроить это изображение таким образом, чтобы сеть начала думать, что это кошка.

![Цикл оптимизации изображения](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.ru.png)

Однако, если мы сделаем это, мы получим нечто очень похожее на случайный шум. Это происходит потому, что *существует множество способов заставить сеть думать, что входное изображение — это кошка*, включая некоторые, которые не имеют визуального смысла. Хотя эти изображения содержат много паттернов, типичных для кошки, нет ничего, что могло бы ограничить их визуальную отличительность.

Чтобы улучшить результат, мы можем добавить еще один термин в функцию потерь, который называется **потеря вариации**. Это метрика, которая показывает, насколько похожи соседние пиксели изображения. Минимизация потери вариации делает изображение более гладким и избавляется от шума, тем самым выявляя более визуально привлекательные паттерны. Вот пример таких "идеальных" изображений, которые классифицируются как кошка и зебра с высокой вероятностью:

![Идеальная кошка](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.ru.png) | ![Идеальная зебра](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.ru.png)
-----|-----
 *Идеальная кошка* | *Идеальная зебра*

Похожий подход можно использовать для проведения так называемых **противоречивых атак** на нейронную сеть. Предположим, мы хотим обмануть нейронную сеть и заставить собаку выглядеть как кошка. Если мы возьмем изображение собаки, которое распознается сетью как собака, мы можем немного подкорректировать его с помощью оптимизации градиентного спуска, пока сеть не начнет классифицировать его как кошку:

![Изображение собаки](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.ru.png) | ![Изображение собаки, классифицированной как кошка](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.ru.png)
-----|-----
*Оригинальное изображение собаки* | *Изображение собаки, классифицированной как кошка*

Смотрите код для воспроизведения вышеуказанных результатов в следующем ноутбуке:

* [Идеальная и противоречивая кошка - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)
## Заключение

Используя перенос обучения, вы можете быстро создать классификатор для задачи классификации пользовательских объектов и достичь высокой точности. Вы можете видеть, что более сложные задачи, которые мы решаем сейчас, требуют большей вычислительной мощности и не могут быть легко решены на ЦП. В следующем модуле мы попробуем использовать более легковесную реализацию для обучения той же модели с использованием меньших вычислительных ресурсов, что приведет к лишь незначительно более низкой точности.

## 🚀 Вызов

В сопроводительных ноутбуках есть заметки внизу о том, как перенос знаний работает лучше всего с несколько схожими тренировочными данными (возможно, новый тип животного). Проведите некоторые эксперименты с совершенно новыми типами изображений, чтобы увидеть, насколько хорошо или плохо работают ваши модели переноса знаний.

## [Послевикторина](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Обзор и самообучение

Прочтите [TrainingTricks.md](TrainingTricks.md), чтобы углубить свои знания о некоторых других способах обучения ваших моделей.

## [Задание](lab/README.md)

В этой лаборатории мы будем использовать реальный набор данных [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) о домашних животных с 35 породами кошек и собак, и мы создадим классификатор с использованием переноса обучения.

**Отказ от ответственности**:  
Этот документ был переведен с использованием машинных сервисов перевода на основе ИИ. Хотя мы стремимся к точности, пожалуйста, имейте в виду, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на родном языке должен считаться авторитетным источником. Для критически важной информации рекомендуется профессиональный человеческий перевод. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования этого перевода.