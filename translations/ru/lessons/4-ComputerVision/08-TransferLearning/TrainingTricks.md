# Трюки обучения глубокому обучению

По мере того как нейронные сети становятся глубже, процесс их обучения становится все более сложным. Одной из основных проблем являются так называемые [исчезающие градиенты](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) или [взрывающиеся градиенты](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled.). [Этот пост](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) дает хорошее введение в эти проблемы.

Чтобы сделать обучение глубоких сетей более эффективным, можно использовать несколько техник.

## Сохранение значений в разумных пределах

Для того чтобы численные вычисления были более стабильными, мы хотим убедиться, что все значения в нашей нейронной сети находятся в разумном диапазоне, обычно [-1..1] или [0..1]. Это не очень строгие требования, но природа вычислений с плавающей точкой такова, что значения разных порядков не могут быть точно обработаны вместе. Например, если мы сложим 10<sup>-10</sup> и 10<sup>10</sup>, мы, вероятно, получим 10<sup>10</sup>, потому что меньшее значение будет "преобразовано" в тот же порядок, что и большее, и, таким образом, мантисса будет потеряна.

Большинство функций активации имеют нелинейности в диапазоне [-1..1], и поэтому имеет смысл масштабировать все входные данные до диапазона [-1..1] или [0..1].

## Начальная инициализация весов

В идеале, мы хотим, чтобы значения находились в одном диапазоне после прохождения через слои сети. Поэтому важно инициализировать веса таким образом, чтобы сохранить распределение значений.

Нормальное распределение **N(0,1)** не является хорошей идеей, потому что если у нас есть *n* входов, стандартное отклонение выхода будет *n*, и значения, вероятно, выйдут за пределы интервала [0..1].

Следующие инициализации часто используются:

 * Равномерное распределение -- `uniform`
 * **N(0,1/n)** -- `gaussian`
 * **N(0,1/√n_in)** гарантирует, что для входов со средним значением 0 и стандартным отклонением 1 среднее/стандартное отклонение останется тем же
 * **N(0,√2/(n_in+n_out))** -- так называемая **инициализация Xavier** (`glorot`), она помогает сохранить сигналы в диапазоне как при прямом, так и при обратном распространении

## Пакетная нормализация

Даже при правильной инициализации весов, веса могут стать произвольно большими или маленькими во время обучения, и они выведут сигналы за пределы правильного диапазона. Мы можем вернуть сигналы, используя одну из техник **нормализации**. Хотя их несколько (нормализация весов, нормализация слоя), наиболее часто используемой является пакетная нормализация.

Идея **пакетной нормализации** заключается в том, чтобы учитывать все значения в мини-батче и выполнять нормализацию (т.е. вычитать среднее и делить на стандартное отклонение) на основе этих значений. Это реализуется как слой сети, который выполняет эту нормализацию после применения весов, но перед функцией активации. В результате мы, вероятно, увидим более высокую окончательную точность и более быстрое обучение.

Вот [оригинальная статья](https://arxiv.org/pdf/1502.03167.pdf) о пакетной нормализации, [объяснение на Википедии](https://en.wikipedia.org/wiki/Batch_normalization) и [хорошая вводная статья в блоге](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338) (и одна [на русском](https://habrahabr.ru/post/309302/)).

## Упадок

**Упадок** — это интересная техника, которая удаляет определенный процент случайных нейронов во время обучения. Она также реализуется как слой с одним параметром (процент нейронов для удаления, обычно 10%-50%), и во время обучения она обнуляет случайные элементы входного вектора перед передачей его в следующий слой.

Хотя это может звучать как странная идея, вы можете увидеть эффект упадка на обучении классификатора цифр MNIST в [`Dropout.ipynb`](../../../../../lessons/4-ComputerVision/08-TransferLearning/Dropout.ipynb) блокноте. Это ускоряет обучение и позволяет достичь более высокой точности за меньшее количество эпох обучения.

Этот эффект можно объяснить несколькими способами:

 * Это можно рассматривать как случайный шок для модели, который выводит оптимизацию из локального минимума
 * Это можно рассматривать как *неявное усреднение модели*, потому что можно сказать, что во время упадка мы обучаем слегка другую модель

> *Некоторые люди говорят, что когда пьяный человек пытается что-то выучить, он запомнит это лучше на следующее утро, по сравнению с трезвым человеком, потому что мозг с некоторыми неисправными нейронами пытается лучше адаптироваться к пониманию. Мы никогда не проверяли, правда ли это или нет*

## Предотвращение переобучения

Одним из очень важных аспектов глубокого обучения является способность предотвращать [переобучение](../../3-NeuralNetworks/05-Frameworks/Overfitting.md). Хотя может быть соблазнительно использовать очень мощную модель нейронной сети, мы всегда должны балансировать количество параметров модели с количеством обучающих примеров.

> Убедитесь, что вы понимаете концепцию [переобучения](../../3-NeuralNetworks/05-Frameworks/Overfitting.md), которую мы представили ранее!

Существует несколько способов предотвратить переобучение:

 * Раннее завершение — непрерывный мониторинг ошибки на валидационном наборе и остановка обучения, когда ошибка валидации начинает увеличиваться.
 * Явное уменьшение веса / Регуляризация — добавление дополнительного штрафа к функции потерь за высокие абсолютные значения весов, что предотвращает получение модели очень нестабильных результатов
 * Усреднение модели — обучение нескольких моделей, а затем усреднение результата. Это помогает минимизировать дисперсию.
 * Упадок (неявное усреднение модели)

## Оптимизаторы / Алгоритмы обучения

Еще одним важным аспектом обучения является выбор хорошего алгоритма обучения. Хотя классический **градиентный спуск** является разумным выбором, он иногда может быть слишком медленным или привести к другим проблемам.

В глубоком обучении мы используем **Стохастический Градиентный Спуск** (SGD), который представляет собой градиентный спуск, применяемый к мини-батчам, случайно выбранным из обучающего набора. Веса корректируются по этой формуле:

w<sup>t+1</sup> = w<sup>t</sup> - η∇ℒ

### Моментум

В **моментум SGD** мы сохраняем часть градиента из предыдущих шагов. Это похоже на то, когда мы движемся куда-то с инерцией, и получаем удар в другом направлении, наша траектория не меняется сразу, но сохраняет часть оригинального движения. Здесь мы вводим еще один вектор v для представления *скорости*:

* v<sup>t+1</sup> = γ v<sup>t</sup> - η∇ℒ
* w<sup>t+1</sup> = w<sup>t</sup> + v<sup>t+1</sup>

Здесь параметр γ указывает, в какой степени мы учитываем инерцию: γ=0 соответствует классическому SGD; γ=1 — это чистое уравнение движения.

### Adam, Adagrad и др.

Поскольку в каждом слое мы умножаем сигналы на некоторую матрицу W<sub>i</sub>, в зависимости от ||W<sub>i</sub>||, градиент может либо уменьшаться и приближаться к 0, либо бесконечно возрастать. Это суть проблемы взрывающихся/исчезающих градиентов.

Одно из решений этой проблемы заключается в том, чтобы использовать только направление градиента в уравнении и игнорировать абсолютное значение, т.е.

w<sup>t+1</sup> = w<sup>t</sup> - η(∇ℒ/||∇ℒ||), где ||∇ℒ|| = √∑(∇ℒ)<sup>2</sup>

Этот алгоритм называется **Adagrad**. Другие алгоритмы, использующие ту же идею: **RMSProp**, **Adam**.

> **Adam** считается очень эффективным алгоритмом для многих приложений, поэтому если вы не уверены, какой использовать — используйте Adam.

### Усечение градиента

Усечение градиента является расширением вышеописанной идеи. Когда ||∇ℒ|| ≤ θ, мы учитываем оригинальный градиент в оптимизации веса, а когда ||∇ℒ|| > θ — мы делим градиент на его норму. Здесь θ — это параметр, в большинстве случаев мы можем взять θ=1 или θ=10.

### Уменьшение скорости обучения

Успех обучения часто зависит от параметра скорости обучения η. Логично предположить, что большие значения η приводят к более быстрому обучению, что обычно нам нужно в начале обучения, а затем меньшие значения η позволяют нам тонко настраивать сеть. Таким образом, в большинстве случаев мы хотим уменьшить η в процессе обучения.

Это можно сделать, умножая η на некоторое число (например, 0.98) после каждой эпохи обучения или используя более сложный **график скорости обучения**.

## Разные архитектуры сетей

Выбор правильной архитектуры сети для вашей задачи может быть непростым. Обычно мы выбираем архитектуру, которая зарекомендовала себя для нашей конкретной задачи (или аналогичной). Вот [хороший обзор](https://www.topbots.com/a-brief-history-of-neural-network-architectures/) архитектур нейронных сетей для компьютерного зрения.

> Важно выбрать архитектуру, которая будет достаточно мощной для количества обучающих примеров, которые у нас есть. Выбор слишком мощной модели может привести к [переобучению](../../3-NeuralNetworks/05-Frameworks/Overfitting.md).

Другим хорошим способом будет использование архитектуры, которая автоматически подстраивается под необходимую сложность. В некоторой степени архитектуры **ResNet** и **Inception** являются самоадаптирующимися. [Больше о архитектурах компьютерного зрения](../07-ConvNets/CNN_Architectures.md)

**Отказ от ответственности**:  
Этот документ был переведен с использованием услуг машинного перевода на основе ИИ. Хотя мы стремимся к точности, пожалуйста, имейте в виду, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для критически важной информации рекомендуется профессиональный человеческий перевод. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования этого перевода.