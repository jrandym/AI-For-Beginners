# Автоэнкодеры

При обучении CNN одной из проблем является необходимость в большом количестве размеченных данных. В случае классификации изображений нам нужно разделить изображения на разные классы, что является ручной работой.

## [Предварительный тест](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Тем не менее, мы можем использовать сырые (незначенные) данные для обучения извлекателей признаков CNN, что называется **самостоятельным обучением**. Вместо меток мы будем использовать обучающие изображения как вход и выход сети. Основная идея **автоэнкодера** заключается в том, что у нас будет **кодирующая сеть**, которая преобразует входное изображение в некоторое **скрытое пространство** (обычно это просто вектор меньшего размера), а затем **декодирующая сеть**, цель которой - восстановить оригинальное изображение.

> ✅ Автоэнкодер - это "тип искусственной нейронной сети, используемой для изучения эффективных кодировок незанятых данных."

Поскольку мы обучаем автоэнкодер, чтобы захватить как можно больше информации из оригинального изображения для точного восстановления, сеть пытается найти лучшее **встраивание** входных изображений для передачи смысла.

![Схема автоэнкодера](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ru.jpg)

> Изображение из [блога Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Сценарии использования автоэнкодеров

Хотя восстановление оригинальных изображений само по себе может не казаться полезным, есть несколько сценариев, где автоэнкодеры особенно полезны:

* **Снижение размерности изображений для визуализации** или **обучения встраиваний изображений**. Обычно автоэнкодеры дают лучшие результаты, чем PCA, поскольку учитывают пространственную природу изображений и иерархические признаки.
* **Удаление шума**, т.е. удаление шума из изображения. Поскольку шум содержит много бесполезной информации, автоэнкодер не может уместить все это в относительно малом скрытом пространстве и, таким образом, захватывает только важную часть изображения. При обучении шумоподавляющих сетей мы начинаем с оригинальных изображений и используем изображения с искусственно добавленным шумом в качестве входных данных для автоэнкодера.
* **Суперразрешение**, увеличение разрешения изображения. Мы начинаем с изображений высокого разрешения и используем изображение с более низким разрешением в качестве входа для автоэнкодера.
* **Генеративные модели**. После того как мы обучим автоэнкодер, часть декодера может быть использована для создания новых объектов, начиная с случайных скрытых векторов.

## Вариационные автоэнкодеры (VAE)

Традиционные автоэнкодеры уменьшают размерность входных данных, определяя важные признаки входных изображений. Однако скрытые векторы часто не имеют большого смысла. Другими словами, взяв датасет MNIST в качестве примера, определить, какие цифры соответствуют различным скрытым векторам, не так просто, поскольку близкие скрытые векторы не обязательно соответствуют одним и тем же цифрам.

С другой стороны, для обучения *генеративных* моделей лучше иметь некоторое понимание скрытого пространства. Эта идея приводит нас к **вариационному автоэнкодеру** (VAE).

VAE - это автоэнкодер, который учится предсказывать *статистическое распределение* скрытых параметров, так называемое **скрытое распределение**. Например, мы можем захотеть, чтобы скрытые векторы распределялись нормально с некоторым средним z<sub>mean</sub> и стандартным отклонением z<sub>sigma</sub> (как среднее, так и стандартное отклонение - это векторы некоторой размерности d). Кодировщик в VAE учится предсказывать эти параметры, а затем декодер берет случайный вектор из этого распределения, чтобы восстановить объект.

Подводя итог:

* Из входного вектора мы предсказываем `z_mean` и `z_log_sigma` (вместо того чтобы предсказывать само стандартное отклонение, мы предсказываем его логарифм)
* Мы выбираем вектор `sample` из распределения N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
* Декодер пытается декодировать оригинальное изображение, используя `sample` в качестве входного вектора

<img src="images/vae.png" width="50%">

> Изображение из [этого блога](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) Исаака Дайкемана

Вариационные автоэнкодеры используют сложную функцию потерь, состоящую из двух частей:

* **Потери восстановления** - это функция потерь, которая показывает, насколько близко восстановленное изображение к целевому (это может быть среднеквадратичная ошибка, или MSE). Это та же функция потерь, что и в обычных автоэнкодерах.
* **KL-потери**, которая гарантирует, что распределения скрытых переменных остаются близкими к нормальному распределению. Она основана на понятии [дивергенции Кульбака-Лейблера](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - метрики для оценки того, насколько похожи два статистических распределения.

Одно из важных преимуществ VAE заключается в том, что они позволяют нам относительно легко генерировать новые изображения, поскольку мы знаем, из какого распределения брать скрытые векторы. Например, если мы обучаем VAE с 2D скрытым вектором на MNIST, мы можем затем изменять компоненты скрытого вектора, чтобы получить разные цифры:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Изображение от [Дмитрия Сошникова](http://soshnikov.com)

Обратите внимание, как изображения сливаются друг с другом, когда мы начинаем получать скрытые векторы из разных частей пространства скрытых параметров. Мы также можем визуализировать это пространство в 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/>

> Изображение от [Дмитрия Сошникова](http://soshnikov.com)

## ✍️ Упражнения: Автоэнкодеры

Узнайте больше об автоэнкодерах в соответствующих ноутбуках:

* [Автоэнкодеры в TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Автоэнкодеры в PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Свойства автоэнкодеров

* **Специфичность данных** - они хорошо работают только с тем типом изображений, на которых они были обучены. Например, если мы обучаем сеть суперразрешения на цветах, она не будет хорошо работать на портретах. Это связано с тем, что сеть может производить изображение более высокого разрешения, извлекая мелкие детали из признаков, изученных на обучающем наборе данных.
* **Потеря качества** - восстановленное изображение не является тем же самым, что и оригинальное изображение. Характер потерь определяется *функцией потерь*, используемой во время обучения.
* Работает с **незначенными данными**.

## [Постлекционный тест](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Заключение

В этом уроке вы узнали о различных типах автоэнкодеров, доступных для ученого в области ИИ. Вы узнали, как их строить и как использовать для восстановления изображений. Вы также узнали о VAE и как использовать его для генерации новых изображений.

## 🚀 Вызов

В этом уроке вы узнали о использовании автоэнкодеров для изображений. Но их также можно использовать для музыки! Ознакомьтесь с проектом Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), который использует автоэнкодеры для изучения восстановления музыки. Проведите несколько [экспериментов](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) с этой библиотекой, чтобы увидеть, что вы можете создать.

## [Постлекционный тест](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Обзор и самостоятельное изучение

Для справки читайте больше об автоэнкодерах в этих ресурсах:

* [Создание автоэнкодеров в Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Блог на NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Объяснение вариационных автоэнкодеров](https://kvfrans.com/variational-autoencoders-explained/)
* [Условные вариационные автоэнкодеры](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Задание

В конце [этого ноутбука с использованием TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) вы найдете "задачу" - используйте это как ваше задание.

**Отказ от ответственности**:  
Этот документ был переведен с использованием услуг машинного перевода на основе ИИ. Хотя мы стремимся к точности, пожалуйста, имейте в виду, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникающие в результате использования этого перевода.