# R√©seaux Antagonistes G√©n√©ratifs

Dans la section pr√©c√©dente, nous avons appris sur les **mod√®les g√©n√©ratifs** : des mod√®les capables de g√©n√©rer de nouvelles images similaires √† celles du jeu de donn√©es d'entra√Ænement. Le VAE √©tait un bon exemple de mod√®le g√©n√©ratif.

## [Quiz pr√©-cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Cependant, si nous essayons de g√©n√©rer quelque chose de vraiment significatif, comme une peinture √† une r√©solution raisonnable, avec un VAE, nous verrons que l'entra√Ænement ne converge pas bien. Pour ce cas d'utilisation, nous devrions nous renseigner sur une autre architecture sp√©cifiquement destin√©e aux mod√®les g√©n√©ratifs - **R√©seaux Antagonistes G√©n√©ratifs**, ou GANs.

L'id√©e principale d'un GAN est d'avoir deux r√©seaux neuronaux qui seront entra√Æn√©s l'un contre l'autre :

<img src="images/gan_architecture.png" width="70%"/>

> Image par [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Un petit vocabulaire :
> * **G√©n√©rateur** est un r√©seau qui prend un vecteur al√©atoire et produit l'image en r√©sultat
> * **Discriminateur** est un r√©seau qui prend une image et doit dire si c'est une image r√©elle (du jeu de donn√©es d'entra√Ænement) ou si elle a √©t√© g√©n√©r√©e par un g√©n√©rateur. C'est essentiellement un classificateur d'images.

### Discriminateur

L'architecture du discriminateur ne diff√®re pas d'un r√©seau de classification d'images ordinaire. Dans le cas le plus simple, il peut s'agir d'un classificateur enti√®rement connect√©, mais tr√®s probablement, il s'agira d'un [r√©seau de convolution](../07-ConvNets/README.md).

> ‚úÖ Un GAN bas√© sur des r√©seaux de convolution est appel√© un [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Un discriminateur CNN se compose des couches suivantes : plusieurs convolutions+poolings (avec une taille spatiale d√©croissante) et une ou plusieurs couches enti√®rement connect√©es pour obtenir un "vecteur de caract√©ristiques", le classificateur binaire final.

> ‚úÖ Un 'pooling' dans ce contexte est une technique qui r√©duit la taille de l'image. "Les couches de pooling r√©duisent les dimensions des donn√©es en combinant les sorties des clusters de neurones √† une couche en un seul neurone √† la couche suivante." - [source](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### G√©n√©rateur

Un g√©n√©rateur est l√©g√®rement plus complexe. Vous pouvez le consid√©rer comme un discriminateur invers√©. Partant d'un vecteur latent (√† la place d'un vecteur de caract√©ristiques), il a une couche enti√®rement connect√©e pour le convertir en la taille/forme requise, suivie de d√©convolutions+upsampling. Cela ressemble √† la partie *d√©codeur* de l'[autoencodeur](../09-Autoencoders/README.md).

> ‚úÖ Comme la couche de convolution est impl√©ment√©e comme un filtre lin√©aire parcourant l'image, la d√©convolution est essentiellement similaire √† la convolution et peut √™tre impl√©ment√©e en utilisant la m√™me logique de couche.

<img src="images/gan_arch_detail.png" width="70%"/>

> Image par [Dmitry Soshnikov](http://soshnikov.com)

### Entra√Ænement du GAN

Les GANs sont appel√©s **antagonistes** car il y a une comp√©tition constante entre le g√©n√©rateur et le discriminateur. Au cours de cette comp√©tition, le g√©n√©rateur et le discriminateur s'am√©liorent, ainsi le r√©seau apprend √† produire des images de meilleure qualit√©.

L'entra√Ænement se d√©roule en deux √©tapes :

* **Entra√Ænement du discriminateur**. Cette t√¢che est assez simple : nous g√©n√©rons un lot d'images par le g√©n√©rateur, les √©tiquetons 0, ce qui repr√©sente une image fausse, et prenons un lot d'images du jeu de donn√©es d'entr√©e (avec l'√©tiquette 1, image r√©elle). Nous obtenons une *perte du discriminateur*, et effectuons une r√©tropropagation.
* **Entra√Ænement du g√©n√©rateur**. Cela est l√©g√®rement plus d√©licat, car nous ne connaissons pas directement la sortie attendue pour le g√©n√©rateur. Nous prenons l'ensemble du r√©seau GAN constitu√© d'un g√©n√©rateur suivi d'un discriminateur, le nourrissons avec des vecteurs al√©atoires, et nous attendons que le r√©sultat soit 1 (correspondant aux images r√©elles). Nous figeons ensuite les param√®tres du discriminateur (nous ne voulons pas qu'il soit entra√Æn√© √† cette √©tape), et effectuons la r√©tropropagation.

Au cours de ce processus, les pertes du g√©n√©rateur et du discriminateur ne diminuent pas significativement. Dans une situation id√©ale, elles devraient osciller, correspondant √† l'am√©lioration des performances des deux r√©seaux.

## ‚úçÔ∏è Exercices : GANs

* [Notebook GAN en TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Notebook GAN en PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Probl√®mes avec l'entra√Ænement des GAN

Les GANs sont connus pour √™tre particuli√®rement difficiles √† entra√Æner. Voici quelques probl√®mes :

* **Effondrement de mode**. Par ce terme, nous entendons que le g√©n√©rateur apprend √† produire une image r√©ussie qui trompe le discriminateur, et non une vari√©t√© d'images diff√©rentes.
* **Sensibilit√© aux hyperparam√®tres**. Souvent, vous pouvez voir qu'un GAN ne converge pas du tout, puis soudainement diminue dans le taux d'apprentissage conduisant √† la convergence.
* Maintenir un **√©quilibre** entre le g√©n√©rateur et le discriminateur. Dans de nombreux cas, la perte du discriminateur peut tomber √† z√©ro relativement rapidement, ce qui emp√™che le g√©n√©rateur de s'entra√Æner davantage. Pour surmonter cela, nous pouvons essayer de d√©finir diff√©rents taux d'apprentissage pour le g√©n√©rateur et le discriminateur, ou sauter l'entra√Ænement du discriminateur si la perte est d√©j√† trop basse.
* Entra√Ænement pour une **haute r√©solution**. R√©fl√©chissant au m√™me probl√®me qu'avec les autoencodeurs, ce probl√®me est d√©clench√© car reconstruire trop de couches de r√©seau de convolution conduit √† des artefacts. Ce probl√®me est g√©n√©ralement r√©solu par ce qu'on appelle la **croissance progressive**, lorsque d'abord quelques couches sont entra√Æn√©es sur des images basse r√©solution, puis les couches sont "d√©bloqu√©es" ou ajout√©es. Une autre solution consisterait √† ajouter des connexions suppl√©mentaires entre les couches et √† entra√Æner plusieurs r√©solutions √† la fois - voir cet article sur les [GANs √† gradient multi-√©chelle](https://arxiv.org/abs/1903.06048) pour plus de d√©tails.

## Transfert de style

Les GANs sont un excellent moyen de g√©n√©rer des images artistiques. Une autre technique int√©ressante est le **transfert de style**, qui prend une **image de contenu** et la redessine dans un style diff√©rent, appliquant des filtres de l'**image de style**.

Le fonctionnement est le suivant :
* Nous commen√ßons avec une image de bruit al√©atoire (ou avec une image de contenu, mais pour mieux comprendre, il est plus facile de commencer par du bruit al√©atoire)
* Notre objectif serait de cr√©er une image qui serait proche √† la fois de l'image de contenu et de l'image de style. Cela serait d√©termin√© par deux fonctions de perte :
   - La **perte de contenu** est calcul√©e en fonction des caract√©ristiques extraites par le CNN √† certaines couches de l'image actuelle et de l'image de contenu
   - La **perte de style** est calcul√©e entre l'image actuelle et l'image de style de mani√®re astucieuse en utilisant des matrices de Gram (plus de d√©tails dans le [notebook exemple](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb))
* Pour rendre l'image plus lisse et √©liminer le bruit, nous introduisons √©galement une **perte de variation**, qui calcule la distance moyenne entre les pixels voisins
* La boucle d'optimisation principale ajuste l'image actuelle en utilisant la descente de gradient (ou un autre algorithme d'optimisation) pour minimiser la perte totale, qui est une somme pond√©r√©e de toutes les trois pertes.

## ‚úçÔ∏è Exemple : [Transfert de style](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Quiz post-cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Conclusion

Dans cette le√ßon, vous avez appris sur les GANs et comment les entra√Æner. Vous avez √©galement appris les d√©fis particuliers que ce type de r√©seau de neurones peut rencontrer, ainsi que quelques strat√©gies pour les surmonter.

## üöÄ D√©fi

Parcourez le [notebook de transfert de style](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) en utilisant vos propres images.

## R√©vision et auto-apprentissage

Pour r√©f√©rence, lisez-en plus sur les GANs dans ces ressources :

* Marco Pasini, [10 le√ßons que j'ai apprises en entra√Ænant des GANs pendant un an](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), une architecture GAN √† consid√©rer
* [Cr√©er de l'art g√©n√©ratif avec des GANs sur Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Assignment

Revisitez l'un des deux notebooks associ√©s √† cette le√ßon et r√©entra√Ænez le GAN sur vos propres images. Que pouvez-vous cr√©er ?

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'IA. Bien que nous visons √† l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, une traduction humaine professionnelle est recommand√©e. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.