# R√©seaux pr√©-entra√Æn√©s et apprentissage par transfert

L'entra√Ænement des CNN peut prendre beaucoup de temps et n√©cessite une grande quantit√© de donn√©es. Cependant, une grande partie du temps est consacr√©e √† l'apprentissage des meilleurs filtres de bas niveau qu'un r√©seau peut utiliser pour extraire des motifs √† partir d'images. Une question naturelle se pose : peut-on utiliser un r√©seau de neurones entra√Æn√© sur un ensemble de donn√©es et l'adapter pour classer diff√©rentes images sans avoir besoin d'un processus d'entra√Ænement complet ?

## [Quiz avant le cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Cette approche s'appelle **l'apprentissage par transfert**, car nous transf√©rons une partie des connaissances d'un mod√®le de r√©seau de neurones √† un autre. Dans l'apprentissage par transfert, nous commen√ßons g√©n√©ralement avec un mod√®le pr√©-entra√Æn√©, qui a √©t√© entra√Æn√© sur un grand ensemble de donn√©es d'images, comme **ImageNet**. Ces mod√®les peuvent d√©j√† faire un bon travail d'extraction de diff√©rentes caract√©ristiques √† partir d'images g√©n√©riques, et dans de nombreux cas, construire simplement un classificateur sur les caract√©ristiques extraites peut donner un bon r√©sultat.

> ‚úÖ L'apprentissage par transfert est un terme que l'on trouve dans d'autres domaines acad√©miques, comme l'√©ducation. Il fait r√©f√©rence au processus de prise de connaissances d'un domaine et de leur application √† un autre.

## Mod√®les pr√©-entra√Æn√©s en tant qu'extracteurs de caract√©ristiques

Les r√©seaux de convolution dont nous avons parl√© dans la section pr√©c√©dente contenaient un certain nombre de couches, chacune √©tant cens√©e extraire certaines caract√©ristiques de l'image, √† partir de combinaisons de pixels de bas niveau (comme des lignes horizontales/verticales ou des traits), jusqu'√† des combinaisons de caract√©ristiques de niveau sup√©rieur, correspondant √† des choses comme l'≈ìil d'une flamme. Si nous entra√Ænons un CNN sur un ensemble de donn√©es suffisamment large d'images g√©n√©riques et diverses, le r√©seau devrait apprendre √† extraire ces caract√©ristiques communes.

Keras et PyTorch contiennent des fonctions pour charger facilement les poids de r√©seaux de neurones pr√©-entra√Æn√©s pour certaines architectures courantes, dont la plupart ont √©t√© entra√Æn√©es sur des images ImageNet. Les plus souvent utilis√©s sont d√©crits sur la page [Architectures CNN](../07-ConvNets/CNN_Architectures.md) de la le√ßon pr√©c√©dente. En particulier, vous voudrez peut-√™tre envisager d'utiliser l'un des suivants :

* **VGG-16/VGG-19**, qui sont des mod√®les relativement simples mais qui offrent une bonne pr√©cision. Utiliser VGG comme premi√®re tentative est souvent un bon choix pour voir comment fonctionne l'apprentissage par transfert.
* **ResNet** est une famille de mod√®les propos√©s par Microsoft Research en 2015. Ils ont plus de couches et n√©cessitent donc plus de ressources.
* **MobileNet** est une famille de mod√®les de taille r√©duite, adapt√©s aux appareils mobiles. Utilisez-les si vous manquez de ressources et pouvez sacrifier un peu de pr√©cision.

Voici des caract√©ristiques extraites d'une image de chat par le r√©seau VGG-16 :

![Caract√©ristiques extraites par VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.fr.png)

## Ensemble de donn√©es Chats vs. Chiens

Dans cet exemple, nous allons utiliser un ensemble de donn√©es de [Chats et Chiens](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), qui est tr√®s proche d'un sc√©nario de classification d'images en conditions r√©elles.

## ‚úçÔ∏è Exercice : Apprentissage par Transfert

Voyons l'apprentissage par transfert en action dans les notebooks correspondants :

* [Apprentissage par Transfert - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Apprentissage par Transfert - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Visualisation du Chat Adversarial

Le r√©seau de neurones pr√©-entra√Æn√© contient diff√©rents motifs dans son *cerveau*, y compris des notions de **chat id√©al** (ainsi que de chien id√©al, de z√®bre id√©al, etc.). Il serait int√©ressant de **visualiser cette image** d'une certaine mani√®re. Cependant, ce n'est pas simple, car les motifs sont r√©partis sur tous les poids du r√©seau et sont √©galement organis√©s dans une structure hi√©rarchique.

Une approche que nous pouvons adopter est de commencer avec une image al√©atoire, puis d'essayer d'utiliser la technique **d'optimisation par descente de gradient** pour ajuster cette image de mani√®re √† ce que le r√©seau commence √† penser qu'il s'agit d'un chat.

![Boucle d'Optimisation d'Image](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.fr.png)

Cependant, si nous faisons cela, nous obtiendrons quelque chose de tr√®s similaire √† un bruit al√©atoire. Cela est d√ª au fait qu'il *existe de nombreuses fa√ßons de faire croire au r√©seau que l'image d'entr√©e est un chat*, y compris certaines qui n'ont pas de sens visuellement. Bien que ces images contiennent de nombreux motifs typiques d'un chat, il n'y a rien pour les contraindre √† √™tre visuellement distinctives.

Pour am√©liorer le r√©sultat, nous pouvons ajouter un autre terme dans la fonction de perte, qui est appel√© **perte de variation**. C'est une m√©trique qui montre √† quel point les pixels voisins de l'image sont similaires. Minimiser la perte de variation rend l'image plus lisse et √©limine le bruit, r√©v√©lant ainsi des motifs plus visuellement attrayants. Voici un exemple de telles images "id√©ales", qui sont class√©es comme chat et comme z√®bre avec une forte probabilit√© :

![Chat Id√©al](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.fr.png) | ![Z√®bre Id√©al](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.fr.png)
-----|-----
 *Chat Id√©al* | *Z√®bre Id√©al*

Une approche similaire peut √™tre utilis√©e pour effectuer ce que l'on appelle des **attaques adversariales** sur un r√©seau de neurones. Supposons que nous voulons tromper un r√©seau de neurones et faire en sorte qu'un chien ressemble √† un chat. Si nous prenons une image de chien, qui est reconnue par un r√©seau comme un chien, nous pouvons ensuite l'ajuster un peu √† l'aide de l'optimisation par descente de gradient, jusqu'√† ce que le r√©seau commence √† la classifier comme un chat :

![Image d'un Chien](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.fr.png) | ![Image d'un chien class√© comme un chat](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.fr.png)
-----|-----
*Image originale d'un chien* | *Image d'un chien class√© comme un chat*

Consultez le code pour reproduire les r√©sultats ci-dessus dans le notebook suivant :

* [Chat Id√©al et Adversarial - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## Conclusion

En utilisant l'apprentissage par transfert, vous pouvez rapidement assembler un classificateur pour une t√¢che de classification d'objets personnalis√©e et atteindre une haute pr√©cision. Vous pouvez constater que les t√¢ches plus complexes que nous r√©solvons maintenant n√©cessitent une plus grande puissance de calcul et ne peuvent pas √™tre facilement r√©solues sur un CPU. Dans l'unit√© suivante, nous essaierons d'utiliser une impl√©mentation plus l√©g√®re pour entra√Æner le m√™me mod√®le en utilisant moins de ressources de calcul, ce qui se traduira par une pr√©cision l√©g√®rement inf√©rieure.

## üöÄ D√©fi

Dans les notebooks accompagnants, il y a des notes en bas sur la fa√ßon dont le transfert de connaissances fonctionne mieux avec des donn√©es d'entra√Ænement quelque peu similaires (un nouveau type d'animal, peut-√™tre). Faites quelques exp√©riences avec des types d'images compl√®tement nouveaux pour voir √† quel point vos mod√®les de transfert de connaissances fonctionnent bien ou mal.

## [Quiz apr√®s le cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## R√©vision et Auto-√©tude

Lisez [TrainingTricks.md](TrainingTricks.md) pour approfondir vos connaissances sur d'autres mani√®res d'entra√Æner vos mod√®les.

## [Devoir](lab/README.md)

Dans ce laboratoire, nous utiliserons un ensemble de donn√©es de [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) sur les animaux de compagnie avec 35 races de chats et de chiens, et nous construirons un classificateur d'apprentissage par transfert.

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'IA. Bien que nous nous effor√ßons d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, une traduction humaine professionnelle est recommand√©e. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.