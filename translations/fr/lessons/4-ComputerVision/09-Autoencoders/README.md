# Autoencodeurs

Lors de l'entra√Ænement de CNN, l'un des probl√®mes est que nous avons besoin de beaucoup de donn√©es √©tiquet√©es. Dans le cas de la classification d'images, nous devons s√©parer les images en diff√©rentes classes, ce qui n√©cessite un effort manuel.

## [Quiz pr√©-cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Cependant, nous pourrions vouloir utiliser des donn√©es brutes (non √©tiquet√©es) pour entra√Æner des extracteurs de caract√©ristiques CNN, ce qui s'appelle **l'apprentissage auto-supervis√©**. Au lieu d'√©tiquettes, nous utiliserons les images d'entra√Ænement comme entr√©e et sortie du r√©seau. L'id√©e principale de l'**autoencodeur** est que nous aurons un **r√©seau encodeur** qui convertit l'image d'entr√©e en un **espace latent** (normalement, c'est juste un vecteur de taille plus petite), puis le **r√©seau d√©codeur**, dont le but serait de reconstruire l'image originale.

> ‚úÖ Un [autoencodeur](https://wikipedia.org/wiki/Autoencoder) est "un type de r√©seau de neurones artificiels utilis√© pour apprendre des codages efficaces de donn√©es non √©tiquet√©es."

Puisque nous entra√Ænons un autoencodeur pour capturer autant d'informations que possible de l'image originale pour une reconstruction pr√©cise, le r√©seau essaie de trouver le meilleur **embedding** des images d'entr√©e pour capturer le sens.

![Diagramme AutoEncodeur](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.fr.jpg)

> Image provenant du [blog Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Sc√©narios d'utilisation des Autoencodeurs

Bien que reconstruire des images originales ne semble pas utile en soi, il existe quelques sc√©narios o√π les autoencodeurs sont particuli√®rement utiles :

* **R√©duction de la dimension des images pour la visualisation** ou **entra√Ænement des embeddings d'images**. En g√©n√©ral, les autoencodeurs donnent de meilleurs r√©sultats que la PCA, car ils prennent en compte la nature spatiale des images et les caract√©ristiques hi√©rarchiques.
* **D√©nuisage**, c'est-√†-dire suppression du bruit de l'image. Comme le bruit contient beaucoup d'informations inutiles, l'autoencodeur ne peut pas tout int√©grer dans un espace latent relativement petit, et il capture donc uniquement la partie importante de l'image. Lors de l'entra√Ænement des d√©bruiteurs, nous commen√ßons avec des images originales et utilisons des images avec du bruit ajout√© artificiellement comme entr√©e pour l'autoencodeur.
* **Super-r√©solution**, augmentation de la r√©solution de l'image. Nous commen√ßons avec des images haute r√©solution et utilisons l'image de plus basse r√©solution comme entr√©e de l'autoencodeur.
* **Mod√®les g√©n√©ratifs**. Une fois que nous avons entra√Æn√© l'autoencodeur, la partie d√©codeur peut √™tre utilis√©e pour cr√©er de nouveaux objets √† partir de vecteurs latents al√©atoires.

## Autoencodeurs Variationnels (VAE)

Les autoencodeurs traditionnels r√©duisent d'une certaine mani√®re la dimension des donn√©es d'entr√©e, en identifiant les caract√©ristiques importantes des images d'entr√©e. Cependant, les vecteurs latents n'ont souvent pas beaucoup de sens. En d'autres termes, en prenant le jeu de donn√©es MNIST comme exemple, il n'est pas facile de d√©terminer quels chiffres correspondent √† diff√©rents vecteurs latents, car des vecteurs latents proches ne correspondent pas n√©cessairement aux m√™mes chiffres.

D'autre part, pour entra√Æner des mod√®les *g√©n√©ratifs*, il est pr√©f√©rable d'avoir une certaine compr√©hension de l'espace latent. Cette id√©e nous conduit √† l'**autoencodeur variationnel** (VAE).

Le VAE est l'autoencodeur qui apprend √† pr√©dire *la distribution statistique* des param√®tres latents, appel√©e **distribution latente**. Par exemple, nous pouvons vouloir que les vecteurs latents soient distribu√©s normalement avec une certaine moyenne z<sub>mean</sub> et un √©cart type z<sub>sigma</sub> (la moyenne et l'√©cart type sont tous deux des vecteurs d'une certaine dimensionnalit√© d). L'encodeur dans le VAE apprend √† pr√©dire ces param√®tres, puis le d√©codeur prend un vecteur al√©atoire de cette distribution pour reconstruire l'objet.

Pour r√©sumer :

* √Ä partir du vecteur d'entr√©e, nous pr√©disons `z_mean` et `z_log_sigma` (au lieu de pr√©dire l'√©cart type lui-m√™me, nous pr√©disons son logarithme)
* Nous √©chantillonnons un vecteur `sample` √† partir de la distribution N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
* Le d√©codeur essaie de d√©coder l'image originale en utilisant `sample` comme vecteur d'entr√©e

<img src="images/vae.png" width="50%">

> Image provenant de [cet article de blog](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) par Isaak Dykeman

Les autoencodeurs variationnels utilisent une fonction de perte complexe qui se compose de deux parties :

* **Perte de reconstruction** est la fonction de perte qui montre √† quel point une image reconstruite est proche de la cible (cela peut √™tre l'erreur quadratique moyenne, ou MSE). C'est la m√™me fonction de perte que dans les autoencodeurs normaux.
* **Perte KL**, qui garantit que les distributions des variables latentes restent proches de la distribution normale. Elle est bas√©e sur la notion de [divergence Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - une m√©trique pour estimer √† quel point deux distributions statistiques sont similaires.

Un avantage important des VAE est qu'ils nous permettent de g√©n√©rer de nouvelles images relativement facilement, car nous savons quelle distribution utiliser pour √©chantillonner les vecteurs latents. Par exemple, si nous entra√Ænons un VAE avec un vecteur latent 2D sur MNIST, nous pouvons ensuite faire varier les composants du vecteur latent pour obtenir diff√©rents chiffres :

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Image par [Dmitry Soshnikov](http://soshnikov.com)

Observez comment les images se fondent les unes dans les autres, alors que nous commen√ßons √† obtenir des vecteurs latents provenant de diff√©rentes portions de l'espace des param√®tres latents. Nous pouvons √©galement visualiser cet espace en 2D :

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/>

> Image par [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è Exercices : Autoencodeurs

Apprenez-en davantage sur les autoencodeurs dans ces carnets correspondants :

* [Autoencodeurs dans TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Autoencodeurs dans PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Propri√©t√©s des Autoencodeurs

* **Sp√©cifique aux donn√©es** - ils ne fonctionnent bien qu'avec le type d'images sur lequel ils ont √©t√© entra√Æn√©s. Par exemple, si nous entra√Ænons un r√©seau de super-r√©solution sur des fleurs, il ne fonctionnera pas bien sur des portraits. Cela est d√ª au fait que le r√©seau peut produire une image de plus haute r√©solution en prenant des d√©tails fins des caract√©ristiques apprises √† partir du jeu de donn√©es d'entra√Ænement.
* **Avec perte** - l'image reconstruite n'est pas la m√™me que l'image originale. La nature de la perte est d√©finie par la *fonction de perte* utilis√©e pendant l'entra√Ænement.
* Fonctionne sur **des donn√©es non √©tiquet√©es**.

## [Quiz post-cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Conclusion

Dans cette le√ßon, vous avez appris les diff√©rents types d'autoencodeurs disponibles pour le scientifique de l'IA. Vous avez appris √† les construire et √† les utiliser pour reconstruire des images. Vous avez √©galement appris sur le VAE et comment l'utiliser pour g√©n√©rer de nouvelles images.

## üöÄ D√©fi

Dans cette le√ßon, vous avez appris √† utiliser des autoencodeurs pour des images. Mais ils peuvent √©galement √™tre utilis√©s pour la musique ! D√©couvrez le projet [MusicVAE](https://magenta.tensorflow.org/music-vae) du projet Magenta, qui utilise des autoencodeurs pour apprendre √† reconstruire de la musique. Faites quelques [exp√©riences](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) avec cette biblioth√®que pour voir ce que vous pouvez cr√©er.

## [Quiz post-cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Revue & Auto-apprentissage

Pour r√©f√©rence, lisez-en plus sur les autoencodeurs dans ces ressources :

* [Construire des Autoencodeurs dans Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Article de blog sur NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Autoencodeurs Variationnels Expliqu√©s](https://kvfrans.com/variational-autoencoders-explained/)
* [Autoencodeurs Variationnels Conditionnels](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Devoir

√Ä la fin de [ce carnet utilisant TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb), vous trouverez une 't√¢che' - utilisez ceci comme votre devoir.

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'IA. Bien que nous nous effor√ßons d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source autoris√©e. Pour des informations critiques, une traduction humaine professionnelle est recommand√©e. Nous ne sommes pas responsables des malentendus ou des erreurs d'interpr√©tation r√©sultant de l'utilisation de cette traduction.