# Cadres de R√©seaux de Neurones

Comme nous l'avons d√©j√† appris, pour pouvoir entra√Æner des r√©seaux de neurones de mani√®re efficace, nous devons faire deux choses :

* Op√©rer sur des tenseurs, par exemple, multiplier, additionner et calculer certaines fonctions telles que sigmoid ou softmax
* Calculer les gradients de toutes les expressions, afin d'effectuer une optimisation par descente de gradient

## [Quiz pr√©-cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/105)

Bien que la biblioth√®que `numpy` puisse faire la premi√®re partie, nous avons besoin d'un m√©canisme pour calculer les gradients. Dans [notre cadre](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb) que nous avons d√©velopp√© dans la section pr√©c√©dente, nous devions programmer manuellement toutes les fonctions d√©riv√©es √† l'int√©rieur de la m√©thode `backward`, qui effectue la r√©tropropagation. Id√©alement, un cadre devrait nous donner la possibilit√© de calculer les gradients de *n'importe quelle expression* que nous pouvons d√©finir.

Une autre chose importante est de pouvoir effectuer des calculs sur GPU, ou sur toute autre unit√© de calcul sp√©cialis√©e, comme [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit). L'entra√Ænement des r√©seaux de neurones profonds n√©cessite *beaucoup* de calculs, et pouvoir parall√©liser ces calculs sur des GPU est tr√®s important.

> ‚úÖ Le terme 'parall√©liser' signifie distribuer les calculs sur plusieurs appareils.

Actuellement, les deux cadres de r√©seaux de neurones les plus populaires sont : [TensorFlow](http://TensorFlow.org) et [PyTorch](https://pytorch.org/). Les deux fournissent une API de bas niveau pour travailler avec des tenseurs √† la fois sur CPU et GPU. En plus de l'API de bas niveau, il existe √©galement une API de niveau sup√©rieur, appel√©e [Keras](https://keras.io/) et [PyTorch Lightning](https://pytorchlightning.ai/) respectivement.

API de Bas Niveau | [TensorFlow](http://TensorFlow.org) | [PyTorch](https://pytorch.org/)
------------------|-------------------------------------|--------------------------------
API de Niveau Sup√©rieur| [Keras](https://keras.io/) | [PyTorch Lightning](https://pytorchlightning.ai/)

**Les API de bas niveau** dans les deux cadres vous permettent de construire ce que l'on appelle des **graphes computationnels**. Ce graphe d√©finit comment calculer la sortie (g√©n√©ralement la fonction de perte) avec des param√®tres d'entr√©e donn√©s, et peut √™tre pouss√© pour le calcul sur GPU, si disponible. Il existe des fonctions pour diff√©rencier ce graphe computationnel et calculer les gradients, qui peuvent ensuite √™tre utilis√©s pour optimiser les param√®tres du mod√®le.

**Les API de niveau sup√©rieur** consid√®rent en grande partie les r√©seaux de neurones comme une **s√©quence de couches**, et facilitent la construction de la plupart des r√©seaux de neurones. L'entra√Ænement du mod√®le n√©cessite g√©n√©ralement de pr√©parer les donn√©es, puis d'appeler une fonction `fit` pour effectuer le travail.

L'API de niveau sup√©rieur vous permet de construire des r√©seaux de neurones typiques tr√®s rapidement sans vous soucier de nombreux d√©tails. En m√™me temps, l'API de bas niveau offre beaucoup plus de contr√¥le sur le processus d'entra√Ænement, et c'est pourquoi elles sont souvent utilis√©es dans la recherche, lorsque vous travaillez avec de nouvelles architectures de r√©seaux de neurones.

Il est √©galement important de comprendre que vous pouvez utiliser les deux API ensemble, par exemple, vous pouvez d√©velopper votre propre architecture de couche de r√©seau en utilisant l'API de bas niveau, puis l'utiliser √† l'int√©rieur d'un r√©seau plus large construit et entra√Æn√© avec l'API de niveau sup√©rieur. Ou vous pouvez d√©finir un r√©seau en utilisant l'API de niveau sup√©rieur comme une s√©quence de couches, puis utiliser votre propre boucle d'entra√Ænement de bas niveau pour effectuer l'optimisation. Les deux API utilisent les m√™mes concepts sous-jacents de base, et elles sont con√ßues pour bien fonctionner ensemble.

## Apprentissage

Dans ce cours, nous offrons la plupart du contenu √† la fois pour PyTorch et TensorFlow. Vous pouvez choisir votre cadre pr√©f√©r√© et ne passer qu'√† travers les notebooks correspondants. Si vous n'√™tes pas s√ªr du cadre √† choisir, lisez quelques discussions sur Internet concernant **PyTorch vs. TensorFlow**. Vous pouvez √©galement jeter un ≈ìil aux deux cadres pour mieux comprendre.

Lorsque cela est possible, nous utiliserons des API de niveau sup√©rieur pour plus de simplicit√©. Cependant, nous pensons qu'il est important de comprendre comment fonctionnent les r√©seaux de neurones depuis le d√©but, donc au d√©but, nous commen√ßons par travailler avec l'API de bas niveau et les tenseurs. Cependant, si vous souhaitez avancer rapidement et ne pas passer trop de temps √† apprendre ces d√©tails, vous pouvez les ignorer et aller directement dans les notebooks de l'API de niveau sup√©rieur.

## ‚úçÔ∏è Exercices : Cadres

Continuez votre apprentissage dans les notebooks suivants :

API de Bas Niveau | [Notebook TensorFlow+Keras](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb) | [PyTorch](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb)
------------------|-------------------------------------|--------------------------------
API de Niveau Sup√©rieur| [Keras](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb) | *PyTorch Lightning*

Apr√®s avoir ma√Ætris√© les cadres, r√©capitulons la notion de surapprentissage.

# Surapprentissage

Le surapprentissage est un concept extr√™mement important en apprentissage automatique, et il est crucial de bien le comprendre !

Consid√©rons le probl√®me suivant d'approximation de 5 points (repr√©sent√©s par `x` sur les graphiques ci-dessous) :

![linear](../../../../../translated_images/overfit1.f24b71c6f652e59e6bed7245ffbeaecc3ba320e16e2221f6832b432052c4da43.fr.jpg) | ![overfit](../../../../../translated_images/overfit2.131f5800ae10ca5e41d12a411f5f705d9ee38b1b10916f284b787028dd55cc1c.fr.jpg)
-------------------------|--------------------------
**Mod√®le lin√©aire, 2 param√®tres** | **Mod√®le non lin√©aire, 7 param√®tres**
Erreur d'entra√Ænement = 5.3 | Erreur de validation = 0
Erreur de validation = 5.1 | Erreur de validation = 20

* √Ä gauche, nous voyons une bonne approximation par une ligne droite. Parce que le nombre de param√®tres est ad√©quat, le mod√®le saisit bien l'id√©e derri√®re la distribution des points.
* √Ä droite, le mod√®le est trop puissant. √âtant donn√© que nous n'avons que 5 points et que le mod√®le a 7 param√®tres, il peut s'ajuster de mani√®re √† passer par tous les points, rendant l'erreur d'entra√Ænement √©gale √† 0. Cependant, cela emp√™che le mod√®le de comprendre le bon motif derri√®re les donn√©es, donc l'erreur de validation est tr√®s √©lev√©e.

Il est tr√®s important de trouver un bon √©quilibre entre la richesse du mod√®le (nombre de param√®tres) et le nombre d'√©chantillons d'entra√Ænement.

## Pourquoi le surapprentissage se produit

  * Pas assez de donn√©es d'entra√Ænement
  * Mod√®le trop puissant
  * Trop de bruit dans les donn√©es d'entr√©e

## Comment d√©tecter le surapprentissage

Comme vous pouvez le voir sur le graphique ci-dessus, le surapprentissage peut √™tre d√©tect√© par une tr√®s faible erreur d'entra√Ænement et une erreur de validation √©lev√©e. Normalement, pendant l'entra√Ænement, nous verrons √† la fois les erreurs d'entra√Ænement et de validation commencer √† diminuer, puis √† un certain moment, l'erreur de validation pourrait cesser de diminuer et commencer √† augmenter. Cela sera un signe de surapprentissage, et l'indicateur que nous devrions probablement arr√™ter l'entra√Ænement √† ce stade (ou au moins faire un instantan√© du mod√®le).

![overfitting](../../../../../translated_images/Overfitting.408ad91cd90b4371d0a81f4287e1409c359751adeb1ae450332af50e84f08c3e.fr.png)

## Comment pr√©venir le surapprentissage

Si vous constatez que le surapprentissage se produit, vous pouvez faire l'une des choses suivantes :

 * Augmenter la quantit√© de donn√©es d'entra√Ænement
 * Diminuer la complexit√© du mod√®le
 * Utiliser une [technique de r√©gularisation](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md), telle que [Dropout](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout), que nous consid√©rerons plus tard.

## Surapprentissage et compromis biais-variance

Le surapprentissage est en fait un cas d'un probl√®me plus g√©n√©rique en statistique appel√© [compromis biais-variance](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff). Si nous consid√©rons les sources possibles d'erreur dans notre mod√®le, nous pouvons voir deux types d'erreurs :

* **Erreurs de biais** caus√©es par le fait que notre algorithme n'est pas capable de capturer correctement la relation entre les donn√©es d'entra√Ænement. Cela peut r√©sulter du fait que notre mod√®le n'est pas assez puissant (**sous-apprentissage**).
* **Erreurs de variance**, qui sont caus√©es par le mod√®le qui approxime le bruit dans les donn√©es d'entr√©e au lieu de la relation significative (**surapprentissage**).

Pendant l'entra√Ænement, l'erreur de biais diminue (√† mesure que notre mod√®le apprend √† approximer les donn√©es), et l'erreur de variance augmente. Il est important d'arr√™ter l'entra√Ænement - soit manuellement (lorsque nous d√©tectons le surapprentissage), soit automatiquement (en introduisant une r√©gularisation) - pour pr√©venir le surapprentissage.

## Conclusion

Dans cette le√ßon, vous avez appris les diff√©rences entre les diff√©rentes API des deux cadres d'IA les plus populaires, TensorFlow et PyTorch. De plus, vous avez appris un sujet tr√®s important, le surapprentissage.

## üöÄ D√©fi

Dans les notebooks accompagnants, vous trouverez des 't√¢ches' en bas ; parcourez les notebooks et compl√©tez les t√¢ches.

## [Quiz post-cours](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/205)

## Revue & Auto-apprentissage

Faites des recherches sur les sujets suivants :

- TensorFlow
- PyTorch
- Surapprentissage

Posez-vous les questions suivantes :

- Quelle est la diff√©rence entre TensorFlow et PyTorch ?
- Quelle est la diff√©rence entre surapprentissage et sous-apprentissage ?

## [Devoir](lab/README.md)

Dans ce laboratoire, vous √™tes invit√© √† r√©soudre deux probl√®mes de classification en utilisant des r√©seaux enti√®rement connect√©s √† une et plusieurs couches en utilisant PyTorch ou TensorFlow.

* [Instructions](lab/README.md)
* [Notebook](../../../../../lessons/3-NeuralNetworks/05-Frameworks/lab/LabFrameworks.ipynb)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatis√©s bas√©s sur l'IA. Bien que nous visons √† garantir l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source autoris√©e. Pour des informations critiques, une traduction professionnelle par un humain est recommand√©e. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.