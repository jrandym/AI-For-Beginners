# Autoencoders

Ao treinar CNNs, um dos problemas √© que precisamos de muitos dados rotulados. No caso da classifica√ß√£o de imagens, precisamos separar as imagens em diferentes classes, o que √© um esfor√ßo manual.

## [Quiz pr√©-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

No entanto, podemos querer usar dados brutos (n√£o rotulados) para treinar extratores de caracter√≠sticas CNN, o que √© chamado de **aprendizado auto-supervisionado**. Em vez de r√≥tulos, usaremos imagens de treinamento como entrada e sa√≠da da rede. A ideia principal do **autoencoder** √© que teremos uma **rede de codifica√ß√£o** que converte a imagem de entrada em algum **espa√ßo latente** (normalmente √© apenas um vetor de um tamanho menor), e ent√£o a **rede de decodifica√ß√£o**, cujo objetivo seria reconstruir a imagem original.

> ‚úÖ Um [autoencoder](https://wikipedia.org/wiki/Autoencoder) √© "um tipo de rede neural artificial usada para aprender codifica√ß√µes eficientes de dados n√£o rotulados."

Como estamos treinando um autoencoder para capturar o m√°ximo de informa√ß√µes da imagem original poss√≠vel para uma reconstru√ß√£o precisa, a rede tenta encontrar a melhor **incorpora√ß√£o** das imagens de entrada para capturar o significado.

![Diagrama do AutoEncoder](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.pt.jpg)

> Imagem do [blog Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Cen√°rios para usar Autoencoders

Embora reconstruir imagens originais n√£o pare√ßa √∫til por si s√≥, existem alguns cen√°rios onde os autoencoders s√£o especialmente √∫teis:

* **Redu√ß√£o da dimens√£o das imagens para visualiza√ß√£o** ou **treinamento de incorpora√ß√µes de imagem**. Normalmente, os autoencoders apresentam resultados melhores do que PCA, pois levam em considera√ß√£o a natureza espacial das imagens e caracter√≠sticas hier√°rquicas.
* **Remo√ß√£o de ru√≠do**, ou seja, eliminar ru√≠do da imagem. Como o ru√≠do carrega muitas informa√ß√µes in√∫teis, o autoencoder n√£o consegue ajust√°-lo todo em um espa√ßo latente relativamente pequeno e, assim, captura apenas a parte importante da imagem. Ao treinar denoisers, come√ßamos com imagens originais e usamos imagens com ru√≠do adicionado artificialmente como entrada para o autoencoder.
* **Super-resolu√ß√£o**, aumentando a resolu√ß√£o da imagem. Come√ßamos com imagens de alta resolu√ß√£o e usamos a imagem de baixa resolu√ß√£o como entrada do autoencoder.
* **Modelos generativos**. Uma vez que treinamos o autoencoder, a parte do decodificador pode ser usada para criar novos objetos a partir de vetores latentes aleat√≥rios.

## Autoencoders Variacionais (VAE)

Autoencoders tradicionais reduzem a dimens√£o dos dados de entrada de alguma forma, identificando as caracter√≠sticas importantes das imagens de entrada. No entanto, vetores latentes muitas vezes n√£o fazem muito sentido. Em outras palavras, tomando o conjunto de dados MNIST como exemplo, descobrir quais d√≠gitos correspondem a diferentes vetores latentes n√£o √© uma tarefa f√°cil, porque vetores latentes pr√≥ximos n√£o necessariamente correspondem aos mesmos d√≠gitos.

Por outro lado, para treinar modelos *generativos*, √© melhor ter algum entendimento do espa√ßo latente. Essa ideia nos leva ao **autoencoder variacional** (VAE).

VAE √© o autoencoder que aprende a prever a *distribui√ß√£o estat√≠stica* dos par√¢metros latentes, chamada de **distribui√ß√£o latente**. Por exemplo, podemos querer que os vetores latentes sejam distribu√≠dos normalmente com uma m√©dia z<sub>mean</sub> e desvio padr√£o z<sub>sigma</sub> (tanto a m√©dia quanto o desvio padr√£o s√£o vetores de alguma dimensionalidade d). O codificador no VAE aprende a prever esses par√¢metros, e ent√£o o decodificador pega um vetor aleat√≥rio dessa distribui√ß√£o para reconstruir o objeto.

Para resumir:

 * A partir do vetor de entrada, prevemos `z_mean` e `z_log_sigma` (em vez de prever o desvio padr√£o em si, prevemos seu logaritmo)
 * Amostramos um vetor `sample` da distribui√ß√£o N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * O decodificador tenta decodificar a imagem original usando `sample` como vetor de entrada

 <img src="images/vae.png" width="50%">

> Imagem do [este post no blog](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) de Isaak Dykeman

Autoencoders variacionais usam uma fun√ß√£o de perda complexa que consiste em duas partes:

* **Perda de reconstru√ß√£o** √© a fun√ß√£o de perda que mostra qu√£o pr√≥xima uma imagem reconstru√≠da est√° do alvo (pode ser o Erro Quadr√°tico M√©dio, ou MSE). √â a mesma fun√ß√£o de perda que em autoencoders normais.
* **Perda KL**, que garante que as distribui√ß√µes das vari√°veis latentes permane√ßam pr√≥ximas √† distribui√ß√£o normal. √â baseada na no√ß√£o de [diverg√™ncia de Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - uma m√©trica para estimar qu√£o semelhantes s√£o duas distribui√ß√µes estat√≠sticas.

Uma vantagem importante dos VAEs √© que eles nos permitem gerar novas imagens relativamente facilmente, porque sabemos de qual distribui√ß√£o amostrar vetores latentes. Por exemplo, se treinarmos um VAE com vetor latente 2D no MNIST, podemos ent√£o variar os componentes do vetor latente para obter diferentes d√≠gitos:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Imagem de [Dmitry Soshnikov](http://soshnikov.com)

Observe como as imagens se misturam umas √†s outras, √† medida que come√ßamos a obter vetores latentes de diferentes por√ß√µes do espa√ßo de par√¢metros latentes. Tamb√©m podemos visualizar esse espa√ßo em 2D:

<img alt="cluster vaemnist" src="images/vaemnist-diag.png" width="50%"/> 

> Imagem de [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è Exerc√≠cios: Autoencoders

Saiba mais sobre autoencoders nestes cadernos correspondentes:

* [Autoencoders em TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Autoencoders em PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Propriedades dos Autoencoders

* **Espec√≠fico para dados** - eles funcionam bem apenas com o tipo de imagens para as quais foram treinados. Por exemplo, se treinarmos uma rede de super-resolu√ß√£o em flores, ela n√£o funcionar√° bem em retratos. Isso ocorre porque a rede pode produzir uma imagem de maior resolu√ß√£o ao captar detalhes finos das caracter√≠sticas aprendidas a partir do conjunto de dados de treinamento.
* **Com perdas** - a imagem reconstru√≠da n√£o √© a mesma que a imagem original. A natureza da perda √© definida pela *fun√ß√£o de perda* usada durante o treinamento.
* Funciona com **dados n√£o rotulados**.

## [Quiz p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Conclus√£o

Nesta li√ß√£o, voc√™ aprendeu sobre os v√°rios tipos de autoencoders dispon√≠veis para o cientista de IA. Voc√™ aprendeu como constru√≠-los e como us√°-los para reconstruir imagens. Voc√™ tamb√©m aprendeu sobre o VAE e como us√°-lo para gerar novas imagens.

## üöÄ Desafio

Nesta li√ß√£o, voc√™ aprendeu sobre o uso de autoencoders para imagens. Mas eles tamb√©m podem ser usados para m√∫sica! Confira o projeto [MusicVAE](https://magenta.tensorflow.org/music-vae) do projeto Magenta, que usa autoencoders para aprender a reconstruir m√∫sica. Fa√ßa alguns [experimentos](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) com esta biblioteca para ver o que voc√™ pode criar.

## [Quiz p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Revis√£o & Autoestudo

Para refer√™ncia, leia mais sobre autoencoders nestes recursos:

* [Construindo Autoencoders em Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Post no blog sobre NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Autoencoders Variacionais Explicados](https://kvfrans.com/variational-autoencoders-explained/)
* [Autoencoders Variacionais Condicionais](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Tarefa

No final de [este caderno usando TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb), voc√™ encontrar√° uma 'tarefa' - use isso como sua tarefa.

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em sua l√≠ngua nativa deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes do uso desta tradu√ß√£o.