# Arquiteturas de CNN Conhecidas

### VGG-16

VGG-16 √© uma rede que alcan√ßou 92,7% de precis√£o na classifica√ß√£o top-5 do ImageNet em 2014. Ela possui a seguinte estrutura de camadas:

![Camadas do ImageNet](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.pt.jpg)

Como voc√™ pode ver, o VGG segue uma arquitetura piramidal tradicional, que √© uma sequ√™ncia de camadas de convolu√ß√£o e pooling.

![Pir√¢mide do ImageNet](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.pt.jpg)

> Imagem de [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet √© uma fam√≠lia de modelos proposta pela Microsoft Research em 2015. A ideia principal do ResNet √© usar **blocos residuais**:

<img src="images/resnet-block.png" width="300"/>

> Imagem deste [artigo](https://arxiv.org/pdf/1512.03385.pdf)

A raz√£o para usar a passagem de identidade √© fazer com que nossa camada preveja **a diferen√ßa** entre o resultado de uma camada anterior e a sa√≠da do bloco residual - da√≠ o nome *residual*. Esses blocos s√£o muito mais f√°ceis de treinar, e √© poss√≠vel construir redes com v√°rias centenas desses blocos (as variantes mais comuns s√£o ResNet-52, ResNet-101 e ResNet-152).

Voc√™ tamb√©m pode pensar nesta rede como sendo capaz de ajustar sua complexidade ao conjunto de dados. Inicialmente, quando voc√™ come√ßa a treinar a rede, os valores dos pesos s√£o pequenos, e a maior parte do sinal passa por camadas de identidade. √Ä medida que o treinamento avan√ßa e os pesos se tornam maiores, a import√¢ncia dos par√¢metros da rede cresce, e a rede se ajusta para acomodar o poder expressivo necess√°rio para classificar corretamente as imagens de treinamento.

### Google Inception

A arquitetura Google Inception leva essa ideia um passo adiante e constr√≥i cada camada da rede como uma combina√ß√£o de v√°rios caminhos diferentes:

<img src="images/inception.png" width="400"/>

> Imagem de [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Aqui, precisamos enfatizar o papel das convolu√ß√µes 1x1, porque √† primeira vista elas n√£o fazem sentido. Por que precisar√≠amos passar pela imagem com um filtro 1x1? No entanto, voc√™ precisa lembrar que os filtros de convolu√ß√£o tamb√©m trabalham com v√°rios canais de profundidade (originalmente - cores RGB, em camadas subsequentes - canais para diferentes filtros), e a convolu√ß√£o 1x1 √© usada para misturar esses canais de entrada juntos usando diferentes pesos trein√°veis. Ela tamb√©m pode ser vista como uma redu√ß√£o de dimens√£o (pooling) sobre a dimens√£o do canal.

Aqui est√° [um bom post no blog](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) sobre o assunto, e [o artigo original](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet √© uma fam√≠lia de modelos com tamanho reduzido, adequados para dispositivos m√≥veis. Use-os se voc√™ estiver com recursos limitados e puder sacrificar um pouco de precis√£o. A ideia principal por tr√°s deles √© a chamada **convolu√ß√£o separ√°vel por profundidade**, que permite representar filtros de convolu√ß√£o por uma composi√ß√£o de convolu√ß√µes espaciais e convolu√ß√£o 1x1 sobre canais de profundidade. Isso reduz significativamente o n√∫mero de par√¢metros, tornando a rede menor em tamanho e tamb√©m mais f√°cil de treinar com menos dados.

Aqui est√° [um bom post no blog sobre MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Conclus√£o

Nesta unidade, voc√™ aprendeu o conceito principal por tr√°s das redes neurais de vis√£o computacional - redes convolucionais. Arquiteturas da vida real que impulsionam a classifica√ß√£o de imagens, detec√ß√£o de objetos e at√© mesmo redes de gera√ß√£o de imagens s√£o todas baseadas em CNNs, apenas com mais camadas e alguns truques de treinamento adicionais.

## üöÄ Desafio

Nos cadernos acompanhantes, h√° notas na parte inferior sobre como obter maior precis√£o. Fa√ßa alguns experimentos para ver se voc√™ consegue alcan√ßar uma precis√£o mais alta.

## [Quiz p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/207)

## Revis√£o e Estudo Aut√¥nomo

Embora as CNNs sejam mais frequentemente usadas para tarefas de Vis√£o Computacional, elas s√£o geralmente boas para extrair padr√µes de tamanho fixo. Por exemplo, se estivermos lidando com sons, tamb√©m podemos querer usar CNNs para procurar padr√µes espec√≠ficos em sinais de √°udio - nesse caso, os filtros seriam unidimensionais (e essa CNN seria chamada de 1D-CNN). Al√©m disso, √†s vezes, a 3D-CNN √© usada para extrair caracter√≠sticas em espa√ßo multidimensional, como certos eventos ocorrendo em v√≠deo - a CNN pode capturar certos padr√µes de mudan√ßa de caracter√≠sticas ao longo do tempo. Fa√ßa uma revis√£o e estudo aut√¥nomo sobre outras tarefas que podem ser realizadas com CNNs.

## [Tarefa](lab/README.md)

Neste laborat√≥rio, voc√™ tem a tarefa de classificar diferentes ra√ßas de gatos e c√£es. Essas imagens s√£o mais complexas do que o conjunto de dados MNIST e t√™m dimens√µes mais altas, e h√° mais de 10 classes.

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.