# Redes Adversariais Generativas

Na se√ß√£o anterior, aprendemos sobre **modelos geradores**: modelos que podem gerar novas imagens semelhantes √†s do conjunto de dados de treinamento. O VAE foi um bom exemplo de um modelo gerador.

## [Quiz pr√©-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

No entanto, se tentarmos gerar algo realmente significativo, como uma pintura em uma resolu√ß√£o razo√°vel, com o VAE, veremos que o treinamento n√£o converge bem. Para esse caso de uso, devemos aprender sobre outra arquitetura especificamente direcionada a modelos geradores - **Redes Adversariais Generativas**, ou GANs.

A ideia principal de uma GAN √© ter duas redes neurais que ser√£o treinadas uma contra a outra:

<img src="images/gan_architecture.png" width="70%"/>

> Imagem por [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Um pequeno vocabul√°rio:
> * **Gerador** √© uma rede que recebe um vetor aleat√≥rio e produz a imagem como resultado.
> * **Discriminador** √© uma rede que recebe uma imagem e deve dizer se √© uma imagem real (do conjunto de dados de treinamento) ou se foi gerada por um gerador. √â essencialmente um classificador de imagens.

### Discriminador

A arquitetura do discriminador n√£o difere de uma rede de classifica√ß√£o de imagens comum. No caso mais simples, pode ser um classificador totalmente conectado, mas provavelmente ser√° uma [rede convolucional](../07-ConvNets/README.md).

> ‚úÖ Uma GAN baseada em redes convolucionais √© chamada de [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Um discriminador CNN consiste nas seguintes camadas: v√°rias convolu√ß√µes + pooling (com tamanho espacial decrescente) e uma ou mais camadas totalmente conectadas para obter o "vetor de caracter√≠sticas", classificador bin√°rio final.

> ‚úÖ Um 'pooling' neste contexto √© uma t√©cnica que reduz o tamanho da imagem. "Camadas de pooling reduzem as dimens√µes dos dados combinando as sa√≠das de grupos de neur√¥nios em uma camada em um √∫nico neur√¥nio na pr√≥xima camada." - [fonte](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Gerador

Um Gerador √© um pouco mais complicado. Voc√™ pode consider√°-lo como um discriminador invertido. Come√ßando de um vetor latente (no lugar de um vetor de caracter√≠sticas), ele tem uma camada totalmente conectada para convert√™-lo no tamanho/formato necess√°rio, seguida de deconvolu√ß√µes + aumento de escala. Isso √© semelhante √† parte *decodificadora* de um [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Como a camada de convolu√ß√£o √© implementada como um filtro linear que percorre a imagem, a deconvolu√ß√£o √© essencialmente semelhante √† convolu√ß√£o e pode ser implementada usando a mesma l√≥gica de camada.

<img src="images/gan_arch_detail.png" width="70%"/>

> Imagem por [Dmitry Soshnikov](http://soshnikov.com)

### Treinando a GAN

As GANs s√£o chamadas de **adversariais** porque h√° uma competi√ß√£o constante entre o gerador e o discriminador. Durante essa competi√ß√£o, tanto o gerador quanto o discriminador melhoram, assim a rede aprende a produzir imagens cada vez melhores.

O treinamento acontece em duas etapas:

* **Treinando o discriminador**. Esta tarefa √© bastante direta: geramos um lote de imagens pelo gerador, rotulando-as como 0, que representa imagem falsa, e pegamos um lote de imagens do conjunto de dados de entrada (com r√≥tulo 1, imagem real). Obtemos uma *perda do discriminador* e realizamos a retropropaga√ß√£o.
* **Treinando o gerador**. Isso √© um pouco mais complicado, porque n√£o sabemos a sa√≠da esperada para o gerador diretamente. Pegamos toda a rede GAN, consistindo de um gerador seguido de um discriminador, alimentamos com alguns vetores aleat√≥rios e esperamos que o resultado seja 1 (correspondente a imagens reais). Em seguida, congelamos os par√¢metros do discriminador (n√£o queremos que ele seja treinado nesta etapa) e realizamos a retropropaga√ß√£o.

Durante esse processo, as perdas do gerador e do discriminador n√£o est√£o diminuindo significativamente. Na situa√ß√£o ideal, elas devem oscilar, correspondendo a ambas as redes melhorando seu desempenho.

## ‚úçÔ∏è Exerc√≠cios: GANs

* [Notebook GAN em TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Notebook GAN em PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Problemas com o treinamento de GAN

As GANs s√£o conhecidas por serem especialmente dif√≠ceis de treinar. Aqui est√£o alguns problemas:

* **Colapso de Modo**. Por esse termo, queremos dizer que o gerador aprende a produzir uma imagem bem-sucedida que engana o discriminador, e n√£o uma variedade de imagens diferentes.
* **Sensibilidade a hiperpar√¢metros**. Muitas vezes voc√™ pode ver que uma GAN n√£o converge de forma alguma e, em seguida, de repente diminui na taxa de aprendizado levando √† converg√™ncia.
* Manter um **equil√≠brio** entre o gerador e o discriminador. Em muitos casos, a perda do discriminador pode cair para zero relativamente r√°pido, o que resulta na incapacidade do gerador de treinar mais. Para superar isso, podemos tentar definir diferentes taxas de aprendizado para o gerador e o discriminador, ou pular o treinamento do discriminador se a perda j√° estiver muito baixa.
* Treinamento para **alta resolu√ß√£o**. Refletindo o mesmo problema que com autoencoders, esse problema √© desencadeado porque reconstruir muitas camadas de uma rede convolucional leva a artefatos. Esse problema √© tipicamente resolvido com o chamado **crescimento progressivo**, quando primeiro algumas camadas s√£o treinadas em imagens de baixa resolu√ß√£o e, em seguida, as camadas s√£o "desbloqueadas" ou adicionadas. Outra solu√ß√£o seria adicionar conex√µes extras entre camadas e treinar v√°rias resolu√ß√µes ao mesmo tempo - veja este [artigo sobre GANs de Gradiente Multi-Escala](https://arxiv.org/abs/1903.06048) para detalhes.

## Transfer√™ncia de Estilo

As GANs s√£o uma √≥tima maneira de gerar imagens art√≠sticas. Outra t√©cnica interessante √© a chamada **transfer√™ncia de estilo**, que pega uma **imagem de conte√∫do** e a redesenha em um estilo diferente, aplicando filtros da **imagem de estilo**.

A maneira como isso funciona √© a seguinte:
* Come√ßamos com uma imagem de ru√≠do aleat√≥rio (ou com uma imagem de conte√∫do, mas para fins de compreens√£o √© mais f√°cil come√ßar a partir do ru√≠do aleat√≥rio).
* Nosso objetivo seria criar uma imagem que estivesse pr√≥xima tanto da imagem de conte√∫do quanto da imagem de estilo. Isso seria determinado por duas fun√ß√µes de perda:
   - **Perda de conte√∫do** √© calculada com base nas caracter√≠sticas extra√≠das pela CNN em algumas camadas da imagem atual e da imagem de conte√∫do.
   - **Perda de estilo** √© calculada entre a imagem atual e a imagem de estilo de uma maneira inteligente usando matrizes de Gram (mais detalhes no [notebook de exemplo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Para tornar a imagem mais suave e remover o ru√≠do, tamb√©m introduzimos a **Perda de Variedade**, que calcula a dist√¢ncia m√©dia entre pixels vizinhos.
* O loop principal de otimiza√ß√£o ajusta a imagem atual usando descida de gradiente (ou algum outro algoritmo de otimiza√ß√£o) para minimizar a perda total, que √© uma soma ponderada de todas as tr√™s perdas.

## ‚úçÔ∏è Exemplo: [Transfer√™ncia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Quiz p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Conclus√£o

Nesta li√ß√£o, voc√™ aprendeu sobre GANs e como trein√°-las. Voc√™ tamb√©m aprendeu sobre os desafios especiais que esse tipo de Rede Neural pode enfrentar e algumas estrat√©gias sobre como super√°-los.

## üöÄ Desafio

Execute o [notebook de Transfer√™ncia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) usando suas pr√≥prias imagens.

## Revis√£o & Estudo Aut√¥nomo

Para refer√™ncia, leia mais sobre GANs nestes recursos:

* Marco Pasini, [10 Li√ß√µes que Aprendi Treinando GANs por um Ano](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), uma arquitetura GAN *de fato* a considerar
* [Criando Arte Generativa usando GANs no Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Tarefa

Revisite um dos dois notebooks associados a esta li√ß√£o e re-treine a GAN com suas pr√≥prias imagens. O que voc√™ pode criar?

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.