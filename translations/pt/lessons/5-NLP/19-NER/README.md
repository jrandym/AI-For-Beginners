# Reconhecimento de Entidades Nomeadas

At√© agora, temos nos concentrado principalmente em uma tarefa de PLN - classifica√ß√£o. No entanto, tamb√©m existem outras tarefas de PLN que podem ser realizadas com redes neurais. Uma dessas tarefas √© o **[Reconhecimento de Entidades Nomeadas](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), que lida com o reconhecimento de entidades espec√≠ficas dentro do texto, como lugares, nomes de pessoas, intervalos de data-hora, f√≥rmulas qu√≠micas e assim por diante.

## [Quiz pr√©-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/119)

## Exemplo de Uso do NER

Suponha que voc√™ queira desenvolver um chatbot de linguagem natural, semelhante ao Amazon Alexa ou ao Google Assistant. A forma como os chatbots inteligentes funcionam √© *entendendo* o que o usu√°rio deseja, realizando a classifica√ß√£o de texto na frase de entrada. O resultado dessa classifica√ß√£o √© chamado de **inten√ß√£o**, que determina o que um chatbot deve fazer.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Imagem do autor

No entanto, um usu√°rio pode fornecer alguns par√¢metros como parte da frase. Por exemplo, ao perguntar sobre o clima, ela pode especificar uma localiza√ß√£o ou data. Um bot deve ser capaz de entender essas entidades e preencher os espa√ßos dos par√¢metros de acordo antes de executar a a√ß√£o. √â exatamente aqui que o NER entra em cena.

> ‚úÖ Outro exemplo seria [analisar artigos m√©dicos cient√≠ficos](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Uma das principais coisas que precisamos procurar s√£o termos m√©dicos espec√≠ficos, como doen√ßas e subst√¢ncias m√©dicas. Embora um pequeno n√∫mero de doen√ßas possa ser extra√≠do usando busca de substring, entidades mais complexas, como compostos qu√≠micos e nomes de medicamentos, necessitam de uma abordagem mais complexa.

## NER como Classifica√ß√£o de Tokens

Os modelos de NER s√£o essencialmente **modelos de classifica√ß√£o de tokens**, porque para cada um dos tokens de entrada precisamos decidir se ele pertence a uma entidade ou n√£o, e se sim - a qual classe de entidade.

Considere o seguinte t√≠tulo de artigo:

**Regurgita√ß√£o da v√°lvula tric√∫spide** e **toxicidade do carbonato de l√≠tio** em um rec√©m-nascido.

As entidades aqui s√£o:

* Regurgita√ß√£o da v√°lvula tric√∫spide √© uma doen√ßa (`DIS`)
* Carbonato de l√≠tio √© uma subst√¢ncia qu√≠mica (`CHEM`)
* Toxicidade tamb√©m √© uma doen√ßa (`DIS`)

Observe que uma entidade pode abranger v√°rios tokens. E, como neste caso, precisamos distinguir entre duas entidades consecutivas. Assim, √© comum usar duas classes para cada entidade - uma especificando o primeiro token da entidade (frequentemente o prefixo `B-` √© usado, para **b**eginning), e outra - a continua√ß√£o de uma entidade (`I-`, para **i**nner token). Tamb√©m usamos `O` como uma classe para representar todos os **o**utros tokens. Essa marca√ß√£o de tokens √© chamada de [BIO tagging](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (ou IOB). Quando marcados, nosso t√≠tulo ficar√° assim:

Token | Tag
------|-----
Tric√∫spide | B-DIS
v√°lvula | I-DIS
regurgita√ß√£o | I-DIS
e | O
l√≠tio | B-CHEM
carbonato | I-CHEM
toxicidade | B-DIS
em | O
um | O
rec√©m-nascido | O
. | O

Como precisamos construir uma correspond√™ncia um a um entre tokens e classes, podemos treinar um modelo de rede neural **muitos-para-muitos** a partir desta imagem:

![Imagem mostrando padr√µes comuns de redes neurais recorrentes.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.pt.jpg)

> *Imagem de [este post no blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) por [Andrej Karpathy](http://karpathy.github.io/). Os modelos de classifica√ß√£o de tokens NER correspondem √† arquitetura de rede mais √† direita nesta imagem.*

## Treinamento de Modelos NER

Como um modelo NER √© essencialmente um modelo de classifica√ß√£o de tokens, podemos usar RNNs com os quais j√° estamos familiarizados para essa tarefa. Nesse caso, cada bloco da rede recorrente retornar√° o ID do token. O exemplo de notebook a seguir mostra como treinar LSTM para classifica√ß√£o de tokens.

## ‚úçÔ∏è Notebooks de Exemplo: NER

Continue seu aprendizado no seguinte notebook:

* [NER com TensorFlow](../../../../../lessons/5-NLP/19-NER/NER-TF.ipynb)

## Conclus√£o

Um modelo NER √© um **modelo de classifica√ß√£o de tokens**, o que significa que pode ser usado para realizar classifica√ß√£o de tokens. Esta √© uma tarefa muito comum em PLN, ajudando a reconhecer entidades espec√≠ficas dentro do texto, incluindo lugares, nomes, datas e mais.

## üöÄ Desafio

Complete a tarefa vinculada abaixo para treinar um modelo de reconhecimento de entidades nomeadas para termos m√©dicos e, em seguida, experimente em um conjunto de dados diferente.

## [Quiz p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/219)

## Revis√£o e Autoestudo

Leia o blog [A Efic√°cia Irresist√≠vel das Redes Neurais Recorrentes](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) e siga a se√ß√£o de Leitura Adicional nesse artigo para aprofundar seu conhecimento.

## [Tarefa](lab/README.md)

Na tarefa para esta li√ß√£o, voc√™ ter√° que treinar um modelo de reconhecimento de entidades m√©dicas. Voc√™ pode come√ßar treinando um modelo LSTM conforme descrito nesta li√ß√£o e prosseguir com o uso do modelo de transformador BERT. Leia [as instru√ß√µes](lab/README.md) para obter todos os detalhes.

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.