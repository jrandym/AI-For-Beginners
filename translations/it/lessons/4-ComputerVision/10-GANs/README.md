# Redes Generativas Antag√≥nicas

En la secci√≥n anterior, aprendimos sobre **modelos generativos**: modelos que pueden generar nuevas im√°genes similares a las que est√°n en el conjunto de datos de entrenamiento. VAE fue un buen ejemplo de un modelo generativo.

## [Cuestionario previo a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Sin embargo, si intentamos generar algo realmente significativo, como una pintura a una resoluci√≥n razonable, con VAE, veremos que el entrenamiento no converge bien. Para este caso de uso, debemos aprender sobre otra arquitectura espec√≠ficamente dirigida a modelos generativos: **Redes Generativas Antag√≥nicas**, o GANs.

La idea principal de una GAN es tener dos redes neuronales que se entrenar√°n entre s√≠:

<img src="images/gan_architecture.png" width="70%"/>

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Un poco de vocabulario:
> * **Generador** es una red que toma un vector aleatorio y produce la imagen como resultado.
> * **Discriminador** es una red que toma una imagen y debe determinar si es una imagen real (del conjunto de datos de entrenamiento) o si fue generada por un generador. Es esencialmente un clasificador de im√°genes.

### Discriminador

La arquitectura del discriminador no difiere de una red de clasificaci√≥n de im√°genes ordinaria. En el caso m√°s simple, puede ser un clasificador totalmente conectado, pero lo m√°s probable es que sea una [red convolucional](../07-ConvNets/README.md).

> ‚úÖ Una GAN basada en redes convolucionales se llama [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Un discriminador CNN consta de las siguientes capas: varias convoluciones+poolings (con tama√±o espacial decreciente) y, una o m√°s capas totalmente conectadas para obtener un "vector de caracter√≠sticas", el clasificador binario final.

> ‚úÖ Un 'pooling' en este contexto es una t√©cnica que reduce el tama√±o de la imagen. "Las capas de pooling reducen las dimensiones de los datos combinando las salidas de grupos de neuronas en una capa en una sola neurona en la siguiente capa." - [fuente](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generador

Un generador es un poco m√°s complicado. Se puede considerar como un discriminador invertido. Comenzando desde un vector latente (en lugar de un vector de caracter√≠sticas), tiene una capa totalmente conectada para convertirlo en el tama√±o/forma requerida, seguida de deconvoluciones+escalado. Esto es similar a la parte *decodificadora* de un [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Dado que la capa de convoluci√≥n se implementa como un filtro lineal que recorre la imagen, la deconvoluci√≥n es esencialmente similar a la convoluci√≥n y se puede implementar utilizando la misma l√≥gica de capa.

<img src="images/gan_arch_detail.png" width="70%"/>

> Imagen de [Dmitry Soshnikov](http://soshnikov.com)

### Entrenando la GAN

Las GANs se llaman **antag√≥nicas** porque hay una competencia constante entre el generador y el discriminador. Durante esta competencia, tanto el generador como el discriminador mejoran, por lo que la red aprende a producir im√°genes cada vez mejores.

El entrenamiento ocurre en dos etapas:

* **Entrenamiento del discriminador**. Esta tarea es bastante directa: generamos un lote de im√°genes por el generador, etiquet√°ndolas como 0, que representa una imagen falsa, y tomamos un lote de im√°genes del conjunto de datos de entrada (con etiqueta 1, imagen real). Obtenemos alguna *p√©rdida del discriminador* y realizamos retropropagaci√≥n.
* **Entrenamiento del generador**. Esto es un poco m√°s complicado, porque no conocemos la salida esperada para el generador directamente. Tomamos toda la red GAN que consiste en un generador seguido de un discriminador, le proporcionamos algunos vectores aleatorios y esperamos que el resultado sea 1 (correspondiente a im√°genes reales). Luego congelamos los par√°metros del discriminador (no queremos que se entrene en este paso) y realizamos la retropropagaci√≥n.

Durante este proceso, tanto las p√©rdidas del generador como las del discriminador no disminuyen significativamente. En la situaci√≥n ideal, deber√≠an oscilar, correspondiendo a ambas redes mejorando su rendimiento.

## ‚úçÔ∏è Ejercicios: GANs

* [Cuaderno de GAN en TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [Cuaderno de GAN en PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Problemas con el entrenamiento de GAN

Se sabe que las GANs son especialmente dif√≠ciles de entrenar. Aqu√≠ hay algunos problemas:

* **Colapso de modo**. Con este t√©rmino nos referimos a que el generador aprende a producir una imagen exitosa que enga√±a al discriminador, y no una variedad de im√°genes diferentes.
* **Sensibilidad a los hiperpar√°metros**. A menudo se puede observar que una GAN no converge en absoluto, y luego de repente disminuye en la tasa de aprendizaje, lo que lleva a la convergencia.
* Mantener un **equilibrio** entre el generador y el discriminador. En muchos casos, la p√©rdida del discriminador puede caer a cero relativamente r√°pido, lo que resulta en que el generador no pueda entrenarse m√°s. Para superar esto, podemos intentar establecer diferentes tasas de aprendizaje para el generador y el discriminador, o saltar el entrenamiento del discriminador si la p√©rdida ya es demasiado baja.
* Entrenamiento para **alta resoluci√≥n**. Reflejando el mismo problema que con los autoencoders, este problema se desencadena porque reconstruir demasiadas capas de la red convolucional conduce a artefactos. Este problema se suele resolver con el llamado **crecimiento progresivo**, cuando primero se entrenan unas pocas capas en im√°genes de baja resoluci√≥n, y luego se "desbloquean" o a√±aden capas. Otra soluci√≥n ser√≠a agregar conexiones adicionales entre capas y entrenar varias resoluciones a la vez: consulte este [art√≠culo sobre Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) para m√°s detalles.

## Transferencia de Estilo

Las GANs son una excelente manera de generar im√°genes art√≠sticas. Otra t√©cnica interesante es la llamada **transferencia de estilo**, que toma una **imagen de contenido** y la redibuja en un estilo diferente, aplicando filtros de una **imagen de estilo**.

La forma en que funciona es la siguiente:
* Comenzamos con una imagen de ruido aleatorio (o con una imagen de contenido, pero para facilitar la comprensi√≥n es m√°s f√°cil comenzar desde ruido aleatorio).
* Nuestro objetivo ser√≠a crear una imagen que est√© cerca tanto de la imagen de contenido como de la imagen de estilo. Esto se determinar√≠a mediante dos funciones de p√©rdida:
   - **P√©rdida de contenido** se calcula en funci√≥n de las caracter√≠sticas extra√≠das por la CNN en algunas capas de la imagen actual y la imagen de contenido.
   - **P√©rdida de estilo** se calcula entre la imagen actual y la imagen de estilo de manera ingeniosa utilizando matrices de Gram (m√°s detalles en el [cuaderno de ejemplo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)).
* Para hacer que la imagen sea m√°s suave y eliminar el ruido, tambi√©n introducimos **p√©rdida de variaci√≥n**, que calcula la distancia promedio entre p√≠xeles vecinos.
* El bucle principal de optimizaci√≥n ajusta la imagen actual utilizando descenso de gradiente (o alg√∫n otro algoritmo de optimizaci√≥n) para minimizar la p√©rdida total, que es una suma ponderada de las tres p√©rdidas.

## ‚úçÔ∏è Ejemplo: [Transferencia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Cuestionario posterior a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Conclusi√≥n

En esta lecci√≥n, aprendiste sobre las GANs y c√≥mo entrenarlas. Tambi√©n aprendiste sobre los desaf√≠os especiales que este tipo de red neuronal puede enfrentar, y algunas estrategias sobre c√≥mo superarlos.

## üöÄ Desaf√≠o

Revisa el [cuaderno de Transferencia de Estilo](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) utilizando tus propias im√°genes.

## Revisi√≥n y Autoestudio

Para referencia, lee m√°s sobre las GANs en estos recursos:

* Marco Pasini, [10 Lecciones que Aprend√≠ Entrenando GANs durante un A√±o](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), una arquitectura GAN *de facto* a considerar.
* [Creando Arte Generativo usando GANs en Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Asignaci√≥n

Revisa uno de los dos cuadernos asociados a esta lecci√≥n y vuelve a entrenar la GAN con tus propias im√°genes. ¬øQu√© puedes crear?

**Disclaimer**:  
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en inteligencia artificial. Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional por parte de un humano. No somos responsables de malentendidos o malas interpretaciones que surjan del uso de esta traducci√≥n.