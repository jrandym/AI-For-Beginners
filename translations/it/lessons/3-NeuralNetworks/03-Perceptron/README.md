# Introducci√≥n a las Redes Neuronales: Perceptr√≥n

## [Cuestionario previo a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/103)

Uno de los primeros intentos de implementar algo similar a una red neuronal moderna fue realizado por Frank Rosenblatt del Laboratorio Aeron√°utico de Cornell en 1957. Fue una implementaci√≥n de hardware llamada "Mark-1", dise√±ada para reconocer figuras geom√©tricas primitivas, como tri√°ngulos, cuadrados y c√≠rculos.

|      |      |
|--------------|-----------|
|<img src='images/Rosenblatt-wikipedia.jpg' alt='Frank Rosenblatt'/> | <img src='images/Mark_I_perceptron_wikipedia.jpg' alt='El Perceptr√≥n Mark 1' />|

> Im√°genes [de Wikipedia](https://en.wikipedia.org/wiki/Perceptron)

Una imagen de entrada se representaba mediante una matriz de fotoceldas de 20x20, por lo que la red neuronal ten√≠a 400 entradas y una salida binaria. Una red simple conten√≠a una neurona, tambi√©n llamada **unidad l√≥gica de umbral**. Los pesos de la red neuronal funcionaban como potenci√≥metros que requer√≠an ajuste manual durante la fase de entrenamiento.

> ‚úÖ Un potenci√≥metro es un dispositivo que permite al usuario ajustar la resistencia de un circuito.

> El New York Times escribi√≥ sobre el perceptr√≥n en ese momento: *el embri√≥n de una computadora electr√≥nica que [la Marina] espera que pueda caminar, hablar, ver, escribir, reproducirse y ser consciente de su existencia.*

## Modelo de Perceptr√≥n

Supongamos que tenemos N caracter√≠sticas en nuestro modelo, en cuyo caso el vector de entrada ser√≠a un vector de tama√±o N. Un perceptr√≥n es un modelo de **clasificaci√≥n binaria**, es decir, puede distinguir entre dos clases de datos de entrada. Asumiremos que para cada vector de entrada x, la salida de nuestro perceptr√≥n ser√° ya sea +1 o -1, dependiendo de la clase. La salida se calcular√° utilizando la f√≥rmula:

y(x) = f(w<sup>T</sup>x)

donde f es una funci√≥n de activaci√≥n de escal√≥n.

<!-- img src="http://www.sciweavers.org/tex2img.php?eq=f%28x%29%20%3D%20%5Cbegin%7Bcases%7D%0A%20%20%20%20%20%20%20%20%20%2B1%20%26%20x%20%5Cgeq%200%20%5C%5C%0A%20%20%20%20%20%20%20%20%20-1%20%26%20x%20%3C%200%0A%20%20%20%20%20%20%20%5Cend%7Bcases%7D%20%5C%5C%0A&bc=White&fc=Black&im=jpg&fs=12&ff=arev&edit=0" align="center" border="0" alt="f(x) = \begin{cases} +1 & x \geq 0 \\ -1 & x < 0 \end{cases} \\" width="154" height="50" / -->
<img src="images/activation-func.png"/>

## Entrenamiento del Perceptr√≥n

Para entrenar un perceptr√≥n, necesitamos encontrar un vector de pesos w que clasifique correctamente la mayor√≠a de los valores, es decir, que resulte en el menor **error**. Este error E se define por el **criterio del perceptr√≥n** de la siguiente manera:

E(w) = -‚àëw<sup>T</sup>x<sub>i</sub>t<sub>i</sub>

donde:

* la suma se toma sobre aquellos puntos de datos de entrenamiento i que resultan en una clasificaci√≥n incorrecta
* x<sub>i</sub> es el dato de entrada, y t<sub>i</sub> es ya sea -1 o +1 para ejemplos negativos y positivos respectivamente.

Este criterio se considera como una funci√≥n de los pesos w, y necesitamos minimizarlo. A menudo, se utiliza un m√©todo llamado **descenso de gradiente**, en el que comenzamos con algunos pesos iniciales w<sup>(0)</sup>, y luego en cada paso actualizamos los pesos de acuerdo con la f√≥rmula:

w<sup>(t+1)</sup> = w<sup>(t)</sup> - Œ∑‚àáE(w)

Aqu√≠ Œ∑ es la llamada **tasa de aprendizaje**, y ‚àáE(w) denota el **gradiente** de E. Despu√©s de calcular el gradiente, terminamos con

w<sup>(t+1)</sup> = w<sup>(t)</sup> + ‚àëŒ∑x<sub>i</sub>t<sub>i</sub>

El algoritmo en Python se ve as√≠:

```python
def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):

    weights = [0,0,0] # Initialize weights (almost randomly :)
        
    for i in range(num_iterations):
        pos = random.choice(positive_examples)
        neg = random.choice(negative_examples)

        z = np.dot(pos, weights) # compute perceptron output
        if z < 0: # positive example classified as negative
            weights = weights + eta*weights.shape

        z  = np.dot(neg, weights)
        if z >= 0: # negative example classified as positive
            weights = weights - eta*weights.shape

    return weights
```

## Conclusi√≥n

En esta lecci√≥n, aprendiste sobre un perceptr√≥n, que es un modelo de clasificaci√≥n binaria, y c√≥mo entrenarlo utilizando un vector de pesos.

## üöÄ Desaf√≠o

Si deseas intentar construir tu propio perceptr√≥n, prueba [este laboratorio en Microsoft Learn](https://docs.microsoft.com/en-us/azure/machine-learning/component-reference/two-class-averaged-perceptron?WT.mc_id=academic-77998-cacaste) que utiliza el [dise√±ador de Azure ML](https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer?WT.mc_id=academic-77998-cacaste).

## [Cuestionario posterior a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/203)

## Revisi√≥n y Autoestudio

Para ver c√≥mo podemos utilizar el perceptr√≥n para resolver un problema simple as√≠ como problemas de la vida real, y para continuar aprendiendo, dir√≠gete al cuaderno [Perceptron](../../../../../lessons/3-NeuralNetworks/03-Perceptron/Perceptron.ipynb).

Aqu√≠ hay un [art√≠culo interesante sobre perceptrones](https://towardsdatascience.com/what-is-a-perceptron-basics-of-neural-networks-c4cfea20c590) tambi√©n.

## [Tarea](lab/README.md)

En esta lecci√≥n, hemos implementado un perceptr√≥n para la tarea de clasificaci√≥n binaria, y lo hemos utilizado para clasificar entre dos d√≠gitos manuscritos. En este laboratorio, se te pide resolver el problema de clasificaci√≥n de d√≠gitos por completo, es decir, determinar qu√© d√≠gito es m√°s probable que corresponda a una imagen dada.

* [Instrucciones](lab/README.md)
* [Cuaderno](../../../../../lessons/3-NeuralNetworks/03-Perceptron/lab/PerceptronMultiClass.ipynb)

**Disclaimer**:  
This document has been translated using machine-based AI translation services. While we strive for accuracy, please be aware that automated translations may contain errors or inaccuracies. The original document in its native language should be considered the authoritative source. For critical information, professional human translation is recommended. We are not liable for any misunderstandings or misinterpretations arising from the use of this translation.