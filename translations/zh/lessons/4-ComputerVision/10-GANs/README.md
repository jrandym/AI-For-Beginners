# 生成对抗网络

在上一节中，我们学习了**生成模型**：能够生成与训练数据集中图像相似的新图像的模型。变分自编码器（VAE）是一个很好的生成模型示例。

## [课前小测](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

然而，如果我们尝试使用VAE生成一些真正有意义的东西，比如一幅合理分辨率的画作，我们会发现训练并没有很好地收敛。对于这个用例，我们应该学习另一种专门针对生成模型的架构——**生成对抗网络**，或称GAN。

GAN的主要思想是有两个神经网络彼此对抗训练：

<img src="images/gan_architecture.png" width="70%"/>

> 图片来源：[Dmitry Soshnikov](http://soshnikov.com)

> ✅ 一些词汇：
> * **生成器**是一个网络，它接收一些随机向量，并生成相应的图像。
> * **判别器**是一个网络，它接收一幅图像，并应判断该图像是否为真实图像（来自训练数据集），或者是由生成器生成的。它本质上是一个图像分类器。

### 判别器

判别器的架构与普通的图像分类网络没有区别。在最简单的情况下，它可以是一个全连接分类器，但更可能是一个[卷积网络](../07-ConvNets/README.md)。

> ✅ 基于卷积网络的GAN称为[DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

CNN判别器由以下层组成：若干卷积+池化层（空间大小逐渐减小），以及一个或多个全连接层以获得“特征向量”，最终形成二分类器。

> ✅ 在这个上下文中，'池化'是一种减少图像大小的技术。“池化层通过将一层中神经元集群的输出组合成下一层中的单个神经元来减少数据的维度。” - [来源](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### 生成器

生成器稍微复杂一些。可以将其视为一个反向判别器。它从一个潜在向量（替代特征向量）开始，具有一个全连接层将其转换为所需的大小/形状，然后是反卷积+上采样。这类似于[自编码器](../09-Autoencoders/README.md)的*解码器*部分。

> ✅ 因为卷积层被实现为遍历图像的线性滤波器，反卷积本质上类似于卷积，可以使用相同的层逻辑实现。

<img src="images/gan_arch_detail.png" width="70%"/>

> 图片来源：[Dmitry Soshnikov](http://soshnikov.com)

### 训练GAN

GAN被称为**对抗性**，因为生成器和判别器之间存在持续的竞争。在这种竞争中，生成器和判别器都在改进，因此网络学习生成越来越好的图像。

训练分为两个阶段：

* **训练判别器**。这个任务相对简单：我们通过生成器生成一批图像，标记为0，表示假图像，然后从输入数据集中提取一批图像（标记为1，真实图像）。我们获得一些*判别器损失*，并进行反向传播。
* **训练生成器**。这稍微复杂一些，因为我们并不知道生成器的期望输出。我们将整个GAN网络（由生成器和判别器组成）输入一些随机向量，期望结果为1（对应真实图像）。然后我们冻结判别器的参数（在此步骤中我们不希望它被训练），并进行反向传播。

在此过程中，生成器和判别器的损失并没有显著下降。在理想情况下，它们应该会震荡，表明两个网络都在提高性能。

## ✍️ 练习：GANs

* [TensorFlow/Keras中的GAN笔记本](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorch中的GAN笔记本](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN训练中的问题

众所周知，GAN的训练特别困难。以下是一些问题：

* **模式崩溃**。这个术语指的是生成器学会生成一种成功的图像来欺骗判别器，而不是各种不同的图像。
* **对超参数的敏感性**。你经常会看到GAN根本不收敛，然后突然在学习率下降时收敛。
* 在生成器和判别器之间保持**平衡**。在许多情况下，判别器的损失可以相对快速地降至零，导致生成器无法继续训练。为了解决这个问题，我们可以尝试为生成器和判别器设置不同的学习率，或者如果损失已经太低，则跳过判别器的训练。
* 训练**高分辨率**图像。反映出与自编码器相同的问题，这个问题的发生是因为重构太多卷积网络层会导致伪影。通常通过所谓的**渐进增长**来解决这个问题，首先在低分辨率图像上训练几层，然后“解锁”或添加层。另一个解决方案是在层之间添加额外的连接，并同时训练多个分辨率——有关详细信息，请参见这篇[多尺度梯度GAN论文](https://arxiv.org/abs/1903.06048)。

## 风格迁移

GAN是生成艺术图像的好方法。另一种有趣的技术是所谓的**风格迁移**，它将一幅**内容图像**重新绘制成不同的风格，应用来自**风格图像**的滤镜。

其工作原理如下：
* 我们从一幅随机噪声图像开始（或从一幅内容图像开始，但为了理解，从随机噪声开始更容易）。
* 我们的目标是创建一幅图像，使其接近内容图像和风格图像。这将由两个损失函数来决定：
   - **内容损失**是基于CNN在某些层从当前图像和内容图像提取的特征计算的。
   - **风格损失**是以一种巧妙的方式计算当前图像和风格图像之间的关系，使用Gram矩阵（更多细节见[示例笔记本](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)）。
* 为了使图像更平滑并去除噪声，我们还引入**变异损失**，计算相邻像素之间的平均距离。
* 主要优化循环使用梯度下降（或其他优化算法）调整当前图像，以最小化总损失，该损失是所有三种损失的加权和。

## ✍️ 示例：[风格迁移](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [课后小测](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## 结论

在本课中，您学习了GAN及其训练方法。您还了解了这种类型的神经网络可能面临的特殊挑战，以及一些应对这些挑战的策略。

## 🚀 挑战

使用您自己的图像运行[风格迁移笔记本](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)。

## 复习与自学

作为参考，您可以在以下资源中进一步了解GAN：

* Marco Pasini，[我在训练GAN一年中学到的10课](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)，一个*事实上的* GAN架构值得考虑
* [在Azure ML上使用GAN创建生成艺术](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## 作业

重新访问与本课相关的两个笔记本之一，并在您自己的图像上重新训练GAN。您能创造出什么？

**免责声明**：  
本文件使用基于机器的人工智能翻译服务进行翻译。虽然我们努力确保准确性，但请注意，自动翻译可能包含错误或不准确之处。原始文件的母语版本应被视为权威来源。对于关键信息，建议进行专业人工翻译。我们对因使用本翻译而产生的任何误解或误释不承担责任。