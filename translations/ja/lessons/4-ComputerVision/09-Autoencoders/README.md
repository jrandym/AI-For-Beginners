# オートエンコーダー

CNNを訓練する際の問題の一つは、多くのラベル付きデータが必要であることです。画像分類の場合、画像を異なるクラスに分ける必要があり、これは手作業で行う作業です。

## [プレ講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

しかし、CNNの特徴抽出器を訓練するために、生の（ラベルなしの）データを使用したい場合があります。これを**自己教師あり学習**と呼びます。ラベルの代わりに、訓練画像をネットワークの入力と出力の両方として使用します。**オートエンコーダー**の主なアイデアは、入力画像を何らかの**潜在空間**（通常はより小さなサイズのベクトル）に変換する**エンコーダーネットワーク**を持ち、その後に元の画像を再構築することを目的とした**デコーダーネットワーク**を持つことです。

> ✅ [オートエンコーダー](https://wikipedia.org/wiki/Autoencoder)は「ラベルなしデータの効率的なコーディングを学習するために使用される人工ニューラルネットワークの一種」です。

オートエンコーダーを訓練して元の画像からできるだけ多くの情報をキャプチャし、正確に再構築するために、ネットワークは入力画像の最適な**埋め込み**を見つけようとします。

![AutoEncoder Diagram](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ja.jpg)

> 画像は[Kerasブログ](https://blog.keras.io/building-autoencoders-in-keras.html)から

## オートエンコーダーの使用シナリオ

元の画像を再構築すること自体は有用ではないように思えるかもしれませんが、オートエンコーダーが特に役立つシナリオがいくつかあります：

* **視覚化のための画像の次元削減**または**画像埋め込みの訓練**。通常、オートエンコーダーはPCAよりも優れた結果を提供します。なぜなら、画像の空間的な特性と階層的な特徴を考慮に入れるからです。
* **ノイズ除去**、すなわち画像からノイズを取り除くこと。ノイズは多くの無駄な情報を含んでいるため、オートエンコーダーはそれを比較的小さな潜在空間にフィットさせることができず、したがって画像の重要な部分のみをキャプチャします。ノイズ除去器を訓練する際は、元の画像から始め、人工的にノイズを追加した画像をオートエンコーダーの入力として使用します。
* **超解像**、画像の解像度を上げること。高解像度の画像から始め、低解像度の画像をオートエンコーダーの入力として使用します。
* **生成モデル**。オートエンコーダーを訓練した後、デコーダー部分を使用してランダムな潜在ベクトルから新しいオブジェクトを生成できます。

## 変分オートエンコーダー（VAE）

従来のオートエンコーダーは、入力データの次元を何らかの方法で削減し、入力画像の重要な特徴を見つけ出します。しかし、潜在ベクトルはあまり意味を持たないことが多いです。言い換えれば、MNISTデータセットを例に取ると、異なる潜在ベクトルにどの数字が対応するかを見つけることは簡単ではありません。なぜなら、近い潜在ベクトルが必ずしも同じ数字に対応するわけではないからです。

一方、*生成的*モデルを訓練するには、潜在空間についての理解がある方が良いです。このアイデアは**変分オートエンコーダー**（VAE）につながります。

VAEは、潜在パラメータの*統計分布*を予測することを学習するオートエンコーダーで、これを**潜在分布**と呼びます。例えば、潜在ベクトルが平均z<sub>mean</sub>と標準偏差z<sub>sigma</sub>（平均と標準偏差は次元dのベクトルです）で正規分布するようにしたい場合があります。VAEのエンコーダーはこれらのパラメータを予測することを学習し、デコーダーはこの分布からランダムなベクトルを取り出してオブジェクトを再構築します。

要約すると：

* 入力ベクトルから、`z_mean`と`z_log_sigma`を予測します（標準偏差そのものを予測するのではなく、その対数を予測します）
* 分布N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))からベクトル`sample`をサンプリングします
* デコーダーは`sample`を入力ベクトルとして使用して元の画像をデコードしようとします

<img src="images/vae.png" width="50%">

> 画像は[このブログ投稿](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)のIsaak Dykemanによるものです

変分オートエンコーダーは、2つの部分からなる複雑な損失関数を使用します：

* **再構築損失**は、再構築された画像がターゲットにどれだけ近いかを示す損失関数です（これは平均二乗誤差、またはMSEになることがあります）。これは通常のオートエンコーダーと同じ損失関数です。
* **KL損失**は、潜在変数の分布が正規分布に近いことを保証します。これは、2つの統計分布がどれだけ似ているかを推定するためのメトリックである[Kullback-Leiblerダイバージェンス](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)に基づいています。

VAEの重要な利点の一つは、潜在ベクトルをサンプリングするための分布がわかっているため、新しい画像を比較的簡単に生成できることです。例えば、MNIST上で2D潜在ベクトルを持つVAEを訓練すると、潜在ベクトルの成分を変化させることで異なる数字を得ることができます：

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> 画像は[Dmitry Soshnikov](http://soshnikov.com)によるものです

異なる潜在パラメータ空間の部分から潜在ベクトルを取得し始めると、画像がどのように融合するかを観察してください。また、この空間を2Dで視覚化することもできます：

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> 画像は[Dmitry Soshnikov](http://soshnikov.com)によるものです

## ✍️ 演習：オートエンコーダー

オートエンコーダーについてさらに学ぶには、以下のノートブックを参照してください：

* [TensorFlowにおけるオートエンコーダー](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [PyTorchにおけるオートエンコーダー](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## オートエンコーダーの特性

* **データ特異的** - 訓練された画像のタイプに対してのみ良好に機能します。例えば、花に対して超解像ネットワークを訓練すると、ポートレートにはうまく機能しません。これは、ネットワークが訓練データセットから学習した特徴の詳細を取り入れて高解像度画像を生成できるからです。
* **損失あり** - 再構築された画像は元の画像と同じではありません。損失の性質は、訓練中に使用される*損失関数*によって定義されます。
* **ラベルなしデータ**で動作します。

## [ポスト講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## 結論

このレッスンでは、AI科学者が利用できるさまざまな種類のオートエンコーダーについて学びました。オートエンコーダーを構築する方法や、画像を再構築するためにそれらを使用する方法についても学びました。また、VAEについて、そしてそれを使用して新しい画像を生成する方法についても学びました。

## 🚀 チャレンジ

このレッスンでは、画像に対するオートエンコーダーの使用について学びました。しかし、オートエンコーダーは音楽にも使用できます！オートエンコーダーを使用して音楽を再構築する方法を学ぶMagentaプロジェクトの[MusicVAE](https://magenta.tensorflow.org/music-vae)プロジェクトをチェックしてみてください。このライブラリでいくつかの[実験](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb)を行い、何を作成できるか見てみましょう。

## [ポスト講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## レビュー & 自習

参考のために、オートエンコーダーについてさらに読むには以下のリソースを参照してください：

* [Kerasでのオートエンコーダーの構築](https://blog.keras.io/building-autoencoders-in-keras.html)
* [NeuroHiveのブログ投稿](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [変分オートエンコーダーの説明](https://kvfrans.com/variational-autoencoders-explained/)
* [条件付き変分オートエンコーダー](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## 課題

[TensorFlowを使用したこのノートブック](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)の最後に「タスク」があります。これを課題として使用してください。

**免責事項**:  
この文書は、機械ベースのAI翻訳サービスを使用して翻訳されています。正確性を追求していますが、自動翻訳には誤りや不正確さが含まれる可能性があることをご承知おきください。原文はその母国語での権威ある情報源と見なされるべきです。重要な情報については、専門の人間翻訳を推奨します。この翻訳の使用から生じる誤解や誤訳について、当社は一切の責任を負いません。