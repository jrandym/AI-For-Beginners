# 敵対的生成ネットワーク

前のセクションでは、**生成モデル**について学びました。これは、トレーニングデータセットにある画像に似た新しい画像を生成できるモデルです。VAEは生成モデルの良い例でした。

## [プレ講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

しかし、VAEを使用して、適切な解像度の意味のあるもの、例えば絵画を生成しようとすると、トレーニングがうまく収束しないことがわかります。このユースケースに対しては、生成モデルに特化した別のアーキテクチャ、すなわち**敵対的生成ネットワーク**、またはGANについて学ぶ必要があります。

GANの主なアイデアは、互いに競い合う二つのニューラルネットワークを持つことです。

<img src="images/gan_architecture.png" width="70%"/>

> 画像提供者: [Dmitry Soshnikov](http://soshnikov.com)

> ✅ 用語集:
> * **ジェネレーター**は、ランダムなベクトルを受け取り、結果として画像を生成するネットワークです。
> * **ディスクリミネーター**は、画像を受け取り、それが実際の画像（トレーニングデータセットからの）であるか、ジェネレーターによって生成されたものであるかを判断するネットワークです。これは本質的に画像分類器です。

### ディスクリミネーター

ディスクリミネーターのアーキテクチャは、通常の画像分類ネットワークと異なりません。最も簡単な場合、完全接続の分類器であることもありますが、ほとんどの場合は[畳み込みネットワーク](../07-ConvNets/README.md)になるでしょう。

> ✅ 畳み込みネットワークに基づくGANは[DCGAN](https://arxiv.org/pdf/1511.06434.pdf)と呼ばれます。

CNNディスクリミネーターは、以下の層で構成されています：いくつかの畳み込み+プーリング（空間サイズが減少する）と、"特徴ベクトル"を得るための1つ以上の完全接続層、最後にバイナリ分類器です。

> ✅ この文脈での「プーリング」とは、画像のサイズを減少させる技術です。「プーリング層は、1層のニューロンクラスターの出力を次の層の単一のニューロンに結合することによってデータの次元を減少させます。」 - [出典](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### ジェネレーター

ジェネレーターは少し複雑です。逆のディスクリミネーターと考えることができます。潜在ベクトル（特徴ベクトルの代わりに）から始まり、必要なサイズ/形状に変換するための完全接続層があり、その後に逆畳み込み+アップスケーリングが続きます。これは[オートエンコーダ](../09-Autoencoders/README.md)のデコーダ部分に似ています。

> ✅ 畳み込み層が画像を横断する線形フィルターとして実装されるため、逆畳み込みは本質的に畳み込みに似ており、同じ層のロジックを使用して実装できます。

<img src="images/gan_arch_detail.png" width="70%"/>

> 画像提供者: [Dmitry Soshnikov](http://soshnikov.com)

### GANのトレーニング

GANは**敵対的**と呼ばれます。なぜなら、ジェネレーターとディスクリミネーターの間に常に競争があるからです。この競争の間に、ジェネレーターとディスクリミネーターの両方が改善され、ネットワークはより良い画像を生成することを学びます。

トレーニングは二段階で行われます：

* **ディスクリミネーターのトレーニング**。このタスクは非常に単純です：ジェネレーターによって画像のバッチを生成し、それに0というラベルを付け（これは偽の画像を意味します）、入力データセットから画像のバッチを取得します（1というラベル、実際の画像）。これにより、*ディスクリミネーター損失*を得て、バックプロパゲーションを行います。
* **ジェネレーターのトレーニング**。これは少し複雑です。なぜなら、ジェネレーターの期待される出力を直接知ることができないからです。ジェネレーターの後にディスクリミネーターが続く全体のGANネットワークを取り、いくつかのランダムベクトルを入力し、結果が1（実際の画像に対応）になることを期待します。その後、ディスクリミネーターのパラメータを固定します（このステップでトレーニングされることは望ましくありません）し、バックプロパゲーションを行います。

このプロセスの間、ジェネレーターとディスクリミネーターの損失は大きく減少しません。理想的な状況では、両方のネットワークがパフォーマンスを向上させることに対応して、振動するはずです。

## ✍️ 演習: GANs

* [TensorFlow/KerasのGANノートブック](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorchのGANノートブック](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GANトレーニングの問題

GANは特にトレーニングが難しいことで知られています。以下はいくつかの問題です：

* **モード崩壊**。この用語は、ジェネレーターが1つの成功した画像を生成し、それを偽の画像として分類することを学び、異なる画像のバラエティを生成しないことを意味します。
* **ハイパーパラメータに対する感度**。しばしば、GANが全く収束しないのを見かけ、突然学習率が減少して収束に至ることがあります。
* ジェネレーターとディスクリミネーターの間の**バランス**を保つこと。多くの場合、ディスクリミネーターの損失は比較的早くゼロに落ちることがあり、これがジェネレーターがさらにトレーニングできなくなる結果を招きます。これを克服するために、ジェネレーターとディスクリミネーターの異なる学習率を設定したり、損失がすでに低すぎる場合はディスクリミネーターのトレーニングをスキップすることを試みることができます。
* **高解像度**のトレーニング。オートエンコーダと同じ問題を反映しており、畳み込みネットワークの多くの層を再構築することでアーティファクトが発生します。この問題は通常、最初に低解像度の画像でいくつかの層をトレーニングし、その後層を「解除」または追加する**進行的成長**と呼ばれる方法で解決されます。別の解決策は、層間に追加の接続を追加し、複数の解像度を同時にトレーニングすることです - 詳細はこの[マルチスケール勾配GANs論文](https://arxiv.org/abs/1903.06048)を参照してください。

## スタイル転送

GANは芸術的な画像を生成する素晴らしい方法です。もう一つの興味深い技術は、いわゆる**スタイル転送**で、これは1つの**コンテンツ画像**を取り、それを異なるスタイルで再描画し、**スタイル画像**からフィルターを適用します。

その仕組みは次のようになります：
* ランダムノイズ画像（またはコンテンツ画像）から始めますが、理解のためにはランダムノイズから始める方が簡単です。
* 目標は、コンテンツ画像とスタイル画像の両方に近い画像を作成することです。これは二つの損失関数によって決定されます：
   - **コンテンツ損失**は、現在の画像とコンテンツ画像から抽出されたCNNの特徴に基づいて計算されます。
   - **スタイル損失**は、現在の画像とスタイル画像の間で賢く計算され、グラム行列を使用します（詳細は[例のノートブック](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)を参照）。
* 画像を滑らかにし、ノイズを除去するために、**変動損失**も導入します。これは隣接するピクセル間の平均距離を計算します。
* 主な最適化ループは、勾配降下法（または他の最適化アルゴリズム）を使用して現在の画像を調整し、総損失を最小化します。これは、3つの損失の加重和です。

## ✍️ 例: [スタイル転送](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [講義後のクイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## 結論

このレッスンでは、GANについて学び、どのようにトレーニングするかを学びました。また、このタイプのニューラルネットワークが直面する特別な課題と、それを乗り越えるためのいくつかの戦略についても学びました。

## 🚀 チャレンジ

あなた自身の画像を使用して、[スタイル転送ノートブック](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)を実行してください。

## レビュー & 自習

参考のため、以下のリソースでGANについてさらに学んでください：

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)、考慮すべき*事実上の* GANアーキテクチャ
* [Azure MLでのGANを使用した生成アートの作成](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## 課題

このレッスンに関連する2つのノートブックのいずれかを再訪し、自分の画像でGANを再トレーニングしてください。何を作成できますか？

**免責事項**:  
この文書は、機械翻訳AIサービスを使用して翻訳されました。正確性を追求していますが、自動翻訳には誤りや不正確な部分が含まれる可能性があることをご理解ください。原文の母国語の文書が権威ある情報源と見なされるべきです。重要な情報については、専門の人間による翻訳をお勧めします。この翻訳の使用から生じる誤解や誤解釈について、当社は一切の責任を負いません。