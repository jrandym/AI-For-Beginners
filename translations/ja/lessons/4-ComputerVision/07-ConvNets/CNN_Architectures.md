# よく知られたCNNアーキテクチャ

### VGG-16

VGG-16は、2014年にImageNetのトップ5分類で92.7%の精度を達成したネットワークです。以下の層構造を持っています：

![ImageNet Layers](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.ja.jpg)

ご覧の通り、VGGは伝統的なピラミッドアーキテクチャに従っており、これは畳み込み層とプーリング層のシーケンスです。

![ImageNet Pyramid](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.ja.jpg)

> 画像出典: [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNetは、2015年にMicrosoft Researchによって提案されたモデルのファミリーです。ResNetの主なアイデアは、**残差ブロック**を使用することです：

<img src="images/resnet-block.png" width="300"/>

> 画像出典: [この論文](https://arxiv.org/pdf/1512.03385.pdf)

アイデンティティパススルーを使用する理由は、層が前の層の結果と残差ブロックの出力の**差**を予測することにあります - これが「残差」という名前の由来です。これらのブロックはトレーニングがはるかに容易であり、数百のブロックを持つネットワークを構築することができます（最も一般的なバリアントはResNet-52、ResNet-101、ResNet-152です）。

このネットワークは、データセットに応じて複雑さを調整できると考えることもできます。最初にネットワークのトレーニングを開始するとき、重みの値は小さく、ほとんどの信号はアイデンティティ層を通過します。トレーニングが進むにつれて重みが大きくなると、ネットワークパラメータの重要性が増し、ネットワークはトレーニング画像を正しく分類するために必要な表現力を調整します。

### Google Inception

Google Inceptionアーキテクチャは、このアイデアをさらに一歩進め、各ネットワーク層を複数の異なるパスの組み合わせとして構築します：

<img src="images/inception.png" width="400"/>

> 画像出典: [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

ここで、1x1の畳み込みの役割を強調する必要があります。なぜなら、最初はそれが意味を持たないからです。なぜ1x1フィルターで画像を通過させる必要があるのでしょうか？しかし、畳み込みフィルターは複数の深さチャネル（元々はRGBカラー、後の層では異なるフィルターのチャネル）でも機能することを思い出す必要があります。1x1の畳み込みは、異なる学習可能な重みを使用してこれらの入力チャネルを混合するために使用されます。また、チャネル次元に対するダウンサンプリング（プーリング）としても見ることができます。

このテーマに関する[良いブログ記事](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578)や、[元の論文](https://arxiv.org/pdf/1312.4400.pdf)があります。

### MobileNet

MobileNetは、サイズが縮小されたモデルのファミリーで、モバイルデバイスに適しています。リソースが限られている場合や、少しの精度を犠牲にできる場合に使用してください。これらの背後にある主なアイデアは、いわゆる**深さ方向に分離可能な畳み込み**であり、これにより畳み込みフィルターを空間的な畳み込みと深さチャネルに対する1x1の畳み込みの合成として表現できます。これにより、パラメータの数が大幅に削減され、ネットワークのサイズが小さくなり、少ないデータでトレーニングしやすくなります。

こちらは[MobileNetに関する良いブログ記事](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470)です。

## 結論

このユニットでは、コンピュータビジョンニューラルネットワークの主要な概念 - 畳み込みネットワークについて学びました。画像分類、物体検出、さらには画像生成ネットワークを支える実際のアーキテクチャはすべてCNNに基づいており、単に層が増え、追加のトレーニングテクニックが加わっています。

## 🚀 チャレンジ

付随するノートブックには、より高い精度を得るためのメモがあります。実験を行い、より高い精度を達成できるかどうかを試してみてください。

## [講義後のクイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/207)

## 復習と自己学習

CNNはコンピュータビジョンのタスクで最もよく使用されますが、一般的には固定サイズのパターンを抽出するのに適しています。たとえば、音に関しては、音声信号の特定のパターンを探すためにCNNを使用することもあります。この場合、フィルターは1次元になります（このCNNは1D-CNNと呼ばれます）。また、時には3D-CNNを使用して、ビデオ上で発生する特定のイベントのような多次元空間での特徴を抽出します - CNNは時間の経過に伴う特徴の変化の特定のパターンを捉えることができます。他のタスクについての復習と自己学習を行ってください。

## [課題](lab/README.md)

このラボでは、異なる猫と犬の品種を分類することが求められます。これらの画像はMNISTデータセットよりも複雑で高次元であり、10クラス以上あります。

**免責事項**:  
この文書は、機械翻訳AIサービスを使用して翻訳されています。正確性を追求していますが、自動翻訳にはエラーや不正確さが含まれる可能性があることをご理解ください。原文の母国語の文書が権威ある情報源と見なされるべきです。重要な情報については、専門の人間翻訳を推奨します。この翻訳の使用から生じる誤解や誤解釈については、当社は責任を負いません。