# ニューラルネットワークフレームワーク

すでに学んだように、ニューラルネットワークを効率的に訓練するためには、2つのことを行う必要があります。

* テンソルに対して操作を行うこと（例えば、掛け算、足し算、シグモイドやソフトマックスなどの関数を計算すること）
* 勾配降下法最適化を行うために、すべての式の勾配を計算すること

## [事前講義クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/105)

`numpy`ライブラリは最初の部分を実行できますが、勾配を計算するためのメカニズムが必要です。[私たちのフレームワーク](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb)では、`backward`メソッド内で全ての導関数関数を手動でプログラムする必要がありました。このメソッドはバックプロパゲーションを行います。理想的には、フレームワークは私たちが定義できる*任意の式*の勾配を計算する機会を提供するべきです。

もう一つ重要なことは、GPUや他の特殊な計算ユニット（例えば、[TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)）で計算を行うことができることです。ディープニューラルネットワークの訓練は*非常に多く*の計算を必要とし、これらの計算をGPU上で並列化できることは非常に重要です。

> ✅ 「並列化」という用語は、計算を複数のデバイスに分散させることを意味します。

現在、最も人気のある2つのニューラルフレームワークは、[TensorFlow](http://TensorFlow.org)と[PyTorch](https://pytorch.org/)です。どちらもCPUとGPUの両方でテンソルを操作するための低レベルAPIを提供しています。その低レベルAPIの上に、対応する高レベルAPIである[Keras](https://keras.io/)と[PyTorch Lightning](https://pytorchlightning.ai/)があります。

| 低レベルAPI | [TensorFlow](http://TensorFlow.org) | [PyTorch](https://pytorch.org/) |
|--------------|-------------------------------------|--------------------------------|
| 高レベルAPI| [Keras](https://keras.io/) | [PyTorch Lightning](https://pytorchlightning.ai/) |

**両方のフレームワークの低レベルAPI**を使用すると、いわゆる**計算グラフ**を構築できます。このグラフは、与えられた入力パラメータで出力（通常は損失関数）を計算する方法を定義し、利用可能であればGPUで計算に送ることができます。この計算グラフを微分して勾配を計算するための関数があり、これをモデルパラメータの最適化に使用できます。

**高レベルAPI**は、ニューラルネットワークを**層のシーケンス**として扱い、大部分のニューラルネットワークの構築をはるかに簡単にします。モデルの訓練には通常、データの準備を行い、その後`fit`関数を呼び出して処理を実行します。

高レベルAPIを使用すると、詳細を気にせずに典型的なニューラルネットワークを非常に迅速に構築できます。一方、低レベルAPIは訓練プロセスに対するより多くの制御を提供するため、新しいニューラルネットワークアーキテクチャを扱う研究で多く使用されます。

両方のAPIを一緒に使用できることも理解することが重要です。例えば、低レベルAPIを使用して独自のネットワーク層アーキテクチャを開発し、その後高レベルAPIで構築および訓練された大規模なネットワーク内で使用することができます。また、高レベルAPIを層のシーケンスとして使用してネットワークを定義し、その後独自の低レベル訓練ループを使用して最適化を実行することもできます。両方のAPIは同じ基本的な概念に基づいており、一緒にうまく機能するように設計されています。

## 学習

このコースでは、PyTorchとTensorFlowの両方のコンテンツを提供しています。好みのフレームワークを選択し、対応するノートブックだけを進めることができます。どのフレームワークを選ぶべきか分からない場合は、インターネットで**PyTorch vs. TensorFlow**に関する議論を読んでみてください。また、両方のフレームワークを見て、より良い理解を得ることもできます。

可能な限り、シンプルさのために高レベルAPIを使用します。ただし、ニューラルネットワークがどのように機能するかを基礎から理解することが重要だと考えているため、最初は低レベルAPIとテンソルを使って作業を開始します。しかし、すぐに始めたい場合やこれらの詳細を学ぶのに多くの時間を費やしたくない場合は、それらをスキップして高レベルAPIのノートブックに直接進むことができます。

## ✍️ 演習: フレームワーク

次のノートブックで学習を続けてください。

| 低レベルAPI | [TensorFlow+Kerasノートブック](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb) | [PyTorch](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb) |
|--------------|-------------------------------------|--------------------------------|
| 高レベルAPI| [Keras](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb) | *PyTorch Lightning* |

フレームワークを習得したら、過剰適合の概念を振り返りましょう。

# 過剰適合

過剰適合は機械学習において非常に重要な概念であり、正しく理解することが非常に重要です！

以下の5つの点（`x`で表現されたもの）を近似する問題を考えてみましょう：

![linear](../../../../../translated_images/overfit1.f24b71c6f652e59e6bed7245ffbeaecc3ba320e16e2221f6832b432052c4da43.ja.jpg) | ![overfit](../../../../../translated_images/overfit2.131f5800ae10ca5e41d12a411f5f705d9ee38b1b10916f284b787028dd55cc1c.ja.jpg)
-------------------------|--------------------------
**線形モデル、パラメータ2つ** | **非線形モデル、パラメータ7つ**
訓練誤差 = 5.3 | 訓練誤差 = 0
検証誤差 = 5.1 | 検証誤差 = 20

* 左側では、良好な直線近似が見られます。パラメータの数が適切であるため、モデルは点の分布の背後にあるアイデアを正しく捉えています。
* 右側では、モデルが強力すぎます。5つの点しかないのに、モデルには7つのパラメータがあるため、すべての点を通過するように調整でき、訓練誤差は0になります。しかし、これによりモデルはデータの背後にある正しいパターンを理解できず、検証誤差が非常に高くなります。

モデルの豊かさ（パラメータの数）と訓練サンプルの数との間で正しいバランスを取ることが非常に重要です。

## 過剰適合が発生する理由

  * 訓練データが不足している
  * モデルが強力すぎる
  * 入力データにノイズが多すぎる

## 過剰適合を検出する方法

上記のグラフからわかるように、過剰適合は非常に低い訓練誤差と高い検証誤差によって検出できます。通常、訓練中は訓練誤差と検証誤差の両方が減少し始め、その後、ある時点で検証誤差が減少を停止し、上昇し始めるかもしれません。これは過剰適合の兆候であり、この時点で訓練を停止すべきか（または少なくともモデルのスナップショットを作成すべき）であることを示す指標です。

![overfitting](../../../../../translated_images/Overfitting.408ad91cd90b4371d0a81f4287e1409c359751adeb1ae450332af50e84f08c3e.ja.png)

## 過剰適合を防ぐ方法

過剰適合が発生していることがわかった場合、次のいずれかを行うことができます。

 * 訓練データの量を増やす
 * モデルの複雑さを減らす
 * 後で考慮する[正則化手法](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md)、例えば[ドロップアウト](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout)を使用する

## 過剰適合とバイアス-バリアンスのトレードオフ

過剰適合は、実際には統計におけるより一般的な問題である[バイアス-バリアンスのトレードオフ](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)の一例です。モデルの誤差の可能な原因を考えると、2種類の誤差が見えてきます。

* **バイアス誤差**は、アルゴリズムが訓練データ間の関係を正しく捉えられないことから生じます。これは、モデルが十分に強力でないことから生じる場合があります（**アンダーフィッティング**）。
* **バリアンス誤差**は、モデルが入力データのノイズを近似することによって生じ、意味のある関係を捉えられないことから生じます（**過剰適合**）。

訓練中、バイアス誤差は減少し（モデルがデータを近似することを学ぶため）、バリアンス誤差は増加します。過剰適合を防ぐためには、訓練を手動（過剰適合を検出したとき）または自動（正則化を導入することによって）で停止することが重要です。

## 結論

このレッスンでは、最も人気のあるAIフレームワークであるTensorFlowとPyTorchのさまざまなAPIの違いについて学びました。また、非常に重要なトピックである過剰適合についても学びました。

## 🚀 チャレンジ

付随するノートブックでは、下部に「タスク」があります。ノートブックを進め、タスクを完了してください。

## [講義後のクイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/205)

## レビュー & 自習

以下のトピックについて調査してください：

- TensorFlow
- PyTorch
- 過剰適合

次の質問を自分に問いかけてください：

- TensorFlowとPyTorchの違いは何ですか？
- 過剰適合とアンダーフィッティングの違いは何ですか？

## [課題](lab/README.md)

このラボでは、PyTorchまたはTensorFlowを使用して、単層および多層の完全連結ネットワークを使用した2つの分類問題を解決するよう求められます。

* [指示](lab/README.md)
* [ノートブック](../../../../../lessons/3-NeuralNetworks/05-Frameworks/lab/LabFrameworks.ipynb)

**免責事項**:  
この文書は、機械ベースのAI翻訳サービスを使用して翻訳されました。正確性を追求していますが、自動翻訳には誤りや不正確さが含まれる可能性があることにご留意ください。原文のネイティブ言語の文書が正式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳をお勧めします。この翻訳の使用に起因する誤解や誤訳については、当社は一切責任を負いません。