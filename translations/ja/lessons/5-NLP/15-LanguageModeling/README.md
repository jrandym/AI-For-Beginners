# 言語モデリング

Word2VecやGloVeのような意味的埋め込みは、実際には**言語モデリング**への第一歩であり、言語の性質を*理解*（または*表現*）するモデルを作成することです。

## [講義前クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/115)

言語モデリングの基本的なアイデアは、ラベルのないデータセットで無監督の方法でそれらを訓練することです。これは重要です。なぜなら、ラベルのない膨大な量のテキストが利用可能であるのに対し、ラベル付きテキストの量は常にラベリングに費やせる努力の量によって制限されるからです。最も一般的には、テキスト内の**欠落した単語を予測する**ことができる言語モデルを構築できます。なぜなら、テキスト内のランダムな単語をマスクして、それを訓練サンプルとして使用するのは簡単だからです。

## 埋め込みの訓練

前の例では、事前に訓練された意味的埋め込みを使用しましたが、これらの埋め込みがどのように訓練されるかを見るのは興味深いです。いくつかの可能なアイデアがあります：

* **Nグラム**言語モデリング：N個の前のトークンを見てトークンを予測します（N-gram）
* **連続袋-of-単語**（CBoW）：トークンシーケンス$W_{-N}$、...、$W_N$の中で中央のトークン$W_0$を予測します。
* **スキップグラム**：中央のトークン$W_0$から隣接するトークンのセット{$W_{-N},\dots, W_{-1}, W_1,\dots, W_N$}を予測します。

![単語をベクトルに変換するアルゴリズムの例](../../../../../translated_images/example-algorithms-for-converting-words-to-vectors.fbe9207a726922f6f0f5de66427e8a6eda63809356114e28fb1fa5f4a83ebda7.ja.png)

> [この論文](https://arxiv.org/pdf/1301.3781.pdf)からの画像

## ✍️ 例のノートブック：CBoWモデルの訓練

以下のノートブックで学習を続けてください：

* [TensorFlowを使ったCBoW Word2Vecの訓練](../../../../../lessons/5-NLP/15-LanguageModeling/CBoW-TF.ipynb)
* [PyTorchを使ったCBoW Word2Vecの訓練](../../../../../lessons/5-NLP/15-LanguageModeling/CBoW-PyTorch.ipynb)

## 結論

前のレッスンでは、単語埋め込みがまるで魔法のように機能することを見ました！これで、単語埋め込みの訓練はそれほど複雑なタスクではないことがわかり、必要に応じてドメイン特有のテキストのために自分自身の単語埋め込みを訓練できるはずです。

## [講義後クイズ](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/215)

## 復習 & 自習

* [言語モデリングに関する公式PyTorchチュートリアル](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)。
* [Word2Vecモデルの訓練に関する公式TensorFlowチュートリアル](https://www.TensorFlow.org/tutorials/text/word2vec)。
* **gensim**フレームワークを使用して、数行のコードで最も一般的に使用される埋め込みを訓練する方法は、[このドキュメント](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)で説明されています。

## 🚀 [課題：スキップグラムモデルの訓練](lab/README.md)

ラボでは、このレッスンのコードを変更してCBoWの代わりにスキップグラムモデルを訓練することに挑戦します。[詳細を読む](lab/README.md)

**免責事項**:  
この文書は、機械翻訳サービスを使用して翻訳されています。正確性を追求していますが、自動翻訳には誤りや不正確な部分が含まれる可能性があることにご留意ください。元の文書は、その母国語での権威ある情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用から生じる誤解や誤訳について、当社は一切の責任を負いません。